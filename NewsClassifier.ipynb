{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NewsClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4beefd765b664ec1ba2ddbd3d9a751a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_baecbc86cdbf42aabd103ac6343c3019",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_836abdfee7c7406c83349b0411caa869",
              "IPY_MODEL_f2784715d9cd417cbd98a0cf11cb81a9"
            ]
          }
        },
        "baecbc86cdbf42aabd103ac6343c3019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "836abdfee7c7406c83349b0411caa869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0b9d27a6e8dc49e198c2dfdd0a0b36ca",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 109540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db0f7096dc714873997a682fe286cc72"
          }
        },
        "f2784715d9cd417cbd98a0cf11cb81a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b957e0887d9458581c2dc2bb5348ae1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 110k/110k [00:00&lt;00:00, 190kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe11d3c0bcd842869a4735d60ab9b672"
          }
        },
        "0b9d27a6e8dc49e198c2dfdd0a0b36ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db0f7096dc714873997a682fe286cc72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b957e0887d9458581c2dc2bb5348ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe11d3c0bcd842869a4735d60ab9b672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S9Nr0oAU3aS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4101b3b1-b1f1-44a9-db17-f38324afa554"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun 21 06:47:35 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8     8W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAdvRrEI5FnP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "b940624b-2905-4564-f5ac-3dd1f02d5ad2"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 16.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 32.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=278099661fc420eb19e3c03436fec87337461a0aaa7f00d0438ab62de4b39e66\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gPrVb5_cf8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "745d7b83-e615-40dc-ce88-1a75b04f40c2"
      },
      "source": [
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "import csv\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f2484566cd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq5FmPexVLaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0205da04-35ba-4be2-9aa0-6419a9c1cffd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl5P0iQ5cZlq"
      },
      "source": [
        "PATH_TO_MATERIAL_DIR='DataSet' #@param {type: \"string\"}\n",
        "material_dir = os.path.join('/content/drive/My Drive', PATH_TO_MATERIAL_DIR)\n",
        "os.chdir(material_dir)\n",
        "corpus='Tbrain_AI'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnY8aSjvaItg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "55ab5505-0507-4528-8d18-c806bc289112"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "with open(os.path.join(corpus, \"origTrainData.csv\"), newline='', encoding='utf-8') as csvfile:\n",
        "\n",
        "  # 讀取 CSV 檔案內容\n",
        "  rows = csv.reader(csvfile)\n",
        "  df = pd.read_csv(csvfile) \n",
        "  #reader = unicode_csv_reader(csvfile)\n",
        " # print(reader)\n",
        " \n",
        "  print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "      Unnamed: 0  Column1  ... name  label\n",
            "0              0        0  ...   []      0\n",
            "1              1        2  ...   []      0\n",
            "2              2        3  ...   []      0\n",
            "3              3        7  ...   []      0\n",
            "4              4        8  ...   []      0\n",
            "...          ...      ...  ...  ...    ...\n",
            "2576        2576     5016  ...   []      0\n",
            "2577        2577     5017  ...   []      0\n",
            "2578        2578     5019  ...   []      0\n",
            "2579        2579     5021  ...   []      0\n",
            "2580        2580     5022  ...   []      0\n",
            "\n",
            "[2581 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8AsuUmqb2QC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "a2388dbb-fe27-42d4-f94a-06ebc7c4d63e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Column1</th>\n",
              "      <th>titles</th>\n",
              "      <th>news_ID</th>\n",
              "      <th>hyperlink</th>\n",
              "      <th>content</th>\n",
              "      <th>name</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0理財基金量化交易追求絕對報酬有效對抗牛熊市鉅亨網記者鄭心芸2019/07/05 22:35...</td>\n",
              "      <td>1</td>\n",
              "      <td>https://news.cnyes.com/news/id/4352432</td>\n",
              "      <td>近年來投資市場波動越來越明顯追求低波動絕對報酬的量化交易備受注目專家表示採用量化交易策略投資...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2019.10.08 01:53【法拍有詭4】飯店遭管委會斷水斷電員工怒吼：生計何去何從？文...</td>\n",
              "      <td>3</td>\n",
              "      <td>https://www.mirrormedia.mg/story/20191008soc011/</td>\n",
              "      <td>福勵樂活富勝家公司的員工向本刊控訴君鴻酒店遭法拍疑點重重已經影響君鴻多位員工的生計；他們也只...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>58歲林姓男子昨凌晨與朋友聚餐結束後 ### 省略內文 ### 而地點就距離林家僅30公尺。...</td>\n",
              "      <td>4</td>\n",
              "      <td>https://www.chinatimes.com/newspapers/20190917...</td>\n",
              "      <td>歲林姓男子昨凌晨與朋友聚餐結束後朋友送他到三峽住處外詎料林未進家門反而醉倒在離家門米外的大街...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2019.12.09 08:00「再教育營學員全已結業」新疆自治區主席：他們過上了幸福生活文...</td>\n",
              "      <td>8</td>\n",
              "      <td>https://www.mirrormedia.mg/story/20191209edi009/</td>\n",
              "      <td>據港媒香港報導新疆維吾爾自治區主席雪克來提扎克爾今出席記者會針對外媒提問目前職業技能教育培訓...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>交通部觀光局26日公布7月國際旅客情況 ### 省略內文 ### 只能長期培養。</td>\n",
              "      <td>9</td>\n",
              "      <td>https://www.chinatimes.com/newspapers/20190827...</td>\n",
              "      <td>交通部觀光局日公布月國際旅客情況單月萬人次較去年同期成長但已連續兩個月未破百萬門檻陸客月單月...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Column1  ... name  label\n",
              "0           0        0  ...   []      0\n",
              "1           1        2  ...   []      0\n",
              "2           2        3  ...   []      0\n",
              "3           3        7  ...   []      0\n",
              "4           4        8  ...   []      0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqqBadZ4doSv"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-chinese'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTjEKuxdfCcD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "4beefd765b664ec1ba2ddbd3d9a751a3",
            "baecbc86cdbf42aabd103ac6343c3019",
            "836abdfee7c7406c83349b0411caa869",
            "f2784715d9cd417cbd98a0cf11cb81a9",
            "0b9d27a6e8dc49e198c2dfdd0a0b36ca",
            "db0f7096dc714873997a682fe286cc72",
            "8b957e0887d9458581c2dc2bb5348ae1",
            "fe11d3c0bcd842869a4735d60ab9b672"
          ]
        },
        "outputId": "a0da499a-f503-4b3d-eb5a-8e85ddfc7d60"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4beefd765b664ec1ba2ddbd3d9a751a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=109540.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbJ61hOWhCTI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c941d881-bc05-45f3-dab4-dd7f01addd92"
      },
      "source": [
        "sample_txt=df['content'][0]\n",
        "label=[df['label'][0]]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIa32HTcfHcW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79836cb2-1f23-4362-e15c-2af8e65b37a4"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=512,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9omldDhhH5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "0758636d-54d6-47a1-b7b7-4b037d19671c"
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 101, 6818, 2399,  889, 2832, 6536, 2356, 1842, 3797, 1240, 6632,  889,\n",
              "         6632, 3209, 7549, 6841, 3724,  856, 3797, 1240, 5179, 2205, 1841, 6992,\n",
              "         4638, 7030, 1265,  769, 3211,  991, 1358, 3800, 4680, 2201, 2157, 6134,\n",
              "         4850, 2967, 4500, 7030, 1265,  769, 3211, 5032, 4526, 2832, 6536, 1378,\n",
              "         5500,  679, 5052, 3221, 5993, 3176, 1914, 7531, 2772, 3221, 4958, 7531,\n",
              "         2356, 1842, 5245, 3126, 1350, 3797, 1240, 2428, 1772, 1377, 7526, 6651,\n",
              "         1920, 4676, 4493, 5635, 3683, 1751, 1058, 2832, 6536, 1378, 5500, 4638,\n",
              "         5500, 4873, 1798, 1825, 7032, 1350, 4638, 3797, 1240, 4372, 6917,  856,\n",
              "         6134, 4412,  738, 3291, 4158, 4952, 2137, 1920, 3149, 3087, 3229,  807,\n",
              "          889, 5631, 7591, 6121, 3627, 5401, 2399, 4638, 7030, 1265,  769, 3211,\n",
              "         1035, 4197, 2768, 4158, 7549, 2119, 1378, 4124,  771, 7274, 1993, 7028,\n",
              "         6213, 3634,  671, 6638, 1248, 4634, 2245,  738, 1728, 3634,  704, 5836,\n",
              "         3582, 4372, 5186, 6243, 2119, 3298, 1350, 1378, 1266, 4906, 2825, 1920,\n",
              "         2119, 5052, 4415, 2119, 7368, 3108, 2797,  712, 6794,  699, 4507, 1039,\n",
              "         1920, 3309, 6515, 3040, 3418,  765, 1922, 7030, 1265,  769, 3211, 5023,\n",
              "         1062, 1385, 3085,  818, 1295, 6794, 1606,  855,  791, 3189, 5647, 6794,\n",
              "         3229, 7279, 2415, 1154, 5645, 7030, 1265,  769, 3211, 4777, 6245, 3298,\n",
              "         2218, 4680, 1184, 4229, 7271, 4638, 7030, 1265,  769, 3211, 3255, 5543,\n",
              "         2832, 6536, 5023, 4685, 7302, 6359, 7539, 6868, 6121, 4777, 6245, 6632,\n",
              "          889, 6632, 1914, 4638, 1825, 7032, 1062, 1385, 7028, 6213, 7030, 1265,\n",
              "          769, 3211, 1059, 4413, 6211, 3563, 6733, 1920, 4638, 6912, 7402, 1825,\n",
              "         7032, 1914, 2967, 6121, 7030, 1265,  769, 3211, 1259, 2886, 3578, 3717,\n",
              "         1825, 7032, 6536, 4496, 5052, 4415, 1062, 1385, 3294, 3694, 7415, 1757,\n",
              "         3152, 5971, 2541, 5646, 4906, 2825, 5023, 1059, 4413, 4761, 1399, 6912,\n",
              "         7402, 1825, 7032, 3040, 3418,  765, 1922, 7415, 1757, 5869,  752, 7269,\n",
              "         2484, 1839, 1235, 2900, 1139, 6912, 7402, 1825, 7032, 6211, 3563, 5147,\n",
              "         4158, 1042, 5401, 1039, 2967, 1357, 7030, 1265,  769, 3211, 4638, 1825,\n",
              "         7032, 6211, 3563, 5147, 1042, 5401, 1039, 3683, 7028,  861,  749,  807,\n",
              "         6134, 7030, 1265,  769, 3211, 4638, 3082,  868, 5245, 3126, 1962, 2798,\n",
              "         3298, 3300, 6929, 7938, 7770, 4638, 3683, 7028, 7030, 1265,  769, 3211,\n",
              "         4638, 3082,  868, 5245, 3126,  679,  765, 3176, 1019,  966, 2832, 6536,\n",
              "         1350, 2825, 6123, 2832, 6536, 6158, 6363, 4158, 3149, 2119, 1921, 2798,\n",
              "         3297, 6553, 7092, 4638, 1825, 7032, 5195, 4415,  782, 3152, 5971, 2541,\n",
              "         5646, 2205, 3762, 1825, 7032, 1201, 1993,  782, 6285, 1990, 3172, 6205,\n",
              "         5885, 3172, 2792, 5052, 4415, 4638, 1920, 4354, 4995, 1825, 7032,  912,\n",
              "         3221, 1073, 1798, 4638, 7030, 1265,  769, 3211, 5245, 3126, 6134, 4412,\n",
              "         1032, 4530,  679, 1006, 1245, 6882, 5164, 5397, 3172, 4638, 7030, 2094,\n",
              "         1825, 7032,  738, 2802, 3134,  749, 5500, 4868, 2349, 5838, 4294, 4638,\n",
              "         1019,  966, 2832, 6536, 6818, 2399,  889, 1378, 4124,  738, 6852, 4041,\n",
              "         7028, 6213, 7030, 1265,  769, 3211, 3040, 3418,  765, 1922, 7030, 1265,\n",
              "          769, 3211, 1062, 1385,  791, 2399, 7274, 1993, 2200, 7030, 1265,  769,\n",
              "         3211, 2471, 6868, 1378, 5500, 2832, 6536, 3221, 1751, 1058, 7674, 2157,\n",
              "         2972, 1139, 7030, 1265,  769, 3211, 5032,  102]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vow7PPEYhMMN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "809c9bd3-252b-4f56-aa91-9777fcaf70c5"
      },
      "source": [
        "tokens = tokenizer.tokenize(sample_txt)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f' Sentence: {sample_txt}')\n",
        "print(f'   Tokens: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Sentence: 近年來投資市場波動越來越明顯追求低波動絕對報酬的量化交易備受注目專家表示採用量化交易策略投資台股不管是處於多頭或是空頭市場績效及波動度均可領跑大盤甚至比國內投資台股的股票型基金及  的波動率還低表現也更為穩定大數據時代來臨風行歐美  年的量化交易儼然成為顯學台灣亦開始重視此一趨勢發展也因此中華機率統計學會及台北科技大學管理學院攜手主辦並由元大期貨摩根亞太量化交易等公司擔任協辦單位今  日舉辦時間序列與量化交易研討會就目前熱門的量化交易智能投資等相關議題進行研討越來越多的基金公司重視量化交易全球規模較大的避險基金多採行量化交易包括橋水基金   資產管理公司曼氏集團  文藝復興科技   等全球知名避險基金摩根亞太集團董事長張堯勇指出避險基金規模約為  兆美元採取量化交易的基金規模約  兆美元比重佔了 代表量化交易的操作績效好才會有那麼高的比重量化交易的操作績效不亞於價值投資及技術投資被譽為數學天才最賺錢的基金經理人文藝復興對沖基金創始人詹姆斯  西蒙斯   所管理的大獎章  基金便是典型的量化交易績效表現優異不僅勝過索羅斯的量子基金也打敗了股神巴菲特的價值投資近年來台灣也逐漸重視量化交易摩根亞太量化交易公司今年開始將量化交易引進台股投資是國內首家推出量化交易策略的公司初期對象鎖定法人機構進行私募投資張堯勇表示數學不只是一門學科更是一項扭轉乾坤轉敗為勝的競爭利器量化交易就是將數學運用在股市投資透過複雜精密的推理計算打敗股市他指出目前全球利率水平  位於年來新低美國十年期公債殖利率只有 日本及一些歐洲國家甚至是負利率歷史極低利率帶導致無風險及低風險工具的投資報酬率太低（例如：銀行存款政府公債及投資等級公司債）無法對抗通貨膨脹及支付負債所以資產配置必須增加較高風險的投資如股票高收益公司債或新興市場債券但是這些投資工具波動很大而且很容易產生虧損他表示長期來說股市絕對是好的投資報酬率也不差但是如何選股是一門學問目前全球  個主要股市交易所總市值  兆美元而台灣上市上櫃市值  兆台幣面對全球及台灣最大的股市金礦投資人應該善用量化交易這個超級挖礦機以程式選股來掏金張堯勇指出量化投資具有低波動絕對報酬優於大盤的三大特點摩根亞太量化交易模擬台股近  年來的績效結果顯示運用量化交易的年化報酬率及波動度均優於台股上市櫃指數以  年金融海嘯及  年中美貿易戰為例台股上市上櫃指數均是負報酬不過摩根量化交易卻是正報酬而且波動度也比較低此外由於台灣四大政府基金操作績效不彰不少金融機構也面臨投資虧損問題亦可透過量化交易提高投資報酬率張堯勇指出郵儲勞退勞保及退撫等四大基金總資產高達  兆台幣但過去  年的投資報酬率不到 去年虧損  億面臨提早破產的風險另外台灣保險公司的總資產高達  兆台幣過去賣出去的保單利率高達 但是去年的資產報酬率卻只不到 而且去年綜合損益虧損高達  億金管會連下三道金牌：所有保險公司今年不準發放現金股利部分保險公司必須儘快舉辦現金增資以後賣的保單利率必須下降另外台灣全體商業銀行也有高達  兆的總資產  兆但是其資產報酬率僅只有 以上將近  兆台幣的資金張堯勇指出若將  投資於股市投資金額高達  兆報酬率每增加 就有  億元的獲利對於台灣的國家財政或金融機構的獲利都有非常巨大的助益\n",
            "   Tokens: ['近', '年', '來', '投', '資', '市', '場', '波', '動', '越', '來', '越', '明', '顯', '追', '求', '低', '波', '動', '絕', '對', '報', '酬', '的', '量', '化', '交', '易', '備', '受', '注', '目', '專', '家', '表', '示', '採', '用', '量', '化', '交', '易', '策', '略', '投', '資', '台', '股', '不', '管', '是', '處', '於', '多', '頭', '或', '是', '空', '頭', '市', '場', '績', '效', '及', '波', '動', '度', '均', '可', '領', '跑', '大', '盤', '甚', '至', '比', '國', '內', '投', '資', '台', '股', '的', '股', '票', '型', '基', '金', '及', '的', '波', '動', '率', '還', '低', '表', '現', '也', '更', '為', '穩', '定', '大', '數', '據', '時', '代', '來', '臨', '風', '行', '歐', '美', '年', '的', '量', '化', '交', '易', '儼', '然', '成', '為', '顯', '學', '台', '灣', '亦', '開', '始', '重', '視', '此', '一', '趨', '勢', '發', '展', '也', '因', '此', '中', '華', '機', '率', '統', '計', '學', '會', '及', '台', '北', '科', '技', '大', '學', '管', '理', '學', '院', '攜', '手', '主', '辦', '並', '由', '元', '大', '期', '貨', '摩', '根', '亞', '太', '量', '化', '交', '易', '等', '公', '司', '擔', '任', '協', '辦', '單', '位', '今', '日', '舉', '辦', '時', '間', '序', '列', '與', '量', '化', '交', '易', '研', '討', '會', '就', '目', '前', '熱', '門', '的', '量', '化', '交', '易', '智', '能', '投', '資', '等', '相', '關', '議', '題', '進', '行', '研', '討', '越', '來', '越', '多', '的', '基', '金', '公', '司', '重', '視', '量', '化', '交', '易', '全', '球', '規', '模', '較', '大', '的', '避', '險', '基', '金', '多', '採', '行', '量', '化', '交', '易', '包', '括', '橋', '水', '基', '金', '資', '產', '管', '理', '公', '司', '曼', '氏', '集', '團', '文', '藝', '復', '興', '科', '技', '等', '全', '球', '知', '名', '避', '險', '基', '金', '摩', '根', '亞', '太', '集', '團', '董', '事', '長', '張', '堯', '勇', '指', '出', '避', '險', '基', '金', '規', '模', '約', '為', '兆', '美', '元', '採', '取', '量', '化', '交', '易', '的', '基', '金', '規', '模', '約', '兆', '美', '元', '比', '重', '佔', '了', '代', '表', '量', '化', '交', '易', '的', '操', '作', '績', '效', '好', '才', '會', '有', '那', '麼', '高', '的', '比', '重', '量', '化', '交', '易', '的', '操', '作', '績', '效', '不', '亞', '於', '價', '值', '投', '資', '及', '技', '術', '投', '資', '被', '譽', '為', '數', '學', '天', '才', '最', '賺', '錢', '的', '基', '金', '經', '理', '人', '文', '藝', '復', '興', '對', '沖', '基', '金', '創', '始', '人', '詹', '姆', '斯', '西', '蒙', '斯', '所', '管', '理', '的', '大', '獎', '章', '基', '金', '便', '是', '典', '型', '的', '量', '化', '交', '易', '績', '效', '表', '現', '優', '異', '不', '僅', '勝', '過', '索', '羅', '斯', '的', '量', '子', '基', '金', '也', '打', '敗', '了', '股', '神', '巴', '菲', '特', '的', '價', '值', '投', '資', '近', '年', '來', '台', '灣', '也', '逐', '漸', '重', '視', '量', '化', '交', '易', '摩', '根', '亞', '太', '量', '化', '交', '易', '公', '司', '今', '年', '開', '始', '將', '量', '化', '交', '易', '引', '進', '台', '股', '投', '資', '是', '國', '內', '首', '家', '推', '出', '量', '化', '交', '易', '策', '略', '的', '公', '司', '初', '期', '對', '象', '鎖', '定', '法', '人', '機', '構', '進', '行', '私', '募', '投', '資', '張', '堯', '勇', '表', '示', '數', '學', '不', '只', '是', '一', '門', '學', '科', '更', '是', '一', '項', '扭', '轉', '乾', '坤', '轉', '敗', '為', '勝', '的', '競', '爭', '利', '器', '量', '化', '交', '易', '就', '是', '將', '數', '學', '運', '用', '在', '股', '市', '投', '資', '透', '過', '複', '雜', '精', '密', '的', '推', '理', '計', '算', '打', '敗', '股', '市', '他', '指', '出', '目', '前', '全', '球', '利', '率', '水', '平', '位', '於', '年', '來', '新', '低', '美', '國', '十', '年', '期', '公', '債', '殖', '利', '率', '只', '有', '日', '本', '及', '一', '些', '歐', '洲', '國', '家', '甚', '至', '是', '負', '利', '率', '歷', '史', '極', '低', '利', '率', '帶', '導', '致', '無', '風', '險', '及', '低', '風', '險', '工', '具', '的', '投', '資', '報', '酬', '率', '太', '低', '（', '例', '如', '：', '銀', '行', '存', '款', '政', '府', '公', '債', '及', '投', '資', '等', '級', '公', '司', '債', '）', '無', '法', '對', '抗', '通', '貨', '膨', '脹', '及', '支', '付', '負', '債', '所', '以', '資', '產', '配', '置', '必', '須', '增', '加', '較', '高', '風', '險', '的', '投', '資', '如', '股', '票', '高', '收', '益', '公', '司', '債', '或', '新', '興', '市', '場', '債', '券', '但', '是', '這', '些', '投', '資', '工', '具', '波', '動', '很', '大', '而', '且', '很', '容', '易', '產', '生', '虧', '損', '他', '表', '示', '長', '期', '來', '說', '股', '市', '絕', '對', '是', '好', '的', '投', '資', '報', '酬', '率', '也', '不', '差', '但', '是', '如', '何', '選', '股', '是', '一', '門', '學', '問', '目', '前', '全', '球', '個', '主', '要', '股', '市', '交', '易', '所', '總', '市', '值', '兆', '美', '元', '而', '台', '灣', '上', '市', '上', '櫃', '市', '值', '兆', '台', '幣', '面', '對', '全', '球', '及', '台', '灣', '最', '大', '的', '股', '市', '金', '礦', '投', '資', '人', '應', '該', '善', '用', '量', '化', '交', '易', '這', '個', '超', '級', '挖', '礦', '機', '以', '程', '式', '選', '股', '來', '掏', '金', '張', '堯', '勇', '指', '出', '量', '化', '投', '資', '具', '有', '低', '波', '動', '絕', '對', '報', '酬', '優', '於', '大', '盤', '的', '三', '大', '特', '點', '摩', '根', '亞', '太', '量', '化', '交', '易', '模', '擬', '台', '股', '近', '年', '來', '的', '績', '效', '結', '果', '顯', '示', '運', '用', '量', '化', '交', '易', '的', '年', '化', '報', '酬', '率', '及', '波', '動', '度', '均', '優', '於', '台', '股', '上', '市', '櫃', '指', '數', '以', '年', '金', '融', '海', '嘯', '及', '年', '中', '美', '貿', '易', '戰', '為', '例', '台', '股', '上', '市', '上', '櫃', '指', '數', '均', '是', '負', '報', '酬', '不', '過', '摩', '根', '量', '化', '交', '易', '卻', '是', '正', '報', '酬', '而', '且', '波', '動', '度', '也', '比', '較', '低', '此', '外', '由', '於', '台', '灣', '四', '大', '政', '府', '基', '金', '操', '作', '績', '效', '不', '彰', '不', '少', '金', '融', '機', '構', '也', '面', '臨', '投', '資', '虧', '損', '問', '題', '亦', '可', '透', '過', '量', '化', '交', '易', '提', '高', '投', '資', '報', '酬', '率', '張', '堯', '勇', '指', '出', '郵', '儲', '勞', '退', '勞', '保', '及', '退', '撫', '等', '四', '大', '基', '金', '總', '資', '產', '高', '達', '兆', '台', '幣', '但', '過', '去', '年', '的', '投', '資', '報', '酬', '率', '不', '到', '去', '年', '虧', '損', '億', '面', '臨', '提', '早', '破', '產', '的', '風', '險', '另', '外', '台', '灣', '保', '險', '公', '司', '的', '總', '資', '產', '高', '達', '兆', '台', '幣', '過', '去', '賣', '出', '去', '的', '保', '單', '利', '率', '高', '達', '但', '是', '去', '年', '的', '資', '產', '報', '酬', '率', '卻', '只', '不', '到', '而', '且', '去', '年', '綜', '合', '損', '益', '虧', '損', '高', '達', '億', '金', '管', '會', '連', '下', '三', '道', '金', '牌', '：', '所', '有', '保', '險', '公', '司', '今', '年', '不', '準', '發', '放', '現', '金', '股', '利', '部', '分', '保', '險', '公', '司', '必', '須', '儘', '快', '舉', '辦', '現', '金', '增', '資', '以', '後', '賣', '的', '保', '單', '利', '率', '必', '須', '下', '降', '另', '外', '台', '灣', '全', '體', '商', '業', '銀', '行', '也', '有', '高', '達', '兆', '的', '總', '資', '產', '兆', '但', '是', '其', '資', '產', '報', '酬', '率', '僅', '只', '有', '以', '上', '將', '近', '兆', '台', '幣', '的', '資', '金', '張', '堯', '勇', '指', '出', '若', '將', '投', '資', '於', '股', '市', '投', '資', '金', '額', '高', '達', '兆', '報', '酬', '率', '每', '增', '加', '就', '有', '億', '元', '的', '獲', '利', '對', '於', '台', '灣', '的', '國', '家', '財', '政', '或', '金', '融', '機', '構', '的', '獲', '利', '都', '有', '非', '常', '巨', '大', '的', '助', '益']\n",
            "Token IDs: [6818, 2399, 889, 2832, 6536, 2356, 1842, 3797, 1240, 6632, 889, 6632, 3209, 7549, 6841, 3724, 856, 3797, 1240, 5179, 2205, 1841, 6992, 4638, 7030, 1265, 769, 3211, 991, 1358, 3800, 4680, 2201, 2157, 6134, 4850, 2967, 4500, 7030, 1265, 769, 3211, 5032, 4526, 2832, 6536, 1378, 5500, 679, 5052, 3221, 5993, 3176, 1914, 7531, 2772, 3221, 4958, 7531, 2356, 1842, 5245, 3126, 1350, 3797, 1240, 2428, 1772, 1377, 7526, 6651, 1920, 4676, 4493, 5635, 3683, 1751, 1058, 2832, 6536, 1378, 5500, 4638, 5500, 4873, 1798, 1825, 7032, 1350, 4638, 3797, 1240, 4372, 6917, 856, 6134, 4412, 738, 3291, 4158, 4952, 2137, 1920, 3149, 3087, 3229, 807, 889, 5631, 7591, 6121, 3627, 5401, 2399, 4638, 7030, 1265, 769, 3211, 1035, 4197, 2768, 4158, 7549, 2119, 1378, 4124, 771, 7274, 1993, 7028, 6213, 3634, 671, 6638, 1248, 4634, 2245, 738, 1728, 3634, 704, 5836, 3582, 4372, 5186, 6243, 2119, 3298, 1350, 1378, 1266, 4906, 2825, 1920, 2119, 5052, 4415, 2119, 7368, 3108, 2797, 712, 6794, 699, 4507, 1039, 1920, 3309, 6515, 3040, 3418, 765, 1922, 7030, 1265, 769, 3211, 5023, 1062, 1385, 3085, 818, 1295, 6794, 1606, 855, 791, 3189, 5647, 6794, 3229, 7279, 2415, 1154, 5645, 7030, 1265, 769, 3211, 4777, 6245, 3298, 2218, 4680, 1184, 4229, 7271, 4638, 7030, 1265, 769, 3211, 3255, 5543, 2832, 6536, 5023, 4685, 7302, 6359, 7539, 6868, 6121, 4777, 6245, 6632, 889, 6632, 1914, 4638, 1825, 7032, 1062, 1385, 7028, 6213, 7030, 1265, 769, 3211, 1059, 4413, 6211, 3563, 6733, 1920, 4638, 6912, 7402, 1825, 7032, 1914, 2967, 6121, 7030, 1265, 769, 3211, 1259, 2886, 3578, 3717, 1825, 7032, 6536, 4496, 5052, 4415, 1062, 1385, 3294, 3694, 7415, 1757, 3152, 5971, 2541, 5646, 4906, 2825, 5023, 1059, 4413, 4761, 1399, 6912, 7402, 1825, 7032, 3040, 3418, 765, 1922, 7415, 1757, 5869, 752, 7269, 2484, 1839, 1235, 2900, 1139, 6912, 7402, 1825, 7032, 6211, 3563, 5147, 4158, 1042, 5401, 1039, 2967, 1357, 7030, 1265, 769, 3211, 4638, 1825, 7032, 6211, 3563, 5147, 1042, 5401, 1039, 3683, 7028, 861, 749, 807, 6134, 7030, 1265, 769, 3211, 4638, 3082, 868, 5245, 3126, 1962, 2798, 3298, 3300, 6929, 7938, 7770, 4638, 3683, 7028, 7030, 1265, 769, 3211, 4638, 3082, 868, 5245, 3126, 679, 765, 3176, 1019, 966, 2832, 6536, 1350, 2825, 6123, 2832, 6536, 6158, 6363, 4158, 3149, 2119, 1921, 2798, 3297, 6553, 7092, 4638, 1825, 7032, 5195, 4415, 782, 3152, 5971, 2541, 5646, 2205, 3762, 1825, 7032, 1201, 1993, 782, 6285, 1990, 3172, 6205, 5885, 3172, 2792, 5052, 4415, 4638, 1920, 4354, 4995, 1825, 7032, 912, 3221, 1073, 1798, 4638, 7030, 1265, 769, 3211, 5245, 3126, 6134, 4412, 1032, 4530, 679, 1006, 1245, 6882, 5164, 5397, 3172, 4638, 7030, 2094, 1825, 7032, 738, 2802, 3134, 749, 5500, 4868, 2349, 5838, 4294, 4638, 1019, 966, 2832, 6536, 6818, 2399, 889, 1378, 4124, 738, 6852, 4041, 7028, 6213, 7030, 1265, 769, 3211, 3040, 3418, 765, 1922, 7030, 1265, 769, 3211, 1062, 1385, 791, 2399, 7274, 1993, 2200, 7030, 1265, 769, 3211, 2471, 6868, 1378, 5500, 2832, 6536, 3221, 1751, 1058, 7674, 2157, 2972, 1139, 7030, 1265, 769, 3211, 5032, 4526, 4638, 1062, 1385, 1159, 3309, 2205, 6496, 7115, 2137, 3791, 782, 3582, 3539, 6868, 6121, 4900, 1247, 2832, 6536, 2484, 1839, 1235, 6134, 4850, 3149, 2119, 679, 1372, 3221, 671, 7271, 2119, 4906, 3291, 3221, 671, 7517, 2814, 6752, 746, 1787, 6752, 3134, 4158, 1245, 4638, 5000, 4261, 1164, 1690, 7030, 1265, 769, 3211, 2218, 3221, 2200, 3149, 2119, 6880, 4500, 1762, 5500, 2356, 2832, 6536, 6851, 6882, 6185, 7429, 5125, 2166, 4638, 2972, 4415, 6243, 5050, 2802, 3134, 5500, 2356, 800, 2900, 1139, 4680, 1184, 1059, 4413, 1164, 4372, 3717, 2398, 855, 3176, 2399, 889, 3173, 856, 5401, 1751, 1282, 2399, 3309, 1062, 1002, 3658, 1164, 4372, 1372, 3300, 3189, 3315, 1350, 671, 763, 3627, 3828, 1751, 2157, 4493, 5635, 3221, 6511, 1164, 4372, 3644, 1380, 3513, 856, 1164, 4372, 2380, 2206, 5636, 4192, 7591, 7402, 1350, 856, 7591, 7402, 2339, 1072, 4638, 2832, 6536, 1841, 6992, 4372, 1922, 856, 8020, 891, 1963, 8038, 7065, 6121, 2100, 3621, 3124, 2424, 1062, 1002, 1350, 2832, 6536, 5023, 5159, 1062, 1385, 1002, 8021, 4192, 3791, 2205, 2834, 6858, 6515, 5610, 5568, 1350, 3118, 802, 6511, 1002, 2792, 809, 6536, 4496, 6981, 5390, 2553, 7519, 1872, 1217, 6733, 7770, 7591, 7402, 4638, 2832, 6536, 1963, 5500, 4873, 7770, 3119, 4660, 1062, 1385, 1002, 2772, 3173, 5646, 2356, 1842, 1002, 1171, 852, 3221, 6857, 763, 2832, 6536, 2339, 1072, 3797, 1240, 2523, 1920, 5445, 684, 2523, 2159, 3211, 4496, 4495, 6000, 3010, 800, 6134, 4850, 7269, 3309, 889, 6303, 5500, 2356, 5179, 2205, 3221, 1962, 4638, 2832, 6536, 1841, 6992, 4372, 738, 679, 2345, 852, 3221, 1963, 862, 6908, 5500, 3221, 671, 7271, 2119, 1558, 4680, 1184, 1059, 4413, 943, 712, 6206, 5500, 2356, 769, 3211, 2792, 5244, 2356, 966, 1042, 5401, 1039, 5445, 1378, 4124, 677, 2356, 677, 3602, 2356, 966, 1042, 1378, 2395, 7481, 2205, 1059, 4413, 1350, 1378, 4124, 3297, 1920, 4638, 5500, 2356, 7032, 4846, 2832, 6536, 782, 2746, 6283, 1587, 4500, 7030, 1265, 769, 3211, 6857, 943, 6631, 5159, 2905, 4846, 3582, 809, 4923, 2466, 6908, 5500, 889, 2959, 7032, 2484, 1839, 1235, 2900, 1139, 7030, 1265, 2832, 6536, 1072, 3300, 856, 3797, 1240, 5179, 2205, 1841, 6992, 1032, 3176, 1920, 4676, 4638, 676, 1920, 4294, 7953, 3040, 3418, 765, 1922, 7030, 1265, 769, 3211, 3563, 3093, 1378, 5500, 6818, 2399, 889, 4638, 5245, 3126, 5178, 3362, 7549, 4850, 6880, 4500, 7030, 1265, 769, 3211, 4638, 2399, 1265, 1841, 6992, 4372, 1350, 3797, 1240, 2428, 1772, 1032, 3176, 1378, 5500, 677, 2356, 3602, 2900, 3149, 809, 2399, 7032, 6084, 3862, 1669, 1350, 2399, 704, 5401, 6530, 3211, 2782, 4158, 891, 1378, 5500, 677, 2356, 677, 3602, 2900, 3149, 1772, 3221, 6511, 1841, 6992, 679, 6882, 3040, 3418, 7030, 1265, 769, 3211, 1320, 3221, 3633, 1841, 6992, 5445, 684, 3797, 1240, 2428, 738, 3683, 6733, 856, 3634, 1912, 4507, 3176, 1378, 4124, 1724, 1920, 3124, 2424, 1825, 7032, 3082, 868, 5245, 3126, 679, 2511, 679, 2208, 7032, 6084, 3582, 3539, 738, 7481, 5631, 2832, 6536, 6000, 3010, 1558, 7539, 771, 1377, 6851, 6882, 7030, 1265, 769, 3211, 2990, 7770, 2832, 6536, 1841, 6992, 4372, 2484, 1839, 1235, 2900, 1139, 6960, 1033, 1246, 6842, 1246, 924, 1350, 6842, 3062, 5023, 1724, 1920, 1825, 7032, 5244, 6536, 4496, 7770, 6888, 1042, 1378, 2395, 852, 6882, 1343, 2399, 4638, 2832, 6536, 1841, 6992, 4372, 679, 1168, 1343, 2399, 6000, 3010, 1023, 7481, 5631, 2990, 3193, 4788, 4496, 4638, 7591, 7402, 1369, 1912, 1378, 4124, 924, 7402, 1062, 1385, 4638, 5244, 6536, 4496, 7770, 6888, 1042, 1378, 2395, 6882, 1343, 6546, 1139, 1343, 4638, 924, 1606, 1164, 4372, 7770, 6888, 852, 3221, 1343, 2399, 4638, 6536, 4496, 1841, 6992, 4372, 1320, 1372, 679, 1168, 5445, 684, 1343, 2399, 5198, 1394, 3010, 4660, 6000, 3010, 7770, 6888, 1023, 7032, 5052, 3298, 6865, 678, 676, 6887, 7032, 4277, 8038, 2792, 3300, 924, 7402, 1062, 1385, 791, 2399, 679, 3976, 4634, 3123, 4412, 7032, 5500, 1164, 6956, 1146, 924, 7402, 1062, 1385, 2553, 7519, 1029, 2571, 5647, 6794, 4412, 7032, 1872, 6536, 809, 2527, 6546, 4638, 924, 1606, 1164, 4372, 2553, 7519, 678, 7360, 1369, 1912, 1378, 4124, 1059, 7768, 1555, 3511, 7065, 6121, 738, 3300, 7770, 6888, 1042, 4638, 5244, 6536, 4496, 1042, 852, 3221, 1071, 6536, 4496, 1841, 6992, 4372, 1006, 1372, 3300, 809, 677, 2200, 6818, 1042, 1378, 2395, 4638, 6536, 7032, 2484, 1839, 1235, 2900, 1139, 5735, 2200, 2832, 6536, 3176, 5500, 2356, 2832, 6536, 7032, 7540, 7770, 6888, 1042, 1841, 6992, 4372, 3680, 1872, 1217, 2218, 3300, 1023, 1039, 4638, 4363, 1164, 2205, 3176, 1378, 4124, 4638, 1751, 2157, 6512, 3124, 2772, 7032, 6084, 3582, 3539, 4638, 4363, 1164, 6963, 3300, 7478, 2382, 2342, 1920, 4638, 1221, 4660]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ceBfeD2iKld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f28af68-4dfc-425b-ed72-8b67b55f8d79"
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " '近',\n",
              " '年',\n",
              " '來',\n",
              " '投',\n",
              " '資',\n",
              " '市',\n",
              " '場',\n",
              " '波',\n",
              " '動',\n",
              " '越',\n",
              " '來',\n",
              " '越',\n",
              " '明',\n",
              " '顯',\n",
              " '追',\n",
              " '求',\n",
              " '低',\n",
              " '波',\n",
              " '動',\n",
              " '絕',\n",
              " '對',\n",
              " '報',\n",
              " '酬',\n",
              " '的',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '備',\n",
              " '受',\n",
              " '注',\n",
              " '目',\n",
              " '專',\n",
              " '家',\n",
              " '表',\n",
              " '示',\n",
              " '採',\n",
              " '用',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '策',\n",
              " '略',\n",
              " '投',\n",
              " '資',\n",
              " '台',\n",
              " '股',\n",
              " '不',\n",
              " '管',\n",
              " '是',\n",
              " '處',\n",
              " '於',\n",
              " '多',\n",
              " '頭',\n",
              " '或',\n",
              " '是',\n",
              " '空',\n",
              " '頭',\n",
              " '市',\n",
              " '場',\n",
              " '績',\n",
              " '效',\n",
              " '及',\n",
              " '波',\n",
              " '動',\n",
              " '度',\n",
              " '均',\n",
              " '可',\n",
              " '領',\n",
              " '跑',\n",
              " '大',\n",
              " '盤',\n",
              " '甚',\n",
              " '至',\n",
              " '比',\n",
              " '國',\n",
              " '內',\n",
              " '投',\n",
              " '資',\n",
              " '台',\n",
              " '股',\n",
              " '的',\n",
              " '股',\n",
              " '票',\n",
              " '型',\n",
              " '基',\n",
              " '金',\n",
              " '及',\n",
              " '的',\n",
              " '波',\n",
              " '動',\n",
              " '率',\n",
              " '還',\n",
              " '低',\n",
              " '表',\n",
              " '現',\n",
              " '也',\n",
              " '更',\n",
              " '為',\n",
              " '穩',\n",
              " '定',\n",
              " '大',\n",
              " '數',\n",
              " '據',\n",
              " '時',\n",
              " '代',\n",
              " '來',\n",
              " '臨',\n",
              " '風',\n",
              " '行',\n",
              " '歐',\n",
              " '美',\n",
              " '年',\n",
              " '的',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '儼',\n",
              " '然',\n",
              " '成',\n",
              " '為',\n",
              " '顯',\n",
              " '學',\n",
              " '台',\n",
              " '灣',\n",
              " '亦',\n",
              " '開',\n",
              " '始',\n",
              " '重',\n",
              " '視',\n",
              " '此',\n",
              " '一',\n",
              " '趨',\n",
              " '勢',\n",
              " '發',\n",
              " '展',\n",
              " '也',\n",
              " '因',\n",
              " '此',\n",
              " '中',\n",
              " '華',\n",
              " '機',\n",
              " '率',\n",
              " '統',\n",
              " '計',\n",
              " '學',\n",
              " '會',\n",
              " '及',\n",
              " '台',\n",
              " '北',\n",
              " '科',\n",
              " '技',\n",
              " '大',\n",
              " '學',\n",
              " '管',\n",
              " '理',\n",
              " '學',\n",
              " '院',\n",
              " '攜',\n",
              " '手',\n",
              " '主',\n",
              " '辦',\n",
              " '並',\n",
              " '由',\n",
              " '元',\n",
              " '大',\n",
              " '期',\n",
              " '貨',\n",
              " '摩',\n",
              " '根',\n",
              " '亞',\n",
              " '太',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '等',\n",
              " '公',\n",
              " '司',\n",
              " '擔',\n",
              " '任',\n",
              " '協',\n",
              " '辦',\n",
              " '單',\n",
              " '位',\n",
              " '今',\n",
              " '日',\n",
              " '舉',\n",
              " '辦',\n",
              " '時',\n",
              " '間',\n",
              " '序',\n",
              " '列',\n",
              " '與',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '研',\n",
              " '討',\n",
              " '會',\n",
              " '就',\n",
              " '目',\n",
              " '前',\n",
              " '熱',\n",
              " '門',\n",
              " '的',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '智',\n",
              " '能',\n",
              " '投',\n",
              " '資',\n",
              " '等',\n",
              " '相',\n",
              " '關',\n",
              " '議',\n",
              " '題',\n",
              " '進',\n",
              " '行',\n",
              " '研',\n",
              " '討',\n",
              " '越',\n",
              " '來',\n",
              " '越',\n",
              " '多',\n",
              " '的',\n",
              " '基',\n",
              " '金',\n",
              " '公',\n",
              " '司',\n",
              " '重',\n",
              " '視',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '全',\n",
              " '球',\n",
              " '規',\n",
              " '模',\n",
              " '較',\n",
              " '大',\n",
              " '的',\n",
              " '避',\n",
              " '險',\n",
              " '基',\n",
              " '金',\n",
              " '多',\n",
              " '採',\n",
              " '行',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '包',\n",
              " '括',\n",
              " '橋',\n",
              " '水',\n",
              " '基',\n",
              " '金',\n",
              " '資',\n",
              " '產',\n",
              " '管',\n",
              " '理',\n",
              " '公',\n",
              " '司',\n",
              " '曼',\n",
              " '氏',\n",
              " '集',\n",
              " '團',\n",
              " '文',\n",
              " '藝',\n",
              " '復',\n",
              " '興',\n",
              " '科',\n",
              " '技',\n",
              " '等',\n",
              " '全',\n",
              " '球',\n",
              " '知',\n",
              " '名',\n",
              " '避',\n",
              " '險',\n",
              " '基',\n",
              " '金',\n",
              " '摩',\n",
              " '根',\n",
              " '亞',\n",
              " '太',\n",
              " '集',\n",
              " '團',\n",
              " '董',\n",
              " '事',\n",
              " '長',\n",
              " '張',\n",
              " '堯',\n",
              " '勇',\n",
              " '指',\n",
              " '出',\n",
              " '避',\n",
              " '險',\n",
              " '基',\n",
              " '金',\n",
              " '規',\n",
              " '模',\n",
              " '約',\n",
              " '為',\n",
              " '兆',\n",
              " '美',\n",
              " '元',\n",
              " '採',\n",
              " '取',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '的',\n",
              " '基',\n",
              " '金',\n",
              " '規',\n",
              " '模',\n",
              " '約',\n",
              " '兆',\n",
              " '美',\n",
              " '元',\n",
              " '比',\n",
              " '重',\n",
              " '佔',\n",
              " '了',\n",
              " '代',\n",
              " '表',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '的',\n",
              " '操',\n",
              " '作',\n",
              " '績',\n",
              " '效',\n",
              " '好',\n",
              " '才',\n",
              " '會',\n",
              " '有',\n",
              " '那',\n",
              " '麼',\n",
              " '高',\n",
              " '的',\n",
              " '比',\n",
              " '重',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '的',\n",
              " '操',\n",
              " '作',\n",
              " '績',\n",
              " '效',\n",
              " '不',\n",
              " '亞',\n",
              " '於',\n",
              " '價',\n",
              " '值',\n",
              " '投',\n",
              " '資',\n",
              " '及',\n",
              " '技',\n",
              " '術',\n",
              " '投',\n",
              " '資',\n",
              " '被',\n",
              " '譽',\n",
              " '為',\n",
              " '數',\n",
              " '學',\n",
              " '天',\n",
              " '才',\n",
              " '最',\n",
              " '賺',\n",
              " '錢',\n",
              " '的',\n",
              " '基',\n",
              " '金',\n",
              " '經',\n",
              " '理',\n",
              " '人',\n",
              " '文',\n",
              " '藝',\n",
              " '復',\n",
              " '興',\n",
              " '對',\n",
              " '沖',\n",
              " '基',\n",
              " '金',\n",
              " '創',\n",
              " '始',\n",
              " '人',\n",
              " '詹',\n",
              " '姆',\n",
              " '斯',\n",
              " '西',\n",
              " '蒙',\n",
              " '斯',\n",
              " '所',\n",
              " '管',\n",
              " '理',\n",
              " '的',\n",
              " '大',\n",
              " '獎',\n",
              " '章',\n",
              " '基',\n",
              " '金',\n",
              " '便',\n",
              " '是',\n",
              " '典',\n",
              " '型',\n",
              " '的',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '績',\n",
              " '效',\n",
              " '表',\n",
              " '現',\n",
              " '優',\n",
              " '異',\n",
              " '不',\n",
              " '僅',\n",
              " '勝',\n",
              " '過',\n",
              " '索',\n",
              " '羅',\n",
              " '斯',\n",
              " '的',\n",
              " '量',\n",
              " '子',\n",
              " '基',\n",
              " '金',\n",
              " '也',\n",
              " '打',\n",
              " '敗',\n",
              " '了',\n",
              " '股',\n",
              " '神',\n",
              " '巴',\n",
              " '菲',\n",
              " '特',\n",
              " '的',\n",
              " '價',\n",
              " '值',\n",
              " '投',\n",
              " '資',\n",
              " '近',\n",
              " '年',\n",
              " '來',\n",
              " '台',\n",
              " '灣',\n",
              " '也',\n",
              " '逐',\n",
              " '漸',\n",
              " '重',\n",
              " '視',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '摩',\n",
              " '根',\n",
              " '亞',\n",
              " '太',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '公',\n",
              " '司',\n",
              " '今',\n",
              " '年',\n",
              " '開',\n",
              " '始',\n",
              " '將',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '引',\n",
              " '進',\n",
              " '台',\n",
              " '股',\n",
              " '投',\n",
              " '資',\n",
              " '是',\n",
              " '國',\n",
              " '內',\n",
              " '首',\n",
              " '家',\n",
              " '推',\n",
              " '出',\n",
              " '量',\n",
              " '化',\n",
              " '交',\n",
              " '易',\n",
              " '策',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY80wtG5iVqc"
      },
      "source": [
        "class NewsDataset(Dataset):\n",
        "\n",
        "  def __init__(self, newscontent, targets, tokenizer, max_len):\n",
        "    self.newscontent = newscontent\n",
        "    self.targets = targets\n",
        "    print('i am targets',targets)\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.newscontent)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    newscontent= str(self.newscontent[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      newscontent,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': newscontent,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgYj9J2akGWF"
      },
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zgW5eM1kKHz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "213686f8-9287-45af-a578-8ee5838f028b"
      },
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2322, 8), (129, 8), (130, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ykKQgQkWcg"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = NewsDataset(\n",
        "    newscontent=df.content.to_numpy(),\n",
        "    targets=df.label.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o_PAM9UlE6P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1320306f-551f-42d4-a166-a5b257a73fc1"
      },
      "source": [
        "BATCH_SIZE = 1\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, 512, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, 512, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, 512, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i am targets [0 0 0 ... 0 0 1]\n",
            "i am targets [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0\n",
            " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "i am targets [0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
            " 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKJxJMiOlF7D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43863bf8-aafd-4cb9-bb1c-eb3d472cf2f4"
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4uwoWaslWFm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6d8f7388-fd05-46ba-f658-c59a0d42f357"
      },
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512])\n",
            "torch.Size([1, 512])\n",
            "torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XiP5xn7mABQ"
      },
      "source": [
        "##NEWS Classification with BERT and Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Had4pulbIT"
      },
      "source": [
        "bert_model1 = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "bert_model2 = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL4zj61amb40"
      },
      "source": [
        "outputs = bert_model2(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-UB2EPCpk6O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45e7aeda-683d-44e3-aea9-c784a0285037"
      },
      "source": [
        "print(outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[[ 0.5648,  0.1388, -0.6515,  ..., -0.5112, -0.6760, -0.0739],\n",
            "         [-0.3625,  0.4070, -1.2115,  ...,  0.0940, -1.0135,  0.1630],\n",
            "         [-0.5314,  0.4980, -0.1927,  ..., -0.0341, -0.4551,  0.0627],\n",
            "         ...,\n",
            "         [-0.0334,  0.3563, -0.9973,  ...,  1.4913,  0.7195,  0.4206],\n",
            "         [ 0.1578,  1.2715, -0.6179,  ...,  0.6072,  0.0866,  0.3967],\n",
            "         [-0.0420,  0.7808,  0.3107,  ...,  0.8388,  0.2968,  0.0500]]],\n",
            "       grad_fn=<NativeLayerNormBackward>), tensor([[ 0.9996, -0.3177,  1.0000, -0.9905, -0.9354, -0.8747,  0.9397,  0.9141,\n",
            "         -0.9022, -0.9994,  1.0000,  1.0000,  0.1843,  0.5923,  0.9995, -0.9986,\n",
            "          0.9492, -0.2187,  0.4035, -0.0708, -0.9002, -0.9996,  0.3842, -0.9996,\n",
            "         -0.8410,  0.9954,  0.7630, -0.5186, -0.3984,  1.0000,  0.9943,  1.0000,\n",
            "          0.7514,  0.4991, -0.9940,  0.5474, -0.5412,  0.9847,  0.5106,  0.9815,\n",
            "         -0.5325,  0.8732, -0.9903, -0.9993,  0.6814,  0.9920, -1.0000,  0.3276,\n",
            "         -0.7846, -0.8628,  0.4532, -0.9764,  1.0000, -1.0000, -0.6567,  0.9948,\n",
            "         -0.4878,  0.9985,  1.0000, -0.7718,  1.0000,  0.9945, -0.9872, -0.9948,\n",
            "          0.9998, -0.9951, -0.9810, -0.9963, -0.5460,  0.9999, -1.0000, -0.7994,\n",
            "          1.0000, -0.9950, -0.1860,  1.0000, -0.9854,  0.8989, -0.9998,  0.3704,\n",
            "          1.0000,  0.8004, -0.9030, -0.9542, -0.7322, -0.9999,  0.9944,  0.9620,\n",
            "          0.9882,  0.0550, -0.8314, -0.9994, -1.0000,  0.9973, -0.9993,  0.6448,\n",
            "          0.9935,  0.9876,  0.9989, -0.9999, -0.2442,  0.4225, -1.0000, -1.0000,\n",
            "         -0.8277,  0.9997,  0.9847, -0.9992,  0.9940, -0.9808, -1.0000, -0.9239,\n",
            "         -1.0000,  0.1553, -0.9961,  0.9999,  0.7858,  0.9985,  1.0000, -1.0000,\n",
            "          0.9956,  0.2617,  0.8808,  0.8059,  0.9677,  0.9996,  0.9999,  0.9632,\n",
            "          1.0000,  1.0000,  0.9287,  0.9652, -0.9998,  0.8508, -0.9781,  0.9908,\n",
            "         -0.9647,  0.0186,  1.0000,  0.9153,  0.9924,  0.9727, -0.3894, -0.9922,\n",
            "          0.9997, -0.9997,  0.9995, -1.0000, -0.5942, -0.8173, -0.9292,  1.0000,\n",
            "          0.9915, -0.1215,  0.6128,  0.8178, -0.4527, -1.0000, -0.9719, -0.9999,\n",
            "         -0.9054, -0.9037,  0.1872, -0.4054, -1.0000,  1.0000, -0.8282,  0.9998,\n",
            "          0.9840,  0.9872, -0.9999, -0.9283,  0.2142, -0.9999,  0.9993,  0.9923,\n",
            "         -0.1672,  0.9994,  0.9845, -0.9998, -0.6617,  0.5865,  0.4741,  0.9809,\n",
            "         -0.6359, -0.9868, -0.9997,  0.9993,  0.5735, -0.9432, -0.9976,  1.0000,\n",
            "          0.8545,  0.9989,  0.9984,  0.1445,  0.9997,  0.9831, -0.9991, -0.8413,\n",
            "          0.3858, -0.9176, -1.0000, -0.1981, -0.9996,  0.1473,  0.9995,  0.9985,\n",
            "         -0.3495, -0.9987,  0.9964, -0.3239, -0.9999, -0.8787,  0.9177,  0.3851,\n",
            "          0.2522, -0.5205, -0.6820, -0.9999,  0.9063, -0.9773,  0.6804, -0.3796,\n",
            "         -0.8708,  1.0000, -0.9945,  0.9999,  0.9871, -0.9816, -1.0000,  1.0000,\n",
            "         -0.9066, -1.0000, -0.9330,  0.4933,  0.9940,  0.9999, -0.9990, -0.9655,\n",
            "          1.0000, -0.9548,  1.0000,  0.9981, -0.9969, -0.9986,  1.0000,  0.9940,\n",
            "          0.9996, -0.9887,  0.7039, -0.9686,  0.9968, -1.0000,  0.8774,  0.6569,\n",
            "          0.9954,  0.9992, -0.9935, -0.9791,  0.9092, -0.9999,  1.0000,  0.9787,\n",
            "          0.9987,  0.9999,  0.8006,  0.7420,  0.2617,  0.9938, -0.9960,  0.9038,\n",
            "          0.2141, -0.6190, -0.9999, -0.9377, -0.9965, -1.0000,  0.3732,  1.0000,\n",
            "          0.9992,  0.2184,  0.9998, -0.7782,  0.9905, -0.9025,  0.9764, -1.0000,\n",
            "          1.0000, -0.9972,  0.8947, -0.9997, -0.9999,  0.4649, -0.1120,  0.9936,\n",
            "         -1.0000,  0.2817, -0.9980,  0.8642, -0.2466, -0.9995,  0.9252, -0.9119,\n",
            "         -0.9998,  0.8922, -0.7507,  0.9162, -0.9914, -0.8617,  1.0000, -0.8219,\n",
            "          1.0000, -0.9614,  1.0000, -0.9699, -0.9516,  0.8229, -0.9566,  0.4605,\n",
            "         -0.2190, -0.7688,  0.9860,  0.8586,  0.3255, -0.9976, -0.8568, -0.6092,\n",
            "          0.5793, -0.0625,  0.9843, -0.6371,  0.5866, -0.9872,  0.9998, -0.9999,\n",
            "         -0.7035,  0.9999,  0.9998, -0.3576,  0.8079, -0.9414, -0.9977, -1.0000,\n",
            "          0.9982, -0.9992,  0.9983,  0.9307, -0.8592, -0.8862, -0.9828,  1.0000,\n",
            "         -0.6016,  0.3204,  0.8631,  0.9631, -0.8924,  0.1520, -0.9916,  0.9961,\n",
            "          0.9403,  0.9991, -1.0000, -1.0000,  0.9973, -0.9999, -0.9998, -1.0000,\n",
            "         -0.8161, -0.9620, -0.9980,  0.8232, -0.3144, -0.3324,  0.8039,  0.6104,\n",
            "          0.9862,  0.7346,  0.5812,  0.7146, -0.9177, -0.9999, -0.9936, -1.0000,\n",
            "         -0.9977,  0.8973, -0.5177, -0.0837,  1.0000, -1.0000, -0.8816,  0.6296,\n",
            "          0.9253,  0.9193,  0.9919,  0.7380,  1.0000,  0.5919,  1.0000,  0.9995,\n",
            "         -0.0470, -1.0000, -0.9962,  0.8862,  0.5281, -0.9999, -0.9571,  0.9785,\n",
            "          0.9346, -1.0000,  0.4530,  0.9707,  1.0000,  0.9773, -0.9996,  0.6608,\n",
            "         -1.0000,  0.3681,  1.0000,  0.9794, -1.0000, -0.8146, -0.4574,  1.0000,\n",
            "          0.5116, -0.5913, -0.9262, -0.3440,  0.9757, -0.9996, -0.9804,  1.0000,\n",
            "         -0.8470, -1.0000, -0.3350, -0.4208,  0.2392, -0.6450,  0.9670,  0.9681,\n",
            "         -0.0319, -0.9905, -1.0000,  0.7599,  0.9507,  0.9774,  0.9996, -0.8223,\n",
            "         -0.3562, -0.8721, -0.9968, -0.3856,  0.5964, -0.9991,  0.9999, -0.9991,\n",
            "          0.5346, -1.0000,  0.9998,  0.7557, -0.7558, -0.9600,  0.9946,  0.9588,\n",
            "          0.9903,  0.9999,  1.0000,  0.9401,  0.4613, -0.9997, -0.9918, -0.9317,\n",
            "         -0.7077, -0.9978, -0.9875, -0.9998, -0.6178,  0.2934,  1.0000, -0.2345,\n",
            "         -0.0135,  0.0399, -0.9994,  1.0000,  0.7251,  0.6481,  0.4226, -1.0000,\n",
            "         -0.9868,  0.7046, -0.8319,  0.8896, -0.1976, -0.9861,  0.9887,  0.5087,\n",
            "         -0.9974,  0.7067,  0.9770,  0.9912,  1.0000,  0.8105,  0.9987, -0.9905,\n",
            "         -0.1915, -0.1391,  0.8516,  0.9355,  0.9166,  0.6673, -0.9110,  0.6725,\n",
            "         -0.9470,  1.0000,  0.9944, -0.4614,  1.0000,  0.9757,  0.9986,  0.6690,\n",
            "         -0.6963,  0.6323,  0.9998, -0.9593, -0.9595, -0.8875,  0.9857,  1.0000,\n",
            "          0.0623, -0.2308, -0.5317, -0.2856, -0.2981, -0.9191,  1.0000,  0.9988,\n",
            "          0.0483, -0.9735,  0.2574, -0.5590,  1.0000,  0.6640,  0.9997,  0.9970,\n",
            "         -0.9983,  0.1024,  0.9188,  0.9910,  0.3872, -0.2616,  1.0000, -0.9995,\n",
            "         -0.9999, -1.0000,  1.0000,  0.9844,  0.7844, -1.0000,  1.0000,  0.4042,\n",
            "          0.5964,  1.0000, -0.9962,  0.9238, -0.3059, -0.9978,  0.5114,  0.8821,\n",
            "          0.9854, -0.6829,  1.0000, -0.9978, -0.8729,  1.0000,  0.9963,  0.1980,\n",
            "          0.5335, -0.6930, -0.9501,  0.9068, -0.9998, -0.9998, -0.3352,  0.9995,\n",
            "         -0.9986,  0.9620,  0.9993,  0.6823,  1.0000, -0.9999,  1.0000, -0.9494,\n",
            "          0.9998, -0.2210, -0.9951,  0.5771, -0.9788, -0.9989, -0.7842,  1.0000,\n",
            "          0.9757,  0.9976,  0.9779,  0.9722, -0.1289, -0.9802,  0.9997,  0.0398,\n",
            "          0.9979,  0.9440,  0.8563,  0.4648,  0.2219,  0.9924,  0.9768, -0.9344,\n",
            "          0.9999,  0.5331, -1.0000, -0.7253, -0.9999, -0.9640,  0.7899, -0.9232,\n",
            "         -0.1618, -1.0000,  0.5618, -0.6422, -1.0000,  0.9776, -0.6332,  0.2979,\n",
            "          0.4069,  0.9963, -0.9849, -0.2704, -0.6579,  0.4367,  0.7810,  0.9625,\n",
            "          0.0833, -1.0000,  0.8373,  0.9994, -1.0000,  0.5552, -0.9999,  1.0000,\n",
            "         -0.3746,  0.2634,  0.8082, -0.9570,  0.8755,  0.5457, -0.9997,  0.6554,\n",
            "         -0.9234, -0.1575, -0.9992, -1.0000,  0.0607, -0.9999, -0.3170,  0.4672,\n",
            "          0.9656, -0.7651,  0.9999,  1.0000, -0.9992, -0.9993, -1.0000,  0.9784,\n",
            "          0.9998,  0.9995,  0.9999,  0.9975, -0.9823,  0.9999,  0.3009,  0.9956,\n",
            "         -0.9960, -1.0000,  0.0942,  0.9426, -0.9520,  0.6920, -0.1552,  0.3778,\n",
            "         -0.5135, -1.0000, -0.6534,  0.2996,  1.0000,  0.9999, -0.9997,  0.9998,\n",
            "         -0.9996, -0.0924, -0.9914,  1.0000, -0.9999,  0.9998,  1.0000,  0.6224,\n",
            "          1.0000, -0.9999, -0.9948, -0.9600, -0.9862,  0.9850, -0.8280, -0.9999,\n",
            "         -0.0473,  1.0000,  0.7921,  1.0000,  0.9934,  0.9944,  0.2920, -0.9704,\n",
            "         -0.7964, -0.8845, -1.0000, -0.9337,  0.8680, -0.7973,  0.9999,  0.9484,\n",
            "         -0.1758, -0.9999, -0.9911, -0.9558, -0.8795,  0.1133, -0.0177,  0.9999,\n",
            "          1.0000, -0.3914, -0.7288,  0.1106,  0.8450, -0.1971,  0.9617,  0.8489,\n",
            "         -0.3597, -0.9966,  0.9982, -1.0000,  0.7665,  0.9865, -0.6781, -0.0189,\n",
            "          0.9538,  0.9955, -1.0000,  1.0000,  0.9139,  0.8403,  1.0000,  0.9994,\n",
            "         -0.9994,  0.9998,  0.3268, -0.9998,  0.2471, -1.0000, -0.9945,  0.5661]],\n",
            "       grad_fn=<TanhBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhS77vG0rFkf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "3e85a3ed-4a08-420d-bfd8-42f6ef3acf0c"
      },
      "source": [
        "np.array(label)\n",
        "print(encoding['input_ids'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 101, 6818, 2399,  889, 2832, 6536, 2356, 1842, 3797, 1240, 6632,  889,\n",
            "         6632, 3209, 7549, 6841, 3724,  856, 3797, 1240, 5179, 2205, 1841, 6992,\n",
            "         4638, 7030, 1265,  769, 3211,  991, 1358, 3800, 4680, 2201, 2157, 6134,\n",
            "         4850, 2967, 4500, 7030, 1265,  769, 3211, 5032, 4526, 2832, 6536, 1378,\n",
            "         5500,  679, 5052, 3221, 5993, 3176, 1914, 7531, 2772, 3221, 4958, 7531,\n",
            "         2356, 1842, 5245, 3126, 1350, 3797, 1240, 2428, 1772, 1377, 7526, 6651,\n",
            "         1920, 4676, 4493, 5635, 3683, 1751, 1058, 2832, 6536, 1378, 5500, 4638,\n",
            "         5500, 4873, 1798, 1825, 7032, 1350, 4638, 3797, 1240, 4372, 6917,  856,\n",
            "         6134, 4412,  738, 3291, 4158, 4952, 2137, 1920, 3149, 3087, 3229,  807,\n",
            "          889, 5631, 7591, 6121, 3627, 5401, 2399, 4638, 7030, 1265,  769, 3211,\n",
            "         1035, 4197, 2768, 4158, 7549, 2119, 1378, 4124,  771, 7274, 1993, 7028,\n",
            "         6213, 3634,  671, 6638, 1248, 4634, 2245,  738, 1728, 3634,  704, 5836,\n",
            "         3582, 4372, 5186, 6243, 2119, 3298, 1350, 1378, 1266, 4906, 2825, 1920,\n",
            "         2119, 5052, 4415, 2119, 7368, 3108, 2797,  712, 6794,  699, 4507, 1039,\n",
            "         1920, 3309, 6515, 3040, 3418,  765, 1922, 7030, 1265,  769, 3211, 5023,\n",
            "         1062, 1385, 3085,  818, 1295, 6794, 1606,  855,  791, 3189, 5647, 6794,\n",
            "         3229, 7279, 2415, 1154, 5645, 7030, 1265,  769, 3211, 4777, 6245, 3298,\n",
            "         2218, 4680, 1184, 4229, 7271, 4638, 7030, 1265,  769, 3211, 3255, 5543,\n",
            "         2832, 6536, 5023, 4685, 7302, 6359, 7539, 6868, 6121, 4777, 6245, 6632,\n",
            "          889, 6632, 1914, 4638, 1825, 7032, 1062, 1385, 7028, 6213, 7030, 1265,\n",
            "          769, 3211, 1059, 4413, 6211, 3563, 6733, 1920, 4638, 6912, 7402, 1825,\n",
            "         7032, 1914, 2967, 6121, 7030, 1265,  769, 3211, 1259, 2886, 3578, 3717,\n",
            "         1825, 7032, 6536, 4496, 5052, 4415, 1062, 1385, 3294, 3694, 7415, 1757,\n",
            "         3152, 5971, 2541, 5646, 4906, 2825, 5023, 1059, 4413, 4761, 1399, 6912,\n",
            "         7402, 1825, 7032, 3040, 3418,  765, 1922, 7415, 1757, 5869,  752, 7269,\n",
            "         2484, 1839, 1235, 2900, 1139, 6912, 7402, 1825, 7032, 6211, 3563, 5147,\n",
            "         4158, 1042, 5401, 1039, 2967, 1357, 7030, 1265,  769, 3211, 4638, 1825,\n",
            "         7032, 6211, 3563, 5147, 1042, 5401, 1039, 3683, 7028,  861,  749,  807,\n",
            "         6134, 7030, 1265,  769, 3211, 4638, 3082,  868, 5245, 3126, 1962, 2798,\n",
            "         3298, 3300, 6929, 7938, 7770, 4638, 3683, 7028, 7030, 1265,  769, 3211,\n",
            "         4638, 3082,  868, 5245, 3126,  679,  765, 3176, 1019,  966, 2832, 6536,\n",
            "         1350, 2825, 6123, 2832, 6536, 6158, 6363, 4158, 3149, 2119, 1921, 2798,\n",
            "         3297, 6553, 7092, 4638, 1825, 7032, 5195, 4415,  782, 3152, 5971, 2541,\n",
            "         5646, 2205, 3762, 1825, 7032, 1201, 1993,  782, 6285, 1990, 3172, 6205,\n",
            "         5885, 3172, 2792, 5052, 4415, 4638, 1920, 4354, 4995, 1825, 7032,  912,\n",
            "         3221, 1073, 1798, 4638, 7030, 1265,  769, 3211, 5245, 3126, 6134, 4412,\n",
            "         1032, 4530,  679, 1006, 1245, 6882, 5164, 5397, 3172, 4638, 7030, 2094,\n",
            "         1825, 7032,  738, 2802, 3134,  749, 5500, 4868, 2349, 5838, 4294, 4638,\n",
            "         1019,  966, 2832, 6536, 6818, 2399,  889, 1378, 4124,  738, 6852, 4041,\n",
            "         7028, 6213, 7030, 1265,  769, 3211, 3040, 3418,  765, 1922, 7030, 1265,\n",
            "          769, 3211, 1062, 1385,  791, 2399, 7274, 1993, 2200, 7030, 1265,  769,\n",
            "         3211, 2471, 6868, 1378, 5500, 2832, 6536, 3221, 1751, 1058, 7674, 2157,\n",
            "         2972, 1139, 7030, 1265,  769, 3211, 5032,  102]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnzcKei5nXuM"
      },
      "source": [
        "output = bert_model1(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  labels=torch.tensor(label),\n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3XMll3E1WwW"
      },
      "source": [
        "def train(data_loader,EPOCHS,model,n_example,is_slide =True):\n",
        "  \n",
        "  model.train()\n",
        "  total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model.to(device)\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "      correct_predictions = 0\n",
        "\n",
        "      \n",
        "      running_loss = 0.0\n",
        "      for idx in data_loader:\n",
        "          print(idx)\n",
        "          input_ids = idx[\"input_ids\"].to(device)\n",
        "          attention_mask = idx[\"attention_mask\"].to(device)\n",
        "          targets = torch.tensor(idx[\"targets\"]).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(input_ids=input_ids, labels=targets,attention_mask=attention_mask)\n",
        "\n",
        "          loss = outputs[0]\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          _, preds = torch.max(outputs[1], dim=1)\n",
        "          correct_predictions += torch.sum(preds == targets)\n",
        "\n",
        "          print(preds)\n",
        "          print(targets)\n",
        "\n",
        "\n",
        "          running_loss += loss.item()\n",
        "      #torch.save(model.state_dict(), '/content/drive/My Drive/DataSet/Tbrain_AI/best_model_state1.bin')\n",
        "  return correct_predictions.double() / n_example\n",
        "         # break\n",
        "\n",
        "      #print('[epoch %d] loss: %.3f, acc: %.3f' %\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4Adkn8ZESIl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "31c15bba-f2ee-4e98-8a8d-99a26a12aa9e"
      },
      "source": [
        " train_acc = train(train_data_loader,5,bert_model1,len(df_train) ,is_slide=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'review_text': ['今年引爆話題的神劇大叔之愛第一季將於月在上線讓粉絲敲碗等待的第二季也將於月上線大叔之愛的故事背景是天空不動產株式會社到了大叔之愛則成了天空航空公司雖然都是天空這次要更上一層樓直達雲霄故事會接續電影版的結尾天空不動產職員的春田在經歷裁員後到了天空航空擔任空服員而從天空不動產就在追求他的前輩黑澤搖身一變成為天空航空的機師大家一邊搭飛機一邊展開愛的追求其他的角色也都會登場只是一樣都換了工作這種幾乎是重新開機故事砍掉重來的創意到底會有怎樣的發展完全勾起觀眾的好奇大叔之愛系列的兩位主要演員田中圭吉田鋼太郎也特別換上大叔之愛的空服員與機師的制服跟台灣的粉絲喊話在全球掀起收視熱潮的酷男的異想世界前進日本錄製了 酷男的異想世界：日本我來啦日版的節目除了介紹體驗當地文化美食與設計還會加入知名女星水原希子與五位主持人一起協助四位日本素人進行改造計畫此外大家熟悉的渡邊直美也會以特別嘉賓的身份加入主持陣容協助素人大變身'], 'input_ids': tensor([[ 101,  791, 2399, 2471, 4255, 6282, 7539, 4638, 4868, 1206, 1920, 1356,\n",
            "          722, 2695, 5018,  671, 2108, 2200, 3176, 3299, 1762,  677, 5221, 6366,\n",
            "         5106, 5187, 3145, 4813, 5023, 2521, 4638, 5018,  753, 2108,  738, 2200,\n",
            "         3176, 3299,  677, 5221, 1920, 1356,  722, 2695, 4638, 3125,  752, 5520,\n",
            "         3250, 3221, 1921, 4958,  679, 1240, 4496, 3415, 2466, 3298, 4852, 1168,\n",
            "          749, 1920, 1356,  722, 2695, 1179, 2768,  749, 1921, 4958, 5661, 4958,\n",
            "         1062, 1385, 7426, 4197, 6963, 3221, 1921, 4958, 6857, 3613, 6206, 3291,\n",
            "          677,  671, 2251, 3559, 4684, 6888, 7437, 7446, 3125,  752, 3298, 2970,\n",
            "         5265, 7442, 2512, 4276, 4638, 5178, 2227, 1921, 4958,  679, 1240, 4496,\n",
            "         5480, 1519, 4638, 3217, 4506, 1762, 5195, 3644, 6161, 1519, 2527, 1168,\n",
            "          749, 1921, 4958, 5661, 4958, 3085,  818, 4958, 3302, 1519, 5445, 2537,\n",
            "         1921, 4958,  679, 1240, 4496, 2218, 1762, 6841, 3724,  800, 4638, 1184,\n",
            "         6742, 7946, 4075, 3015, 6716,  671, 6365, 2768, 4158, 1921, 4958, 5661,\n",
            "         4958, 4638, 3582, 2374, 1920, 2157,  671, 6920, 3022, 7606, 3582,  671,\n",
            "         6920, 2245, 7274, 2695, 4638, 6841, 3724, 1071,  800, 4638, 6235, 5682,\n",
            "          738, 6963, 3298, 4633, 1842, 1372, 3221,  671, 3564, 6963, 2994,  749,\n",
            "         2339,  868, 6857, 4934, 2407,  725, 3221, 7028, 3173, 7274, 3582, 3125,\n",
            "          752, 4775, 2957, 7028,  889, 4638, 1201, 2692, 1168, 2419, 3298, 3300,\n",
            "         2582, 3564, 4638, 4634, 2245, 2130, 1059, 1256, 6629, 6223, 4707, 4638,\n",
            "         1962, 1936, 1920, 1356,  722, 2695, 5143, 1154, 4638, 1060,  855,  712,\n",
            "         6206, 4028, 1519, 4506,  704, 1764, 1395, 4506, 7086, 1922, 6947,  738,\n",
            "         4294, 1162, 2994,  677, 1920, 1356,  722, 2695, 4638, 4958, 3302, 1519,\n",
            "         5645, 3582, 2374, 4638, 1169, 3302, 6656, 1378, 4124, 4638, 5106, 5187,\n",
            "         1591, 6282, 1762, 1059, 4413, 2952, 6629, 3119, 6213, 4229, 4060, 4638,\n",
            "         6999, 4511, 4638, 4530, 2682,  686, 4518, 1184, 6868, 3189, 3315, 7087,\n",
            "         6182,  749, 6999, 4511, 4638, 4530, 2682,  686, 4518, 8038, 3189, 3315,\n",
            "         2769,  889, 1568, 3189, 4276, 4638, 5059, 4680, 7370,  749,  792, 5171,\n",
            "         7768, 7710, 4534, 1765, 3152, 1265, 5401, 7608, 5645, 6257, 6243, 6917,\n",
            "         3298, 1217, 1057, 4761, 1399, 1957, 3215, 3717, 1333, 2361, 2094, 5645,\n",
            "          758,  855,  712, 2898,  782,  671, 6629, 1295, 1221, 1724,  855, 3189,\n",
            "         3315, 5162,  782, 6868, 6121, 3121, 6863, 6243, 4529, 3634, 1912, 1920,\n",
            "         2157, 4225, 2634, 4638, 3941, 6920, 4684, 5401,  738, 3298,  809, 4294,\n",
            "         1162, 1649, 6540, 4638, 6716,  819, 1217, 1057,  712, 2898, 7369, 2159,\n",
            "         1295, 1221, 5162,  782, 1920, 6365, 6716,  102,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         1925, 7065, 6121, 6512, 3124, 6956, 1350,  704, 1925, 2100, 3621,  924,\n",
            "         7402, 1062, 1385, 5175, 2768, 2201, 3428, 2207, 5175, 5883, 7415,  712,\n",
            "         6206, 1751, 2157, 1072, 7768,  868, 3791, 2130, 2768, 2769, 1751, 5072,\n",
            "         6908, 3373, 3539, 1350, 2485, 1265, 4675, 4415, 2974, 3177, 6211, 1205,\n",
            "         7032, 5052, 3298, 6134, 4850, 4158, 7518, 1164, 2972, 1240, 4685, 7302,\n",
            "         4675, 4415, 2974, 3177, 5052, 4415, 6794, 3791, 2347,  898, 3791, 2130,\n",
            "         2768, 7521, 1440, 4923, 2415, 7032, 5052, 3298, 1347, 6980, 1751, 7396,\n",
            "         6211, 5061,  898, 6211, 3563, 7302, 6865, 2595, 1377, 3296,  807, 2595,\n",
            "         1350, 6185, 7429, 4923, 2428, 5023, 1724, 1920, 7481, 1403, 5072, 6908,\n",
            "         1139, 5016, 1394, 3454,  816,  722, 2769, 1751, 5143, 5186, 2595, 7028,\n",
            "         6206, 7065, 6121, 1066, 3300,  758, 2157, 1259, 2886,  704, 1751,  928,\n",
            "         6249, 1751, 3805,  686, 5836, 1378, 1266, 2168, 6930, 1042, 6493, 7065,\n",
            "         1350, 1394, 2430, 7065, 5023, 4507, 3176, 6857, 2157, 6206, 2824, 3085,\n",
            "         1920, 1168,  679, 5543,  948, 4638, 1886, 1213, 1728, 3634,  738, 2553,\n",
            "         7519, 1072,  991, 6733, 7770, 4638, 7591, 7402, 2824, 3085, 5543, 1213,\n",
            "         7032, 5052, 3298, 6211, 2137, 2157, 6963, 6206, 3300, 7540, 1912, 6536,\n",
            "         3315, 4638, 6206, 3724, 1259, 2886, 7540, 1912, 3791, 2137, 6536, 3315,\n",
            "         6206, 3724,  809, 1350, 1058, 6956, 5052, 4415, 6536, 3315, 6206, 3724,\n",
            "         2205, 3176, 7065, 6121, 7519, 7481, 2205, 6857, 7540, 1912, 4638, 6536,\n",
            "         3315, 6206, 3724, 2200, 5183,  750, 2130, 3146, 2399, 4638, 6310, 3146,\n",
            "         3309, 5143, 5186, 2595, 7028, 6206, 7065, 6121, 5632, 6158, 2900, 2137,\n",
            "         4638, 3613, 2399, 6629, 7444, 1403,  712, 5052, 3582, 7302, 1350,  704,\n",
            "         1925, 2100, 3621,  924, 7402, 1062, 1385, 4509, 1841,  898, 5993, 4415,\n",
            "         7032, 6084, 3582, 3539, 5195, 4245, 1314, 3582,  868, 3511, 6206, 7953,\n",
            "         2792, 6242, 2137,  722, 5195, 4245, 1314, 3582, 2746, 6365, 2974, 3177,\n",
            "         1259, 2886, 2746, 6303, 3209, 7065, 6121,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['氣象專家吳德榮在三立準氣象老大洩天機專欄指出今日東北季風南下迎風面北部東北部及東部有局部雨北台灣氣溫下降轉溼涼；明（日）和週三（日）水氣漸減降雨逐漸偏在北海岸北部山區及東北部天氣仍偏涼；背風面天氣穩定中南部白天舒適早晚涼不過到了週四又會有另一波東北季風南下冷空氣比今日這一波略強一些迎風面北部東北部及東部有局部雨北台灣溼涼；週五（日）和週六（日）水氣漸減降雨偏在北海岸北部山區東北部及東部天氣仍偏涼；背風面都是穩定的天氣中南部白天舒適早晚涼天氣風險公司氣象主播賴忠瑋指出這次天氣變化的主要原因是北方冷高壓南下使得迎風面的北部和東北部雲量逐漸增加也容易有局部短暫陣雨或飄雨雖然不是隨時都在下雨不過會斷斷續續的持續一整天'], 'input_ids': tensor([[ 101, 3706, 6496, 2201, 2157, 1425, 2548, 3532, 1762,  676, 4989, 3976,\n",
            "         3706, 6496, 5439, 1920, 3824, 1921, 3582, 2201, 3608, 2900, 1139,  791,\n",
            "         3189, 3346, 1266, 2108, 7591, 1298,  678, 6816, 7591, 7481, 1266, 6956,\n",
            "         3346, 1266, 6956, 1350, 3346, 6956, 3300, 2229, 6956, 7433, 1266, 1378,\n",
            "         4124, 3706, 3984,  678, 7360, 6752, 3990, 3893, 8039, 3209, 8020, 3189,\n",
            "         8021, 1469, 6867,  676, 8020, 3189, 8021, 3717, 3706, 4041, 3938, 7360,\n",
            "         7433, 6852, 4041,  974, 1762, 1266, 3862, 2279, 1266, 6956, 2255, 1281,\n",
            "         1350, 3346, 1266, 6956, 1921, 3706,  793,  974, 3893, 8039, 5520, 7591,\n",
            "         7481, 1921, 3706, 4952, 2137,  704, 1298, 6956, 4635, 1921, 5653, 6900,\n",
            "         3193, 3241, 3893,  679, 6882, 1168,  749, 6867, 1724, 1348, 3298, 3300,\n",
            "         1369,  671, 3797, 3346, 1266, 2108, 7591, 1298,  678, 1107, 4958, 3706,\n",
            "         3683,  791, 3189, 6857,  671, 3797, 4526, 2485,  671,  763, 6816, 7591,\n",
            "         7481, 1266, 6956, 3346, 1266, 6956, 1350, 3346, 6956, 3300, 2229, 6956,\n",
            "         7433, 1266, 1378, 4124, 3990, 3893, 8039, 6867,  758, 8020, 3189, 8021,\n",
            "         1469, 6867, 1063, 8020, 3189, 8021, 3717, 3706, 4041, 3938, 7360, 7433,\n",
            "          974, 1762, 1266, 3862, 2279, 1266, 6956, 2255, 1281, 3346, 1266, 6956,\n",
            "         1350, 3346, 6956, 1921, 3706,  793,  974, 3893, 8039, 5520, 7591, 7481,\n",
            "         6963, 3221, 4952, 2137, 4638, 1921, 3706,  704, 1298, 6956, 4635, 1921,\n",
            "         5653, 6900, 3193, 3241, 3893, 1921, 3706, 7591, 7402, 1062, 1385, 3706,\n",
            "         6496,  712, 3064, 6552, 2566, 4441, 2900, 1139, 6857, 3613, 1921, 3706,\n",
            "         6365, 1265, 4638,  712, 6206, 1333, 1728, 3221, 1266, 3175, 1107, 7770,\n",
            "         1886, 1298,  678,  886, 2533, 6816, 7591, 7481, 4638, 1266, 6956, 1469,\n",
            "         3346, 1266, 6956, 7437, 7030, 6852, 4041, 1872, 1217,  738, 2159, 3211,\n",
            "         3300, 2229, 6956, 4764, 3271, 7369, 7433, 2772, 7597, 7433, 7426, 4197,\n",
            "          679, 3221, 7401, 3229, 6963, 1762,  678, 7433,  679, 6882, 3298, 3174,\n",
            "         3174, 5265, 5265, 4638, 2898, 5265,  671, 3146, 1921,  102,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['連凱和高以翔因拍戲建立起好交情在高以翔送醫的消息曝光後他第一時間傳訊關心：  但遲遲沒收到回覆接下來就是聽到過世噩耗他難過發文：我早上才留言給你的但是沒有收到你的回覆這麼拼幹什麼上個節目而已哥心裡空空的現在連凱過去呼籲過很多次不要賣命工作感嘆沒有人重視很多影視演員為了掙錢或是刷存在感紛紛上綜藝節目有的賣自尊有的賣人格最看不過去的就是賣命半夜三更還在錄影弟弟沒有簽工作時間嗎一整天心情無法平復又生氣又傷心從演員的誕生到如今的追我吧這些年我也批評過很多次了這些是傷害演員的節目對演員來說不但曝露自己的短板神祕感也全沒了你不難堪痛苦退出倒下怎麼會有人看電視臺收視率有了你有了什麼連凱沉痛呼籲藝人要好好愛惜自己更痛斥節目：有考慮我們的死活嗎'], 'input_ids': tensor([[ 101, 6865, 1134, 1469, 7770,  809, 5425, 1728, 2864, 2783, 2456, 4989,\n",
            "         6629, 1962,  769, 2658, 1762, 7770,  809, 5425, 6843, 7015, 4638, 3867,\n",
            "         2622, 3284, 1045, 2527,  800, 5018,  671, 3229, 7279, 1001, 6244, 7302,\n",
            "         2552, 8038,  852, 6903, 6903, 3760, 3119, 1168, 1726, 6208, 2970,  678,\n",
            "          889, 2218, 3221, 5481, 1168, 6882,  686, 1691, 5450,  800, 7432, 6882,\n",
            "         4634, 3152, 8038, 2769, 3193,  677, 2798, 4522, 6241, 5183,  872, 4638,\n",
            "          852, 3221, 3760, 3300, 3119, 1168,  872, 4638, 1726, 6208, 6857, 7938,\n",
            "         2894, 2402,  784, 7938,  677,  943, 5059, 4680, 5445, 2347, 1520, 2552,\n",
            "         6174, 4958, 4958, 4638, 4412, 1762, 6865, 1134, 6882, 1343, 1461, 5100,\n",
            "         6882, 2523, 1914, 3613,  679, 6206, 6546, 1462, 2339,  868, 2697, 1647,\n",
            "         3760, 3300,  782, 7028, 6213, 2523, 1914, 2512, 6213, 4028, 1519, 4158,\n",
            "          749, 2964, 7092, 2772, 3221, 1170, 2100, 1762, 2697, 5160, 5160,  677,\n",
            "         5198, 5971, 5059, 4680, 3300, 4638, 6546, 5632, 2203, 3300, 4638, 6546,\n",
            "          782, 3419, 3297, 4692,  679, 6882, 1343, 4638, 2218, 3221, 6546, 1462,\n",
            "         1288, 1915,  676, 3291, 6917, 1762, 7087, 2512, 2475, 2475, 3760, 3300,\n",
            "         5087, 2339,  868, 3229, 7279, 1621,  671, 3146, 1921, 2552, 2658, 4192,\n",
            "         3791, 2398, 2541, 1348, 4495, 3706, 1348, 1003, 2552, 2537, 4028, 1519,\n",
            "         4638, 6293, 4495, 1168, 1963,  791, 4638, 6841, 2769, 1416, 6857,  763,\n",
            "         2399, 2769,  738, 2821, 6268, 6882, 2523, 1914, 3613,  749, 6857,  763,\n",
            "         3221, 1003, 2154, 4028, 1519, 4638, 5059, 4680, 2205, 4028, 1519,  889,\n",
            "         6303,  679,  852, 3284, 7463, 5632, 2346, 4638, 4764, 3352, 4868, 4861,\n",
            "         2697,  738, 1059, 3760,  749,  872,  679, 7432, 1838, 4578, 5736, 6842,\n",
            "         1139,  948,  678, 2582, 7938, 3298, 3300,  782, 4692, 7442, 6213, 5637,\n",
            "         3119, 6213, 4372, 3300,  749,  872, 3300,  749,  784, 7938, 6865, 1134,\n",
            "         3756, 4578, 1461, 5100, 5971,  782, 6206, 1962, 1962, 2695, 2667, 5632,\n",
            "         2346, 3291, 4578, 3166, 5059, 4680, 8038, 3300, 5440, 2719, 2769,  947,\n",
            "         4638, 3647, 3833, 1621,  102,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['前富味鄉董事陳瑞禮因假純芝麻油案遭境管他以到大陸廣西參與富味鄉工廠建置技術改善等理由聲請暫時解除境管高院裁准讓他以萬元及張富味鄉股票供擔保後准予解除檢不服提抗告最高法院駁回確定陳瑞禮獲准暫時解除境管前往大陸的時間是今年月日起至日止及月日起至月日止陳須在入境期限內返台並主動以書面向高院陳報如未遵期返台他繳納的保證金及扣押的股票擔保物都將予以沒入富味鄉董事長陳文南被訴在年前向胞弟陳瑞禮所經營的富鼎公司採購摻有玉米原油的假純芝麻油造成富味鄉損失逾億元事後他與公司女副總在櫃買中心說明會上說謊欺騙大眾；陳瑞禮二審遭判刑年月最高法院撤銷發回更審中陳瑞禮在今年月日到月日間到大陸廣西防城港富味鄉油脂公司參與製程改善會議執行精煉線建設位置及佈 局配置風送脫皮系統進行單殼芝麻脫皮測試等他以打算月及月再去參加產銷協調會議因此再度向高院聲請暫時解除境管高院認為本件陳瑞禮並未遭羈押且他從偵查以來曾為大陸建廠多次出國處理相關事宜於事務處理完畢後均能遵期返國因此裁准他繳納保證金及股票後暫時解除境管到大陸檢方不服提抗告最高法院駁回確定中時'], 'input_ids': tensor([[ 101, 1184, 2168, 1456, 6965, 5869,  752, 7376, 4448, 4891, 1728,  969,\n",
            "         5155, 5698, 7937, 3779, 3428, 6901, 1862, 5052,  800,  809, 1168, 1920,\n",
            "         7380, 2451, 6205, 1347, 5645, 2168, 1456, 6965, 2339, 2449, 2456, 5390,\n",
            "         2825, 6123, 3121, 1587, 5023, 4415, 4507, 5476, 6313, 3271, 3229, 6237,\n",
            "         7370, 1862, 5052, 7770, 7368, 6161, 1114, 6366,  800,  809, 5857, 1039,\n",
            "         1350, 2484, 2168, 1456, 6965, 5500, 4873,  897, 3085,  924, 2527, 1114,\n",
            "          750, 6237, 7370, 3596,  679, 3302, 2990, 2834, 1440, 3297, 7770, 3791,\n",
            "         7368, 7684, 1726, 4825, 2137, 7376, 4448, 4891, 4363, 1114, 3271, 3229,\n",
            "         6237, 7370, 1862, 5052, 1184, 2518, 1920, 7380, 4638, 3229, 7279, 3221,\n",
            "          791, 2399, 3299, 3189, 6629, 5635, 3189, 3632, 1350, 3299, 3189, 6629,\n",
            "         5635, 3299, 3189, 3632, 7376, 7519, 1762, 1057, 1862, 3309, 7361, 1058,\n",
            "         6819, 1378,  699,  712, 1240,  809, 3292, 7481, 1403, 7770, 7368, 7376,\n",
            "         1841, 1963, 3313, 6905, 3309, 6819, 1378,  800, 5260, 5152, 4638,  924,\n",
            "         6349, 7032, 1350, 2807, 2852, 4638, 5500, 4873, 3085,  924, 4289, 6963,\n",
            "         2200,  750,  809, 3760, 1057, 2168, 1456, 6965, 5869,  752, 7269, 7376,\n",
            "         3152, 1298, 6158, 6260, 1762, 2399, 1184, 1403, 5528, 2475, 7376, 4448,\n",
            "         4891, 2792, 5195, 4245, 4638, 2168, 7959, 1062, 1385, 2967, 6554, 3046,\n",
            "         3300, 4373, 5101, 1333, 3779, 4638,  969, 5155, 5698, 7937, 3779, 6863,\n",
            "         2768, 2168, 1456, 6965, 3010, 1927, 6874, 1023, 1039,  752, 2527,  800,\n",
            "         5645, 1062, 1385, 1957, 1199, 5244, 1762, 3602, 6525,  704, 2552, 6303,\n",
            "         3209, 3298,  677, 6303, 6335, 3619, 7700, 1920, 4707, 8039, 7376, 4448,\n",
            "         4891,  753, 2182, 6901, 1161, 1152, 2399, 3299, 3297, 7770, 3791, 7368,\n",
            "         3059, 7077, 4634, 1726, 3291, 2182,  704, 7376, 4448, 4891, 1762,  791,\n",
            "         2399, 3299, 3189, 1168, 3299, 3189, 7279, 1168, 1920, 7380, 2451, 6205,\n",
            "         7344, 1814, 3949, 2168, 1456, 6965, 3779, 5544, 1062, 1385, 1347, 5645,\n",
            "         6182, 4923, 3121, 1587, 3298, 6359, 1822, 6121, 5125, 4200, 5221, 2456,\n",
            "         6257,  855, 5390, 1350,  854, 2229, 6981, 5390, 7591, 6843, 5562, 4649,\n",
            "         5143, 5186, 6868, 6121, 1606, 3670, 5698, 7937, 5562, 4649, 3947, 6275,\n",
            "         5023,  800,  809, 2802, 5050, 3299, 1350, 3299, 1086, 1343, 1347, 1217,\n",
            "         4496, 7077, 1295, 6310, 3298, 6359, 1728, 3634, 1086, 2428, 1403, 7770,\n",
            "         7368, 5476, 6313, 3271, 3229, 6237, 7370, 1862, 5052, 7770, 7368, 6291,\n",
            "         4158, 3315,  816, 7376, 4448, 4891,  699, 3313, 6901, 5398, 2852,  684,\n",
            "          800, 2537,  980, 3389,  809,  889, 3295, 4158, 1920, 7380, 2456, 2449,\n",
            "         1914, 3613, 1139, 1751, 5993, 4415, 4685, 7302,  752, 2139, 3176,  752,\n",
            "         1243, 5993, 4415, 2130, 4525, 2527, 1772, 5543, 6905, 3309, 6819, 1751,\n",
            "         1728, 3634, 6161, 1114,  800, 5260, 5152,  924, 6349, 7032, 1350, 5500,\n",
            "         4873, 2527, 3271, 3229, 6237, 7370, 1862, 5052, 1168, 1920, 7380, 3596,\n",
            "         3175,  679, 3302, 2990, 2834, 1440, 3297, 7770, 3791, 7368, 7684, 1726,\n",
            "         4825, 2137,  704, 3229,  102,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([1])}\n",
            "tensor([1], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n",
            "{'review_text': ['南山人壽新系統上線後不斷出包經第三方專業機構查證後發現有內控等嚴重缺失金管會今天重罰萬元罰鍰且停止南山壽董事長杜英宗年職務調降前總稽核楊玠青薪資一年南山人壽境界系統自去年月上線後不斷出包金融監督管理委員會保險局局長施瓊華今天表示經第三方專業機構針對系統上線造成諸多嚴重問題查證後發現南山壽相關監督管理內部控制有嚴重缺失違反保險法規及有礙公司健全經營依保險法核處南山壽新台幣萬元罰鍰並予以項糾正處分除了鉅額罰鍰之外施瓊華也表示將停止南山人壽投資型保險商品新契約業務直至投資型保險商品資訊系統改善完成經金管會認可的第三方專業機構查核驗證通過才可以恢復辦理另外南山壽董事長杜英宗將暫停職務年且停止董事及董事長職務期間不得支付或給予任何形式報酬及福利；前總稽核楊玠青也被調降薪資一年（中央社）最話題在這想跟上時事快點我加入新聞好友'], 'input_ids': tensor([[ 101, 1298, 2255,  782, 1904, 3173, 5143, 5186,  677, 5221, 2527,  679,\n",
            "         3174, 1139, 1259, 5195, 5018,  676, 3175, 2201, 3511, 3582, 3539, 3389,\n",
            "         6349, 2527, 4634, 4412, 3300, 1058, 2971, 5023, 1713, 7028, 5375, 1927,\n",
            "         7032, 5052, 3298,  791, 1921, 7028, 5391, 5857, 1039, 5391, 7106,  684,\n",
            "          977, 3632, 1298, 2255, 1904, 5869,  752, 7269, 3336, 5739, 2134, 2399,\n",
            "         5480, 1243, 6310, 7360, 1184, 5244, 4942, 3417, 3501, 4379, 7471, 5959,\n",
            "         6536,  671, 2399, 1298, 2255,  782, 1904, 1862, 4518, 5143, 5186, 5632,\n",
            "         1343, 2399, 3299,  677, 5221, 2527,  679, 3174, 1139, 1259, 7032, 6084,\n",
            "         4675, 4719, 5052, 4415, 1999, 1519, 3298,  924, 7402, 2229, 2229, 7269,\n",
            "         3177, 4475, 5836,  791, 1921, 6134, 4850, 5195, 5018,  676, 3175, 2201,\n",
            "         3511, 3582, 3539, 7036, 2205, 5143, 5186,  677, 5221, 6863, 2768, 6328,\n",
            "         1914, 1713, 7028, 1558, 7539, 3389, 6349, 2527, 4634, 4412, 1298, 2255,\n",
            "         1904, 4685, 7302, 4675, 4719, 5052, 4415, 1058, 6956, 2971, 1169, 3300,\n",
            "         1713, 7028, 5375, 1927, 6889, 1353,  924, 7402, 3791, 6211, 1350, 3300,\n",
            "         4844, 1062, 1385,  978, 1059, 5195, 4245,  898,  924, 7402, 3791, 3417,\n",
            "         5993, 1298, 2255, 1904, 3173, 1378, 2395, 5857, 1039, 5391, 7106,  699,\n",
            "          750,  809, 7517, 5144, 3633, 5993, 1146, 7370,  749, 7056, 7540, 5391,\n",
            "         7106,  722, 1912, 3177, 4475, 5836,  738, 6134, 4850, 2200,  977, 3632,\n",
            "         1298, 2255,  782, 1904, 2832, 6536, 1798,  924, 7402, 1555, 1501, 3173,\n",
            "         1943, 5147, 3511, 1243, 4684, 5635, 2832, 6536, 1798,  924, 7402, 1555,\n",
            "         1501, 6536, 6244, 5143, 5186, 3121, 1587, 2130, 2768, 5195, 7032, 5052,\n",
            "         3298, 6291, 1377, 4638, 5018,  676, 3175, 2201, 3511, 3582, 3539, 3389,\n",
            "         3417, 7710, 6349, 6858, 6882, 2798, 1377,  809, 2612, 2541, 6794, 4415,\n",
            "         1369, 1912, 1298, 2255, 1904, 5869,  752, 7269, 3336, 5739, 2134, 2200,\n",
            "         3271,  977, 5480, 1243, 2399,  684,  977, 3632, 5869,  752, 1350, 5869,\n",
            "          752, 7269, 5480, 1243, 3309, 7279,  679, 2533, 3118,  802, 2772, 5183,\n",
            "          750,  818,  862, 2501, 2466, 1841, 6992, 1350, 4886, 1164, 8039, 1184,\n",
            "         5244, 4942, 3417, 3501, 4379, 7471,  738, 6158, 6310, 7360, 5959, 6536,\n",
            "          671, 2399, 8020,  704, 1925, 4852, 8021, 3297, 6282, 7539, 1762, 6857,\n",
            "         2682, 6656,  677, 3229,  752, 2571, 7953, 2769, 1217, 1057, 3173, 5472,\n",
            "         1962, 1351,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['阿比查邦年以波米叔叔的前世今生（       ）拿下坎城金棕櫚大獎這次他帶著自己的狂中之靜（   ）展覽來台他靦腆地說自己還在芝加哥藝術學院念電影時受到台灣新電影包括蔡明亮侯孝賢楊德昌等人的啟發讓他重新看待自然光影樹木能在台灣展覽也是對這些導演的致意阿比查邦的影像氣質神祕遊走夢境與現實敘事受佛教印度教及泰國東北的傳統影響經常探討生死輪迴神話並隱隱加入對政治社會的批判前作華麗之墓（  ）讓一群士兵沈睡唯有在睡夢中意識的殘響可以不被政治掌控既是逃避也是抵抗拍攝華麗之墓時正好是年泰國軍政府再度發動政變他不願意接受審查臨時改變了拍攝地點影片完成後也不想送審因此無法在泰國上映日積月累的挫折與沮喪讓他宣布：不會繼續在泰國拍攝劇情片年政變時我覺得自己年紀已經大了真的受夠民族主義何時才會有真正的民主如果泰王（拉瑪九世蒲美蓬）過世全國人民必須守喪無法拍電影對投資人來說也是很大的風險社會愈來愈不自由人民上街示威被扣留年輕學生聚集閱讀喬治歐威爾以創意反抗後來軍政府禁止於公開場合閱讀真的很困難我不是會上街示威的人但我可以了解他們的想法和感受阿比查邦選擇離開今年歲年近半百他感覺自己沒有太多餘裕必須去一個全新的地方刺激自己今年與英國女演員蒂妲史雲頓（ ）合作的記憶（）在南美洲哥倫比亞開拍主題牽涉當地毒梟暴力地緣政治記憶與夢境本來會有擔心怕不能如期完成又要與不同系統的劇組合作但現在已經拍完這次的經驗和感受很開心就算觀眾討厭這部片我也無所謂儘管暫時不會在泰國拍劇情長片但他仍關心國內的社會政治現實會持續紀錄創作美術館正好提供了另一個出口狂中之靜包含攝影錄相裝置影像日記展覽主視覺意象是一個來自泰北的青少年戴著鬼怪面具與太陽眼鏡象徵鬼魅的拒斥阿比查邦出生於泰國東北部的孔敬市父母都是醫生他排行老三有一個哥哥一個姊姊孔敬大學建築系畢業後前往芝加哥藝術學院修讀電影相較於南方曼谷都會與平原東北是地處邊陲的高原年代東北人湧入曼谷打工年代開始又成為輸出海外的勞動力主要來源阿比查邦說東北的出身讓他來到曼谷大城後有自卑感是開始拍電影重新回到東北泰寮邊界探索歷史後才逐漸驅逐了自卑他的作品多帶有政治歷史探索例如煙火（檔案）（）以薩拉鬼窟佛像公園為拍攝場景影片開頭出現數位左翼民主運動者的人像煙火的爆炸聲伴隨軍隊槍響骷顱頭等死亡意象正好反映了泰國社會以佛教立國祥和寧靜的氛圍下暗湧的暴力殺戮當時的政治環境更嚴峻他們用生命反抗政府最後被當時的首相處決我去過其中一個政治犯的家他兒子已經七十歲了父親坐牢在獄中自學法律為自己辯護創建這個薩拉鬼窟佛像公園的僧侶   在年代被控為共產黨員流亡寮國而當時處決政治犯的首相至今在泰國各地公園中仍有紀念雕像有民眾去獻花致意泰國政府一直沒有面對自己的歷史我們一直沒有正義也不能相信法庭判決很多判決違反常識現在甚至有不能批評政府系統的法律非常可怕藝術家在國家機器體系外開啟不同的記憶戰場錄相灰燼（）以相機紀錄泰國社會日常隱隱用這個數字暗指泰國刑法條對皇室不敬的冒犯君主法；攝影動力男孩（湄公河）（  ）映照泰寮邊界湄公河對岸的沙耶武里大壩發電廠電廠為寮國提供電力主要消費者卻是泰國人泰國人一面反對興建卻又離不開對其依賴年開始的原始計畫（ ）以納布亞村（）的青年為創作與田野調查對象這裡曾是至年代泰國軍隊駐紮清剿泰國共產黨的地方女人被強暴遭懷疑是共產黨的人們受到折磨或逃入叢林中冷戰結束後軍隊撤離但轉型正義始終沒有發生這段歷史也不曾出現在課本上我關注這些年輕人因為我關心未來他們的祖父父親輩受到軍政權警察暴力折磨雖然有些年輕人現在只是關心自己能不能找到工作有些人選擇去從軍原始計畫延伸出的一件錄相作品俳句（）中納布亞的青年們睡在與藝術家一起建造的時光機中在睡夢中被催眠面對現實困境只有在睡眠裡才擁有全然的自由夢境是阿比查邦持續探索的主題以前他花很多時間睡覺做夢紀錄夢境但近二年睡得比較少一天只有四五個小時我比較淺眠常醒來所以睡前我會吃各種不同的東西油補品西藥訪問時他打開一包中藥聞起來有甘草味以為他感冒了他卻說：這是為了睡眠品質原來他來到台灣也積極嘗試不同提升睡眠品質的方法在哥倫比亞拍片時他也到秘魯嘗試古老的迷幻植物死藤水第一次很恐怖吐得亂七八糟感覺很糟但隔天早上感到很清新就像大病初癒晚上我開始想起小時候被壓抑的創傷記憶我重新面對對話明白這是死藤水的效果後來又嘗試了第二次有一段時間我的意識進入到一個幾何空間有很多房間開開關關我在裡面進出我也成為空間的一部分我本來預期會看到比較有機生物或植物的形象但沒想到是這樣的帶給我很大的平靜和自信睡覺之外阿比查邦的日常生活很簡單不看電視也不聽音樂反而對冷氣機運轉風吹過樹枝的聲音更為敏感起床後花很多時間做早餐偶爾打坐冥想然後工作清邁的工作室養了三隻狗一隻貓十幾隻雞在周圍跑來跑去記憶是為了抵抗遺忘問他：如果有一個絕對不想忘掉的記憶會是什麼他想了很久說：也許還是拍電影的記憶我跟劇組共同度過開心沮喪壓力但回頭看都很美麗拍熱帶幻夢（ ）的時候我們必須拍攝樹上的猴子說話但拍攝時猴子跑掉了消失在森林中訓練師很沮喪第二助導很同情他但我當時只在乎電影我需要一隻新的猴子所以我打給朋友：你可以幫我找隻新猴子嗎這段記憶很模糊我那時很焦慮氣到開除這個訓練師我需要記得這個我當時脾氣很壞拍片的時候簡直就像個獨裁者他說自己原本脾氣不好是拍攝戀愛症候群（   ）前夕父親過世拍完電影後他開始修行脾氣才漸漸改變一個藝術家與其作品就像是從土地中有機生長出來的樹木離開泰國後他還能自在創作而不被改變嗎我很喜歡在哥倫比亞拍攝的經驗我也在問自己創作能否更自由例如運用二三個人的小劇組旅行各地不一定是拍電影而是沒有計畫的創作他是公開出櫃的同性戀他自言母親一輩的思想已奴化兄姊也較擁護君主政體因而有過爭執他已放棄與家人談論政治追尋自由離鄉做夢的人還是從不離地'], 'input_ids': tensor([[ 101, 7350, 3683, 3389, 6930, 2399,  809, 3797, 5101, 1356, 1356, 4638,\n",
            "         1184,  686,  791, 4495, 8020, 8021, 2897,  678, 1775, 1814, 7032, 3473,\n",
            "         3603, 1920, 4354, 6857, 3613,  800, 2380, 5865, 5632, 2346, 4638, 4312,\n",
            "          704,  722, 7477, 8020, 8021, 2245, 6222,  889, 1378,  800, 7483, 5570,\n",
            "         1765, 6303, 5632, 2346, 6917, 1762, 5698, 1217, 1520, 5971, 6123, 2119,\n",
            "         7368, 2573, 7442, 2512, 3229, 1358, 1168, 1378, 4124, 3173, 7442, 2512,\n",
            "         1259, 2886, 5918, 3209,  778,  908, 2105, 6545, 3501, 2548, 3208, 5023,\n",
            "          782, 4638, 1564, 4634, 6366,  800, 7028, 3173, 4692, 2521, 5632, 4197,\n",
            "         1045, 2512, 3572, 3312, 5543, 1762, 1378, 4124, 2245, 6222,  738, 3221,\n",
            "         2205, 6857,  763, 2206, 4028, 4638, 5636, 2692, 7350, 3683, 3389, 6930,\n",
            "         4638, 2512, 1008, 3706, 6549, 4868, 4861, 6879, 6624, 1918, 1862, 5645,\n",
            "         4412, 2179, 3135,  752, 1358,  867, 3136, 1313, 2428, 3136, 1350, 3805,\n",
            "         1751, 3346, 1266, 4638, 1001, 5186, 2512, 7513, 5195, 2382, 2968, 6245,\n",
            "         4495, 3647, 6743, 6836, 4868, 6282,  699, 7403, 7403, 1217, 1057, 2205,\n",
            "         3124, 3780, 4852, 3298, 4638, 2821, 1161, 1184,  868, 5836, 7927,  722,\n",
            "         1867, 8020, 8021, 6366,  671, 5408, 1894, 1070, 3755, 4717, 1546, 3300,\n",
            "         1762, 4717, 1918,  704, 2692, 6352, 4638, 3659, 7513, 1377,  809,  679,\n",
            "         6158, 3124, 3780, 2958, 2971, 3188, 3221, 6845, 6912,  738, 3221, 2850,\n",
            "         2834, 2864, 3109, 5836, 7927,  722, 1867, 3229, 3633, 1962, 3221, 2399,\n",
            "         3805, 1751, 6725, 3124, 2424, 1086, 2428, 4634, 1240, 3124, 6365,  800,\n",
            "          679, 7544, 2692, 2970, 1358, 2182, 3389, 5631, 3229, 3121, 6365,  749,\n",
            "         2864, 3109, 1765, 7953, 2512, 4275, 2130, 2768, 2527,  738,  679, 2682,\n",
            "         6843, 2182, 1728, 3634, 4192, 3791, 1762, 3805, 1751,  677, 3216, 3189,\n",
            "         4948, 3299, 5168, 4638, 2919, 2835, 5645, 3775, 1603, 6366,  800, 2146,\n",
            "         2357, 8038,  679, 3298, 5262, 5265, 1762, 3805, 1751, 2864, 3109, 1206,\n",
            "         2658, 4275, 2399, 3124, 6365, 3229, 2769, 6221, 2533, 5632, 2346, 2399,\n",
            "         5145, 2347, 5195, 1920,  749, 4696, 4638, 1358, 1917, 3696, 3184,  712,\n",
            "         5412,  862, 3229, 2798, 3298, 3300, 4696, 3633, 4638, 3696,  712, 1963,\n",
            "         3362, 3805, 4374, 8020, 2861, 4454,  736,  686, 5891, 5401, 5908, 8021,\n",
            "         6882,  686, 1059, 1751,  782, 3696, 2553, 7519, 2127, 1603, 4192, 3791,\n",
            "         2864, 7442, 2512, 2205, 2832, 6536,  782,  889, 6303,  738, 3221, 2523,\n",
            "         1920, 4638, 7591, 7402, 4852, 3298, 2689,  889, 2689,  679, 5632, 4507,\n",
            "          782, 3696,  677, 6125, 4850, 2014, 6158, 2807, 4522, 2399, 6738, 2119,\n",
            "         4495, 5471, 7415, 7288, 6364, 1605, 3780, 3627, 2014, 4273,  809, 1201,\n",
            "         2692, 1353, 2834, 2527,  889, 6725, 3124, 2424, 4881, 3632, 3176, 1062,\n",
            "         7274, 1842, 1394, 7288, 6364, 4696, 4638, 2523, 1737, 7432, 2769,  679,\n",
            "         3221, 3298,  677, 6125, 4850, 2014, 4638,  782,  852, 2769, 1377,  809,\n",
            "          749, 6237,  800,  947, 4638, 2682, 3791, 1469, 2697, 1358, 7350, 3683,\n",
            "         3389, 6930, 6908, 3079, 7431, 7274,  791, 2399, 3641, 2399, 6818, 1288,\n",
            "         4636,  800, 2697, 6221, 5632, 2346, 3760, 3300, 1922, 1914, 7626, 6168,\n",
            "         2553, 7519, 1343,  671,  943, 1059, 3173, 4638, 1765, 3175, 1173, 4080,\n",
            "         5632, 2346,  791, 2399, 5645, 5739, 1751, 1957, 4028, 1519, 5881, 1985,\n",
            "         1380, 7437, 7524, 8020, 8021, 1394,  868,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['月日政府訂立禁蒙面法各區都有大批人士聚集反對立法商舖提早關門沙田的示威者點多開始快閃破壞政府合署康文署大樓和港鐵沙田站沙田站現已關閉從各區情況所見除了政府總部有警方戒備外其他地方從下午到晚上點均未見警察香港正在各區直播月日政府訂立禁蒙面法各區都有大批人士聚集反對立法沙田午夜前警方從沙田警署向外發射催淚彈（盧翊銘攝）年月日\\u3000星期六東涌站以及鄰近商場亦廣受破壞包括美心集團的食肆旺角：警員破壞太子站外的悼念物品警員退回警署後有市民立即收拾被撕下的紙張並將被警員拔除的白鮮花重新插在鐵欄上警員清場時將盛載冥鏹的紙箱翻倒倒出冥鏹後再用路邊水樽的水及飲料淋濕冥鏹市民在警員離開後收拾被弄濕的冥鏹午夜後旺角彌敦道仍有數百名示威者聚集分散在不同位置當中近百人聚集在旺角警署外的彌敦道數名警員在警署高位駐守正門則有兩名警員在高台上持槍戒備蒙面法生效後記者問過現場示威者有示威者坦言難以決定之後如何走下去沙田新城市廣場有職員打掃玻璃碎沙田除了有警員從沙田警署內向外發射催淚彈外全晚並無警察出現沙田源禾路消防員到場救熄路障的火種示威者和市民已離開現場剩下大多數是記者禁蒙面法生效沙田警署發射完催淚彈後並無進一步行動示威者步行離開部份依然戴着防毒面具有街坊在附近圍觀年月日\\u3000星期五警員用擴音器警告示威者用鐳射裝置照射警務人員構成襲警之後發射兩枚催淚彈示威者後撤警員從沙田警署內向外發射催淚彈但並無警員到警署外驅散沙田放催淚彈數十名示威者仍留守舉傘陣沙田源禾路仍有多處雜物着火早前此處有逾千人快閃破壞不同港鐵站現時九成示威者已撤離現場仍有部份示威者在等禁蒙面法生效沙田全晚未見有警員出現沙田多處遭縱火網上影片顯示今晚較早時候上水站港鐵職員關閘時遭黑衣人圍毆旺角防暴警集結後上警車未有驅趕行人路上的市民旺角防暴警推進要求在場市民盡快離開警員到場前有示威者已提示警員到場晚上點多沙田中旅社遭投擲汽油彈縱火消防到旺角救熄路障的火種小米優品店舖遭破壞有示威者曾將優品的商品拿出馬路燃點由於大量車站遭到暴力破壞及蓄意縱火並有列車懷疑被縱火有車站職員被襲擊受傷顧及乘客和員工的安全港鐵現時全線暫停服務早前沙田站港鐵列車着火片段顯示現場火光熊熊濃煙上半空示威者在旺角警署一條街外的旺角道架設路障消防車未能通過消防員手持滅火筒徒步前往救火旺角站多個出口被焚毀消防到場將火救熄彌敦道近旺角道的中銀分行玻璃門遭示威者破壞馬鐵石門站遭快閃破壞旺角站遭縱火示威者不斷投擲易燃物火勢愈來愈大東鐵線馬鐵線全線停運沙田多個車站遭破壞包括大圍站第一城站沙田圍站沙田站馬鐵第一城站遭快閃破壞旺角：數百示威者在彌敦道及亞皆老街交界的十字路口聚集大部分示威者戴上口罩示威者用木板竹枝等雜物設置路障十數名示威者圍繞交通燈並舉傘遮蓋外界視線然後一些人剪斷交通燈的電線示威者快閃破壞馬鐵線沙田圍站閘機遭破壞玻璃碎滿一地緊急關閉示威者繼續在沙田堵路大叫香港人反抗光復香港時代革命等口號目前未知示威者去向從下午至今未見有警察沙田示威者破壞中旅社沙田證件服務中心撬開大閘和打爛玻璃門後快閃離開歷時僅數分鐘沙田大批示威者在源禾路聚集設置路障示威者快閃離開新城市廣場向百步梯方向離開沙田港鐵站和連城廣場的自動灑水系統被破壞現場多處灑水港鐵站落閘示威者返回沙田港鐵港鐵站破壞部份閘機之後返回新城市廣場月日政府訂立禁蒙面法各區都有大批人士聚集反對立法晚上約點分示威者快閃沙田康文署大樓砸玻璃（梁煥敏攝）示威者在沙田康文署大樓砸玻璃之後快閃離開前後不夠五分鐘外面有路障起火沙田政府合署及康文署兩邊快閃已完玻璃外牆的全數爆裂人潮沿路大叫：香港人反抗月日政府訂立禁蒙面法各區都有大批人士聚集反對立法晚上約點分沙田政府合署排頭街位置有路障起火（資料圖片梁煥敏攝）沙田政府合署快閃完在牆上噴上字句沙田示威者快閃封源禾路人潮從新城市廣場走向政府合署大批市民在又一城舉行集會（曾梓洋攝）元朗 廣播重複今日營業時間已結束並關上大部分燈全部商店已關門但商場內仍有近百名名戴口罩市民留守亦掛上印有示威標語小旗幟在玻璃貼上紙鶴期間有人高叫口號另外旺角的彌敦道中國銀行香港自助銀行服務區亦已落閘職員指無法提供櫃員機服務又一城內亦有大批市民和學生聚集有市民在地上擺放罷課不罷學願榮光歸香港等標語將軍澳東港城多間商舖已落閘關門因應旺角朗豪坊商場宣布晚上六時半關閉大批市民從商場陸續離開 中環人群已佔領環球大廈對出一段的干諾道中現時東行車輛不能夠經迴旋處駛出有巴士私家車及的士被迫滯留 新城市廣場內部分燈關掉在場人士舉起手機燈商場亦播放廣播指所有商鋪已暫停營業呼籲在場人士離開紫荊之殤合奏團到朗豪坊演奏願榮光歸香港問誰未發聲高呼香港警察知法犯法六大訴求缺一不可朗豪坊內有部分商場落閘商場職員指未收到通知需提早關閉商場；又指正了解情況 有大批市民堵塞畢打街對出的干諾道中東西行車線令西行車輛需往金鐘方向折返；環球大廈及交易廣場對出的干諾道中迴旋處行車則未有受阻東行線車輛則經此駛出中環有大批市民堵塞畢打街對出的干諾道中東西行車線令西行車輛需往金鐘方向折返；環球大廈及交易廣場對出的干諾道中迴旋處行車則未有受阻東行線車輛則經此駛出中環（故家欣攝）\\xa0尖沙咀警署對面的美麗華商場亦陸續有店舖落閘\\xa0現場目測所見逾人聚集於沙田新城市廣場不時高呼口號光復香港 時代革命香港人加油高唱願榮光歸香港群眾亦曾高呼我要戴口罩香港人反抗等口號有人於商場貼上標語蒙面法已通過部分商鋪提早結束營業在場亦有市民派發口罩呼籲大家戴上以示對禁蒙面法的不滿有市民分享時指出港人應擔心自禁蒙面法先例一開政府可引緊急法立不同法例他勸勉港人未來需盡力參與每一次運動展現團結精神\\xa0新世紀廣場內至少有間店鋪落閘商場內有多位職員正統計提早關門的店鋪數量；商場職員稱仍未知商場是否需要提早關閉同時紫荊之殤合奏團到商場地下港鐵旺角東站外演奏願榮光歸香港問誰還未發聲並展示五大訴求缺一不可香港人加油標語並高呼香港人加油合奏團於分鐘後離開新世紀廣場前往朗豪坊另外沙田新城市廣場有店舖已提早關門\\xa0國際金融中心商場發出廣播因應中環及附近公眾活動為保障顧客職員及商戶安全商場將於下午時暫停營業呼籲現場人士在附近出口離開\\xa0尖沙咀海港城內的連卡佛準備關門對面的已關門海港城客戶服務職員向記者表示商場暫時無意提早關門而連卡佛方面則只會關閉化妝品樓層其他部門將繼續營業海港城對出天星碼頭東海堂職員則表示店舖將於下午時暫停營業；亦有星巴克職員表示全線店舖將於下午時提早關門 在旺角新世紀廣場一批學生高呼蒙面無罪立法可恥香港警察知法犯法有市民隨即附和高叫口號；有商舖落閘另外美心集團旗下的元氣壽司職員表示收到商場通知指商場將於點關閉惟商場服務台職員指未有收到通知而平日商場關閉時間為點而商場內有約個店鋪落閘新世紀廣場職員表示正了解有多少商戶落閘因應情況或提早關閉商場'], 'input_ids': tensor([[ 101, 3299, 3189, 3124, 2424, 6242, 4989, 4881, 5885, 7481, 3791, 1392,\n",
            "         1281, 6963, 3300, 1920, 2821,  782, 1894, 5471, 7415, 1353, 2205, 4989,\n",
            "         3791, 1555, 5655, 2990, 3193, 7302, 7271, 3763, 4506, 4638, 4850, 2014,\n",
            "         5442, 7953, 1914, 7274, 1993, 2571, 7272, 4788, 1889, 3124, 2424, 1394,\n",
            "         5392, 2434, 3152, 5392, 1920, 3559, 1469, 3949, 7136, 3763, 4506, 4991,\n",
            "         3763, 4506, 4991, 4412, 2347, 7302, 7273, 2537, 1392, 1281, 2658, 3785,\n",
            "         2792, 6210, 7370,  749, 3124, 2424, 5244, 6956, 3300, 6356, 3175, 2770,\n",
            "          991, 1912, 1071,  800, 1765, 3175, 2537,  678, 1286, 1168, 3241,  677,\n",
            "         7953, 1772, 3313, 6210, 6356, 2175, 7676, 3949, 3633, 1762, 1392, 1281,\n",
            "         4684, 3064, 3299, 3189, 3124, 2424, 6242, 4989, 4881, 5885, 7481, 3791,\n",
            "         1392, 1281, 6963, 3300, 1920, 2821,  782, 1894, 5471, 7415, 1353, 2205,\n",
            "         4989, 3791, 3763, 4506, 1286, 1915, 1184, 6356, 3175, 2537, 3763, 4506,\n",
            "         6356, 5392, 1403, 1912, 4634, 2198,  998, 3907, 2492, 8020, 4678, 5421,\n",
            "         7071, 3109, 8021, 2399, 3299, 3189, 3215, 3309, 1063, 3346, 3869, 4991,\n",
            "          809, 1350, 6973, 6818, 1555, 1842,  771, 2451, 1358, 4788, 1889, 1259,\n",
            "         2886, 5401, 2552, 7415, 1757, 4638, 7608, 5487, 3200, 6235, 8038, 6356,\n",
            "         1519, 4788, 1889, 1922, 2094, 4991, 1912, 4638, 2656, 2573, 4289, 1501,\n",
            "         6356, 1519, 6842, 1726, 6356, 5392, 2527, 3300, 2356, 3696, 4989, 1315,\n",
            "         3119, 2896, 6158, 3056,  678, 4638, 5158, 2484,  699, 2200, 6158, 6356,\n",
            "         1519, 2869, 7370, 4638, 4635, 7804, 5709, 7028, 3173, 2991, 1762, 7136,\n",
            "         3608,  677, 6356, 1519, 3926, 1842, 3229, 2200, 4670, 6734, 1097,  100,\n",
            "         4638, 5158, 5056, 5436,  948,  948, 1139, 1097,  100, 2527, 1086, 4500,\n",
            "         6662, 6920, 3717, 3574, 4638, 3717, 1350, 7614, 3160, 3900, 4086, 1097,\n",
            "          100, 2356, 3696, 1762, 6356, 1519, 7431, 7274, 2527, 3119, 2896, 6158,\n",
            "         2462, 4086, 4638, 1097,  100, 1286, 1915, 2527, 3200, 6235, 2493, 3142,\n",
            "         6887,  793, 3300, 3149, 4636, 1399, 4850, 2014, 5442, 5471, 7415, 1146,\n",
            "         3141, 1762,  679, 1398,  855, 5390, 4534,  704, 6818, 4636,  782, 5471,\n",
            "         7415, 1762, 3200, 6235, 6356, 5392, 1912, 4638, 2493, 3142, 6887, 3149,\n",
            "         1399, 6356, 1519, 1762, 6356, 5392, 7770,  855, 7688, 2127, 3633, 7271,\n",
            "         1179, 3300, 1060, 1399, 6356, 1519, 1762, 7770, 1378,  677, 2898, 3541,\n",
            "         2770,  991, 5885, 7481, 3791, 4495, 3126, 2527, 6250, 5442, 1558, 6882,\n",
            "         4412, 1842, 4850, 2014, 5442, 3300, 4850, 2014, 5442, 1788, 6241, 7432,\n",
            "          809, 3748, 2137,  722, 2527, 1963,  862, 6624,  678, 1343, 3763, 4506,\n",
            "         3173, 1814, 2356, 2451, 1842, 3300, 5480, 1519, 2802, 2954, 4390, 4461,\n",
            "         4810, 3763, 4506, 7370,  749, 3300, 6356, 1519, 2537, 3763, 4506, 6356,\n",
            "         5392, 1058, 1403, 1912, 4634, 2198,  998, 3907, 2492, 1912, 1059, 3241,\n",
            "          699, 4192, 6356, 2175, 1139, 4412, 3763, 4506, 3975, 4897, 6662, 3867,\n",
            "         7344, 1519, 1168, 1842, 3131, 4219, 6662, 7397, 4638, 4125, 4934, 4850,\n",
            "         2014, 5442, 1469, 2356, 3696, 2347, 7431, 7274, 4412, 1842, 1197,  678,\n",
            "         1920, 1914, 3149, 3221, 6250, 5442, 4881, 5885, 7481, 3791, 4495, 3126,\n",
            "         3763, 4506, 6356, 5392, 4634, 2198, 2130,  998, 3907, 2492, 2527,  699,\n",
            "         4192, 6868,  671, 3635, 6121, 1240, 4850, 2014, 5442, 3635, 6121, 7431,\n",
            "         7274, 6956,  819,  898, 4197, 2785, 4708,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['安永（）財務管理諮詢服務（股）公司總經理何淑芬日前指出受到中美貿易戰保護主義影響併購熱潮轉向歐洲歐洲年併購交易金額為兆美元年增率高達又以英國最受投資人喜愛受投資額為億美元創下歷年新高安永財務管理諮詢服務（股）公司以及台灣併購與私募股權協會舉辦國際投資論壇並發布投資布局歐洲趨勢分析報告協助台資企業在海外穩健布局何淑芬認為歐洲的智慧製造智慧醫療與能源產業等技術優勢有望補強台灣企業供應鏈根據安永報告顯示年台灣併購市場交易金額約億美元為近六年新高主要是受到跨國併購交易熱度增加尤其是科技產業的車聯網大型交易案（億美元）何淑芬表示年我國企業赴海外併購交易金額達到億美元為近六年新高可看出我國企業併購動能強勁她分析我國海外併購交易主要以三大產業為主第一是不動產與建造業以及科技業的大型併購案還有零售商透過海外併購取得新品牌切入新興市場何淑芬認為歐洲市場涵蓋大量的高技術人才完整的基礎設施與高度整合之供應鏈台企併購後不僅可獲得關鍵技術甚至可直接整合上游產業另外高技術也代表有防禦型併購的需求若台企不買而是被競爭對手買走反而對台企有所不利安永指出歐洲對台灣企業普遍較友善主要是過去併購交易中台企出價較為保險但整體法遵相當完善形塑台企高誠信的印象另外歐洲政府也普遍認為台灣企業技術人才充沛在併購審批流程上只要不涉及國防航空台企在併購的整合上更具優勢不過由於台企對於歐洲地區的併購經驗較為不足何淑芬建議台企有意取得當地企業第一步是要找出融資管道設定時程表並打造未來併購後的企業架構第二步就是談判細節應包含併購整合的綜效目前檯面上歐洲出售企業多為集團分拆也就是大公司將其中一個部門出售何淑芬提醒這類投資案是找投資銀行競標台企在流程上要更為注意她也指出部分交易之賣方會要求分手費以及公司高階主管的留任費用長期激勵獎金等台企也應尋找財務顧問及法律顧問以免多花冤枉錢安永聯合會計師事務所所長傅文芳則指出過去三年來安永辦過投資日本美國論壇他表示從下半年起隨著全球保護主義興起中美貿易戰等趨勢下全球投資環境變動劇烈加上歐洲稅務革新對於台灣企業長期跨國投資有正面助益歐洲市場將是良好標的傅文芳鼓勵我國企業併購交易不用侷限於相同產業而是要重新檢視生產鏈與商業模式以多元面向分析透過併購交易做資源整合台灣與歐洲雙向投資有望創雙贏局面'], 'input_ids': tensor([[ 101, 2128, 3719, 8020, 8021, 6512, 1243, 5052, 4415, 6324, 6273, 3302,\n",
            "         1243, 8020, 5500, 8021, 1062, 1385, 5244, 5195, 4415,  862, 3902, 5705,\n",
            "         3189, 1184, 2900, 1139, 1358, 1168,  704, 5401, 6530, 3211, 2782,  924,\n",
            "         6362,  712, 5412, 2512, 7513,  882, 6554, 4229, 4060, 6752, 1403, 3627,\n",
            "         3828, 3627, 3828, 2399,  882, 6554,  769, 3211, 7032, 7540, 4158, 1042,\n",
            "         5401, 1039, 2399, 1872, 4372, 7770, 6888, 1348,  809, 5739, 1751, 3297,\n",
            "         1358, 2832, 6536,  782, 1599, 2695, 1358, 2832, 6536, 7540, 4158, 1023,\n",
            "         5401, 1039, 1201,  678, 3644, 2399, 3173, 7770, 2128, 3719, 6512, 1243,\n",
            "         5052, 4415, 6324, 6273, 3302, 1243, 8020, 5500, 8021, 1062, 1385,  809,\n",
            "         1350, 1378, 4124,  882, 6554, 5645, 4900, 1247, 5500, 3609, 1295, 3298,\n",
            "         5647, 6794, 1751, 7396, 2832, 6536, 6316, 1883,  699, 4634, 2357, 2832,\n",
            "         6536, 2357, 2229, 3627, 3828, 6638, 1248, 1146, 3358, 1841, 1440, 1295,\n",
            "         1221, 1378, 6536,  821, 3511, 1762, 3862, 1912, 4952,  978, 2357, 2229,\n",
            "          862, 3902, 5705, 6291, 4158, 3627, 3828, 4638, 3255, 2716, 6182, 6863,\n",
            "         3255, 2716, 7015, 4615, 5645, 5543, 3975, 4496, 3511, 5023, 2825, 6123,\n",
            "         1032, 1248, 3300, 3307, 6171, 2485, 1378, 4124,  821, 3511,  897, 2746,\n",
            "         7122, 3418, 3087, 2128, 3719, 1841, 1440, 7549, 4850, 2399, 1378, 4124,\n",
            "          882, 6554, 2356, 1842,  769, 3211, 7032, 7540, 5147, 1023, 5401, 1039,\n",
            "         4158, 6818, 1063, 2399, 3173, 7770,  712, 6206, 3221, 1358, 1168, 6659,\n",
            "         1751,  882, 6554,  769, 3211, 4229, 2428, 1872, 1217, 2215, 1071, 3221,\n",
            "         4906, 2825, 4496, 3511, 4638, 6722, 5474, 5206, 1920, 1798,  769, 3211,\n",
            "         3428, 8020, 1023, 5401, 1039, 8021,  862, 3902, 5705, 6134, 4850, 2399,\n",
            "         2769, 1751,  821, 3511, 6626, 3862, 1912,  882, 6554,  769, 3211, 7032,\n",
            "         7540, 6888, 1168, 1023, 5401, 1039, 4158, 6818, 1063, 2399, 3173, 7770,\n",
            "         1377, 4692, 1139, 2769, 1751,  821, 3511,  882, 6554, 1240, 5543, 2485,\n",
            "         1233, 1961, 1146, 3358, 2769, 1751, 3862, 1912,  882, 6554,  769, 3211,\n",
            "          712, 6206,  809,  676, 1920, 4496, 3511, 4158,  712, 5018,  671, 3221,\n",
            "          679, 1240, 4496, 5645, 2456, 6863, 3511,  809, 1350, 4906, 2825, 3511,\n",
            "         4638, 1920, 1798,  882, 6554, 3428, 6917, 3300, 7439, 1545, 1555, 6851,\n",
            "         6882, 3862, 1912,  882, 6554, 1357, 2533, 3173, 1501, 4277, 1147, 1057,\n",
            "         3173, 5646, 2356, 1842,  862, 3902, 5705, 6291, 4158, 3627, 3828, 2356,\n",
            "         1842, 3891, 5901, 1920, 7030, 4638, 7770, 2825, 6123,  782, 2798, 2130,\n",
            "         3146, 4638, 1825, 4843, 6257, 3177, 5645, 7770, 2428, 3146, 1394,  722,\n",
            "          897, 2746, 7122, 1378,  821,  882, 6554, 2527,  679, 1006, 1377, 4363,\n",
            "         2533, 7302, 7107, 2825, 6123, 4493, 5635, 1377, 4684, 2970, 3146, 1394,\n",
            "          677, 3952, 4496, 3511, 1369, 1912, 7770, 2825, 6123,  738,  807, 6134,\n",
            "         3300, 7344, 4888, 1798,  882, 6554, 4638, 7444, 3724, 5735, 1378,  821,\n",
            "          679, 6525, 5445, 3221, 6158, 5000, 4261, 2205, 2797, 6525, 6624, 1353,\n",
            "         5445, 2205, 1378,  821, 3300, 2792,  679, 1164, 2128, 3719, 2900, 1139,\n",
            "         3627, 3828, 2205, 1378, 4124,  821, 3511, 3249, 6881, 6733, 1351, 1587,\n",
            "          712, 6206, 3221, 6882, 1343,  882, 6554,  769, 3211,  704, 1378,  821,\n",
            "         1139, 1019, 6733, 4158,  924, 7402,  852, 3146, 7768, 3791, 6905, 4685,\n",
            "         4534, 2130, 1587, 2501, 1848, 1378,  821,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['我來自哈薩克古力巴哈意指美麗的春天我家鄉有山草原山底都是蘋果園每年蘋果熟成我們會提著小籃子去蘋果園摘蘋果在那裡玩我父母很早過世我靠自己努力考大學念財經離婚後獨力撫養名子女為了孩子我很努力販售服飾和耳環項鍊年開始去中國調貨烏魯木齊義烏海南深圳都去烏魯木齊事件後維吾爾人到任何地方都得安檢但漢人不用為了安全我不再跟當地維吾爾人接觸每次去中國訂好貨就離開年我在中國因莫須有罪名突然被帶走關進集中營我們被迫打針吃藥不知被注射什麼即使滿身瘡疤化膿竟沒人覺得痛我看過年輕女生被帶走回來只會哭沒人說自己被性侵但身為女人我知道發生什麼曾有維吾爾人審訊我逼我認罪否則把陰莖塞到我嘴裡我罵他換來毒打我被綁用手銬敲桌子抗議：你殺了我受這種侮辱我不如去死他聽完走出去在走廊抽菸回來後按了鈕跟對講機說：把她帶走我們的確一直被帶走—換牢房每個囚房都有姐妹把希望放在我身上因為我是唯一的外國人有機會把這裡的情況告訴世界她們說：我們就算走出牢房還是活在監控下不管怎樣妳的國家總是比我們的自由每天警察會要我們人一組脫光衣服起立蹲下哭的人會被電擊有姐妹說：別哭他們頂多折磨我們但我們有信仰真主和我們在一起伊斯蘭教義說人死後要接受真主審判但我覺得對刑求我的人來說環境不允許他們想到真主因為大家都沒有自由但有時我猜他們心裡還是會想起神吧我不怪他們他們也是在被監控之下審訊我如果對我不嚴厲明天可能換他坐牢我想到他們也有家庭對我的同胞那些警察就恨不起來集中營裡有很多個古力巴哈但我知道自己是目前唯一活著走出去的那一個被救出來之前我受中國政府威脅離開後也常接到無聲電話但我一定要說出證言現在我日夜禱告只求真主一件事：讓受苦的姐妹們早日出來雖然我心裡有數：這輩子大概再也見不到她們了古力巴哈（ ）歲哈薩克斯坦人（現居土耳其）無業'], 'input_ids': tensor([[ 101, 2769,  889, 5632, 1506, 5958, 1046, 1367, 1213, 2349, 1506, 2692,\n",
            "         2900, 5401, 7927, 4638, 3217, 1921, 2769, 2157, 6965, 3300, 2255, 5770,\n",
            "         1333, 2255, 2419, 6963, 3221, 5981, 3362, 1754, 3680, 2399, 5981, 3362,\n",
            "         4225, 2768, 2769,  947, 3298, 2990, 5865, 2207, 5091, 2094, 1343, 5981,\n",
            "         3362, 1754, 3036, 5981, 3362, 1762, 6929, 6174, 4381, 2769, 4266, 3678,\n",
            "         2523, 3193, 6882,  686, 2769, 7479, 5632, 2346, 1222, 1213, 5440, 1920,\n",
            "         2119, 2573, 6512, 5195, 7431, 2042, 2527, 4360, 1213, 3062, 7621, 1399,\n",
            "         2094, 1957, 4158,  749, 2111, 2094, 2769, 2523, 1222, 1213, 6516, 1545,\n",
            "         3302, 7617, 1469, 5455, 4472, 7517, 7101, 2399, 7274, 1993, 1343,  704,\n",
            "         1751, 6310, 6515, 4166, 7798, 3312, 7968, 5412, 4166, 3862, 1298, 3918,\n",
            "         1766, 6963, 1343, 4166, 7798, 3312, 7968,  752,  816, 2527, 5204, 1434,\n",
            "         4273,  782, 1168,  818,  862, 1765, 3175, 6963, 2533, 2128, 3596,  852,\n",
            "         4031,  782,  679, 4500, 4158,  749, 2128, 1059, 2769,  679, 1086, 6656,\n",
            "         4534, 1765, 5204, 1434, 4273,  782, 2970, 6240, 3680, 3613, 1343,  704,\n",
            "         1751, 6242, 1962, 6515, 2218, 7431, 7274, 2399, 2769, 1762,  704, 1751,\n",
            "         1728, 5811, 7519, 3300, 5389, 1399, 4960, 4197, 6158, 2380, 6624, 7302,\n",
            "         6868, 7415,  704, 4245, 2769,  947, 6158, 6833, 2802, 7036, 1391, 5973,\n",
            "          679, 4761, 6158, 3800, 2198,  784, 7938, 1315,  886, 4021, 6716, 4604,\n",
            "         4552, 1265, 5617, 4994, 3760,  782, 6221, 2533, 4578, 2769, 4692, 6882,\n",
            "         2399, 6738, 1957, 4495, 6158, 2380, 6624, 1726,  889, 1372, 3298, 1526,\n",
            "         3760,  782, 6303, 5632, 2346, 6158, 2595,  909,  852, 6716, 4158, 1957,\n",
            "          782, 2769, 4761, 6887, 4634, 4495,  784, 7938, 3295, 3300, 5204, 1434,\n",
            "         4273,  782, 2182, 6244, 2769, 6873, 2769, 6291, 5389, 1415, 1179, 2828,\n",
            "         7374, 5804, 1853, 1168, 2769, 1673, 6174, 2769, 5393,  800, 2994,  889,\n",
            "         3681, 2802, 2769, 6158, 5192, 4500, 2797, 7073, 3145, 3430, 2094, 2834,\n",
            "         6359, 8038,  872, 3669,  749, 2769, 1358, 6857, 4934,  907, 6802, 2769,\n",
            "          679, 1963, 1343, 3647,  800, 5481, 2130, 6624, 1139, 1343, 1762, 6624,\n",
            "         2443, 2853, 5839, 1726,  889, 2527, 2902,  749, 7046, 6656, 2205, 6341,\n",
            "         3582, 6303, 8038, 2828, 1961, 2380, 6624, 2769,  947, 4638, 4825,  671,\n",
            "         4684, 6158, 2380, 6624,  100, 2994, 4286, 2791, 3680,  943, 1723, 2791,\n",
            "         6963, 3300, 1995, 1987, 2828, 2361, 3307, 3123, 1762, 2769, 6716,  677,\n",
            "         1728, 4158, 2769, 3221, 1546,  671, 4638, 1912, 1751,  782, 3300, 3582,\n",
            "         3298, 2828, 6857, 6174, 4638, 2658, 3785, 1440, 6260,  686, 4518, 1961,\n",
            "          947, 6303, 8038, 2769,  947, 2218, 5050, 6624, 1139, 4286, 2791, 6917,\n",
            "         3221, 3833, 1762, 4675, 2971,  678,  679, 5052, 2582, 3564, 1986, 4638,\n",
            "         1751, 2157, 5244, 3221, 3683, 2769,  947, 4638, 5632, 4507, 3680, 1921,\n",
            "         6356, 2175, 3298, 6206, 2769,  947,  782,  671, 5175, 5562, 1045, 6132,\n",
            "         3302, 6629, 4989, 6702,  678, 1526, 4638,  782, 3298, 6158, 7442, 3080,\n",
            "         3300, 1995, 1987, 6303, 8038, 1162, 1526,  800,  947, 7515, 1914, 2835,\n",
            "         4836, 2769,  947,  852, 2769,  947, 3300,  928,  814, 4696,  712, 1469,\n",
            "         2769,  947, 1762,  671, 6629,  823, 3172, 5984, 3136, 5412, 6303,  782,\n",
            "         3647, 2527, 6206, 2970, 1358, 4696,  712, 2182, 1161,  852, 2769, 6221,\n",
            "         2533, 2205, 1152, 3724, 2769, 4638,  782,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['北市立建國中學日前發現校內管制的圖書館系統疑遭駭客入侵檢警調查發現周姓畢業校友所為依涉嫌妨害電腦使用罪送辦周男到案坦承他因不滿校方紀錄所有學生資料為抗議校方違反個資法入侵系統周稱他是以猜測密碼方式進入系統建中因得知涉案周男是資優校友考量未造成實際損失對周男撤告台北地檢署今不起訴周男檢警查出周男是理工類組資優生在校期間曾在圖書館打工因此有管理者權限的帳號因進入系統發現裡面紀錄了建中全體學生的個人資料認為有侵犯個資疑慮他畢業後考上國立大學決定入侵學校系統表達抗議據指出周男入侵後將個一般權限帳號的改成管理者權限其中個是測試用的虛擬帳號因圖書館測試時發現登入時間有異且權限遭人打開擔心是駭客入侵向警方報案檢警依位置找到周男周坦承犯行聲稱是靠記憶用管理帳號後猜一下密碼就登入建中知悉是剛畢業的校友犯案認周男只修改個帳號權限並未竄改資訊或造成系統損害向檢方表示撤告意願北檢今不起訴周男中時'], 'input_ids': tensor([[ 101, 1266, 2356, 4989, 2456, 1751,  704, 2119, 3189, 1184, 4634, 4412,\n",
            "         3413, 1058, 5052, 1169, 4638, 1756, 3292, 7631, 5143, 5186, 4542, 6901,\n",
            "         7693, 2145, 1057,  909, 3596, 6356, 6310, 3389, 4634, 4412, 1453, 1998,\n",
            "         4525, 3511, 3413, 1351, 2792, 4158,  898, 3868, 2066, 1981, 2154, 7442,\n",
            "         5582,  886, 4500, 5389, 6843, 6794, 1453, 4511, 1168, 3428, 1788, 2824,\n",
            "          800, 1728,  679, 4021, 3413, 3175, 5145, 7087, 2792, 3300, 2119, 4495,\n",
            "         6536, 3160, 4158, 2834, 6359, 3413, 3175, 6889, 1353,  943, 6536, 3791,\n",
            "         1057,  909, 5143, 5186, 1453, 4935,  800, 3221,  809, 4339, 3947, 2166,\n",
            "         4826, 3175, 2466, 6868, 1057, 5143, 5186, 2456,  704, 1728, 2533, 4761,\n",
            "         3868, 3428, 1453, 4511, 3221, 6536, 1032, 3413, 1351, 5440, 7030, 3313,\n",
            "         6863, 2768, 2179, 7396, 3010, 1927, 2205, 1453, 4511, 3059, 1440, 1378,\n",
            "         1266, 1765, 3596, 5392,  791,  679, 6629, 6260, 1453, 4511, 3596, 6356,\n",
            "         3389, 1139, 1453, 4511, 3221, 4415, 2339, 7546, 5175, 6536, 1032, 4495,\n",
            "         1762, 3413, 3309, 7279, 3295, 1762, 1756, 3292, 7631, 2802, 2339, 1728,\n",
            "         3634, 3300, 5052, 4415, 5442, 3609, 7361, 4638, 2379, 5998, 1728, 6868,\n",
            "         1057, 5143, 5186, 4634, 4412, 6174, 7481, 5145, 7087,  749, 2456,  704,\n",
            "         1059, 7768, 2119, 4495, 4638,  943,  782, 6536, 3160, 6291, 4158, 3300,\n",
            "          909, 4306,  943, 6536, 4542, 2719,  800, 4525, 3511, 2527, 5440,  677,\n",
            "         1751, 4989, 1920, 2119, 3748, 2137, 1057,  909, 2119, 3413, 5143, 5186,\n",
            "         6134, 6888, 2834, 6359, 3087, 2900, 1139, 1453, 4511, 1057,  909, 2527,\n",
            "         2200,  943,  671, 5663, 3609, 7361, 2379, 5998, 4638, 3121, 2768, 5052,\n",
            "         4415, 5442, 3609, 7361, 1071,  704,  943, 3221, 3947, 6275, 4500, 4638,\n",
            "         5995, 3093, 2379, 5998, 1728, 1756, 3292, 7631, 3947, 6275, 3229, 4634,\n",
            "         4412, 4633, 1057, 3229, 7279, 3300, 4530,  684, 3609, 7361, 6901,  782,\n",
            "         2802, 7274, 3085, 2552, 3221, 7693, 2145, 1057,  909, 1403, 6356, 3175,\n",
            "         1841, 3428, 3596, 6356,  898,  855, 5390, 2823, 1168, 1453, 4511, 1453,\n",
            "         1788, 2824, 4306, 6121, 5476, 4935, 3221, 7479, 6250, 2741, 4500, 5052,\n",
            "         4415, 2379, 5998, 2527, 4339,  671,  678, 2166, 4826, 2218, 4633, 1057,\n",
            "         2456,  704, 4761, 2634, 3221, 1190, 4525, 3511, 4638, 3413, 1351, 4306,\n",
            "         3428, 6291, 1453, 4511, 1372,  934, 3121,  943, 2379, 5998, 3609, 7361,\n",
            "          699, 3313, 4985, 3121, 6536, 6244, 2772, 6863, 2768, 5143, 5186, 3010,\n",
            "         2154, 1403, 3596, 3175, 6134, 4850, 3059, 1440, 2692, 7544, 1266, 3596,\n",
            "          791,  679, 6629, 6260, 1453, 4511,  704, 3229,  102,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['硬板廠泰鼎（）日公告月營收億元月增年增單月營收創下今年新高累計前七月營收達億元年增續創歷史同期新高法人預估市場進入傳統旺季加上貿易戰再度開打泰鼎身處東南亞後續有望看到轉單效益看好雙利多因素加持搭配嚴格控管成本以及產品組合轉佳之下第三季營收獲利皆有望再戰新高泰鼎今年在新產品新訂單挹注下上半年即使市場處於淡季仍展現強勁的成長力道不過第二季受到泰國新年假期影響單季營收億元較第一季億元有所下滑但仍優於去年同期的億元雖然該公司尚未公布第二季財務報表但法人預估看好管銷費用仍在降低材料成本會較去年更優產品組合持續優化第二季毛利表現有望優於預期此外法人指出第三季為傳統旺季多數客戶的新產品也將陸續上市由於新品單價高毛利好將帶動營運維持成長態勢更重要的是東南亞製造需求看漲廠前進東南亞的趨勢明確該公司也在積極接洽與布局預計在營運維持漲幅業務逐漸擴大下中長期向上格局不變泰鼎先前也表示過去業界所謂的東南亞投資其實關注的多下注的少如今東南亞不再只是詢問度高已經聽到不少業者確實要押注台灣電子五哥布局東南亞幾乎底定看好組裝廠陸續往東南亞移動放眼中長期對泰鼎來說是絕對有利預期相關效益會落在第四季或明年初開始發酵'], 'input_ids': tensor([[ 101, 4801, 3352, 2449, 3805, 7959, 8020, 8021, 3189, 1062, 1440, 3299,\n",
            "         4245, 3119, 1023, 1039, 3299, 1872, 2399, 1872, 1606, 3299, 4245, 3119,\n",
            "         1201,  678,  791, 2399, 3173, 7770, 5168, 6243, 1184,  673, 3299, 4245,\n",
            "         3119, 6888, 1023, 1039, 2399, 1872, 5265, 1201, 3644, 1380, 1398, 3309,\n",
            "         3173, 7770, 3791,  782, 7521,  844, 2356, 1842, 6868, 1057, 1001, 5186,\n",
            "         3200, 2108, 1217,  677, 6530, 3211, 2782, 1086, 2428, 7274, 2802, 3805,\n",
            "         7959, 6716, 5993, 3346, 1298,  765, 2527, 5265, 3300, 3307, 4692, 1168,\n",
            "         6752, 1606, 3126, 4660, 4692, 1962, 7427, 1164, 1914, 1728, 5162, 1217,\n",
            "         2898, 3022, 6981, 1713, 3419, 2971, 5052, 2768, 3315,  809, 1350, 4496,\n",
            "         1501, 5175, 1394, 6752,  881,  722,  678, 5018,  676, 2108, 4245, 3119,\n",
            "         4363, 1164, 4639, 3300, 3307, 1086, 2782, 3173, 7770, 3805, 7959,  791,\n",
            "         2399, 1762, 3173, 4496, 1501, 3173, 6242, 1606, 2922, 3800,  678,  677,\n",
            "         1288, 2399, 1315,  886, 2356, 1842, 5993, 3176, 3909, 2108,  793, 2245,\n",
            "         4412, 2485, 1233, 4638, 2768, 7269, 1213, 6887,  679, 6882, 5018,  753,\n",
            "         2108, 1358, 1168, 3805, 1751, 3173, 2399,  969, 3309, 2512, 7513, 1606,\n",
            "         2108, 4245, 3119, 1023, 1039, 6733, 5018,  671, 2108, 1023, 1039, 3300,\n",
            "         2792,  678, 3998,  852,  793, 1032, 3176, 1343, 2399, 1398, 3309, 4638,\n",
            "         1023, 1039, 7426, 4197, 6283, 1062, 1385, 2213, 3313, 1062, 2357, 5018,\n",
            "          753, 2108, 6512, 1243, 1841, 6134,  852, 3791,  782, 7521,  844, 4692,\n",
            "         1962, 5052, 7077, 6527, 4500,  793, 1762, 7360,  856, 3332, 3160, 2768,\n",
            "         3315, 3298, 6733, 1343, 2399, 3291, 1032, 4496, 1501, 5175, 1394, 2898,\n",
            "         5265, 1032, 1265, 5018,  753, 2108, 3688, 1164, 6134, 4412, 3300, 3307,\n",
            "         1032, 3176, 7521, 3309, 3634, 1912, 3791,  782, 2900, 1139, 5018,  676,\n",
            "         2108, 4158, 1001, 5186, 3200, 2108, 1914, 3149, 2145, 2786, 4638, 3173,\n",
            "         4496, 1501,  738, 2200, 7380, 5265,  677, 2356, 4507, 3176, 3173, 1501,\n",
            "         1606, 1019, 7770, 3688, 1164, 1962, 2200, 2380, 1240, 4245, 6880, 5204,\n",
            "         2898, 2768, 7269, 2706, 1248, 3291, 7028, 6206, 4638, 3221, 3346, 1298,\n",
            "          765, 6182, 6863, 7444, 3724, 4692, 4039, 2449, 1184, 6868, 3346, 1298,\n",
            "          765, 4638, 6638, 1248, 3209, 4825, 6283, 1062, 1385,  738, 1762, 4948,\n",
            "         3513, 2970, 3835, 5645, 2357, 2229, 7521, 6243, 1762, 4245, 6880, 5204,\n",
            "         2898, 4039, 2388, 3511, 1243, 6852, 4041, 3097, 1920,  678,  704, 7269,\n",
            "         3309, 1403,  677, 3419, 2229,  679, 6365, 3805, 7959, 1044, 1184,  738,\n",
            "         6134, 4850, 6882, 1343, 3511, 4518, 2792, 6333, 4638, 3346, 1298,  765,\n",
            "         2832, 6536, 1071, 2179, 7302, 3800, 4638, 1914,  678, 3800, 4638, 2208,\n",
            "         1963,  791, 3346, 1298,  765,  679, 1086, 1372, 3221, 6273, 1558, 2428,\n",
            "         7770, 2347, 5195, 5481, 1168,  679, 2208, 3511, 5442, 4825, 2179, 6206,\n",
            "         2852, 3800, 1378, 4124, 7442, 2094,  758, 1520, 2357, 2229, 3346, 1298,\n",
            "          765, 2407,  725, 2419, 2137, 4692, 1962, 5175, 6172, 2449, 7380, 5265,\n",
            "         2518, 3346, 1298,  765, 4919, 1240, 3123, 4706,  704, 7269, 3309, 2205,\n",
            "         3805, 7959,  889, 6303, 3221, 5179, 2205, 3300, 1164, 7521, 3309, 4685,\n",
            "         7302, 3126, 4660, 3298, 5862, 1762, 5018, 1724, 2108, 2772, 3209, 2399,\n",
            "         1159, 7274, 1993, 4634, 6997,  102,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['中國人民銀行貨幣政策司司長孫國峰今  表示中國法定準備金率有一定調整空間但空間不會如外界想像的那麼大目前中國的準備金率平均水準大概是 這個水準在開發中國家來說算是中間偏低如果加上超額準備金計算一個總和準備金率中國的水準和已開發中國家相比也是偏低若從法定準備金率的角度來看未來有一定的調整空間但總體來看這個空間並不如大家想像的那麼大而中國央行副行長劉國強指出目前  新機制短期主要看改革情況改革以後則是看市場反映中國降准降息都有空間但是降不降還要根據實際經濟成長和物價形勢這次改革  機制有利於降低貸款利率主要針對的是企業融資成本一般而言市場利率與匯率是直接相關但這次改革並不涉及市場利率的變化而是貸款利率的市場化因此對人民幣匯率沒有直接影響總體來看目前中美利差處於舒適區間中國人行對於人民幣匯率保持在合理均衡水準的基本穩定充滿信心而  新機制使得短期內貸款利率下降可能會對銀行的利差獲利會有一定的影響但另一方面就存款利率來說存款基準利率是保留的而且將在未來較長時間內保留中國人行也將指導市場利率定價自律機制加強對存款利率的自律管理維護市場競爭秩序穩住銀行負債端的成本為銀行可持續發展營造有利的條件從短期來看利率改革對銀行業的影響是不確定的也很難說有一個預估從中長期來看銀行貸款自主定價能力提升有利於銀行可持續健康發展對銀行是有利的'], 'input_ids': tensor([[ 101,  704, 1751,  782, 3696, 7065, 6121, 6515, 2395, 3124, 5032, 1385,\n",
            "         1385, 7269, 2113, 1751, 2292,  791, 6134, 4850,  704, 1751, 3791, 2137,\n",
            "         3976,  991, 7032, 4372, 3300,  671, 2137, 6310, 3146, 4958, 7279,  852,\n",
            "         4958, 7279,  679, 3298, 1963, 1912, 4518, 2682, 1008, 4638, 6929, 7938,\n",
            "         1920, 4680, 1184,  704, 1751, 4638, 3976,  991, 7032, 4372, 2398, 1772,\n",
            "         3717, 3976, 1920, 3519, 3221, 6857,  943, 3717, 3976, 1762, 7274, 4634,\n",
            "          704, 1751, 2157,  889, 6303, 5050, 3221,  704, 7279,  974,  856, 1963,\n",
            "         3362, 1217,  677, 6631, 7540, 3976,  991, 7032, 6243, 5050,  671,  943,\n",
            "         5244, 1469, 3976,  991, 7032, 4372,  704, 1751, 4638, 3717, 3976, 1469,\n",
            "         2347, 7274, 4634,  704, 1751, 2157, 4685, 3683,  738, 3221,  974,  856,\n",
            "         5735, 2537, 3791, 2137, 3976,  991, 7032, 4372, 4638, 6235, 2428,  889,\n",
            "         4692, 3313,  889, 3300,  671, 2137, 4638, 6310, 3146, 4958, 7279,  852,\n",
            "         5244, 7768,  889, 4692, 6857,  943, 4958, 7279,  699,  679, 1963, 1920,\n",
            "         2157, 2682, 1008, 4638, 6929, 7938, 1920, 5445,  704, 1751, 1925, 6121,\n",
            "         1199, 6121, 7269, 1208, 1751, 2485, 2900, 1139, 4680, 1184, 3173, 3582,\n",
            "         1169, 4764, 3309,  712, 6206, 4692, 3121, 7484, 2658, 3785, 3121, 7484,\n",
            "          809, 2527, 1179, 3221, 4692, 2356, 1842, 1353, 3216,  704, 1751, 7360,\n",
            "         1114, 7360, 2622, 6963, 3300, 4958, 7279,  852, 3221, 7360,  679, 7360,\n",
            "         6917, 6206, 3418, 3087, 2179, 7396, 5195, 4089, 2768, 7269, 1469, 4289,\n",
            "         1019, 2501, 1248, 6857, 3613, 3121, 7484, 3582, 1169, 3300, 1164, 3176,\n",
            "         7360,  856, 6526, 3621, 1164, 4372,  712, 6206, 7036, 2205, 4638, 3221,\n",
            "          821, 3511, 6084, 6536, 2768, 3315,  671, 5663, 5445, 6241, 2356, 1842,\n",
            "         1164, 4372, 5645, 1274, 4372, 3221, 4684, 2970, 4685, 7302,  852, 6857,\n",
            "         3613, 3121, 7484,  699,  679, 3868, 1350, 2356, 1842, 1164, 4372, 4638,\n",
            "         6365, 1265, 5445, 3221, 6526, 3621, 1164, 4372, 4638, 2356, 1842, 1265,\n",
            "         1728, 3634, 2205,  782, 3696, 2395, 1274, 4372, 3760, 3300, 4684, 2970,\n",
            "         2512, 7513, 5244, 7768,  889, 4692, 4680, 1184,  704, 5401, 1164, 2345,\n",
            "         5993, 3176, 5653, 6900, 1281, 7279,  704, 1751,  782, 6121, 2205, 3176,\n",
            "          782, 3696, 2395, 1274, 4372,  924, 2898, 1762, 1394, 4415, 1772, 6130,\n",
            "         3717, 3976, 4638, 1825, 3315, 4952, 2137, 1041, 4021,  928, 2552, 5445,\n",
            "         3173, 3582, 1169,  886, 2533, 4764, 3309, 1058, 6526, 3621, 1164, 4372,\n",
            "          678, 7360, 1377, 5543, 3298, 2205, 7065, 6121, 4638, 1164, 2345, 4363,\n",
            "         1164, 3298, 3300,  671, 2137, 4638, 2512, 7513,  852, 1369,  671, 3175,\n",
            "         7481, 2218, 2100, 3621, 1164, 4372,  889, 6303, 2100, 3621, 1825, 3976,\n",
            "         1164, 4372, 3221,  924, 4522, 4638, 5445,  684, 2200, 1762, 3313,  889,\n",
            "         6733, 7269, 3229, 7279, 1058,  924, 4522,  704, 1751,  782, 6121,  738,\n",
            "         2200, 2900, 2206, 2356, 1842, 1164, 4372, 2137, 1019, 5632, 2526, 3582,\n",
            "         1169, 1217, 2485, 2205, 2100, 3621, 1164, 4372, 4638, 5632, 2526, 5052,\n",
            "         4415, 5204, 6362, 2356, 1842, 5000, 4261, 4914, 2415, 4952,  857, 7065,\n",
            "         6121, 6511, 1002, 4999, 4638, 2768, 3315, 4158, 7065, 6121, 1377, 2898,\n",
            "         5265, 4634, 2245, 4245, 6863, 3300, 1164, 4638, 3454,  816, 2537, 4764,\n",
            "         3309,  889, 4692, 1164, 4372, 3121, 7484, 2205, 7065, 6121, 3511, 4638,\n",
            "         2512, 7513, 3221,  679, 4825, 2137, 4638,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['鑽針廠尖點科技（）日法說會公布第三季財報單季合併營收為億元稅後淨利約萬元每股稅後基本盈餘元前三季合併營收億元稅後淨利為億元每股稅後基本盈餘新台幣元尖點表示第三季合併營收與去年同期相比減少近成主要是今年公司執行聚焦收斂策略調整長期營運表現不彰之子公司規模導致近幾個月營收呈現年減不過收斂轉投資子公司規模的減虧效益已反應在第三季的毛利率提升第三季毛利率為是自年以來首度回到以上的水準分別較第二季及去年同期增加及個百分點以各項業務來看第三季鑽針的營收占比為產能利用率有達到旺季水準大約在左右；鑽孔服務為整體稼動約在；而刀具事業營收占比則約為尖點同步公告月合併營收為億元較上月減少較去年同期減少累計前月合併營收達億元較去年同期減少展望第四季尖點認為產業需求已逐漸進入淡季目前公司看到的是正常的需求水準預估第四季鑽針產能利用率可維持在成左右鑽孔稼動約在成刀具則約至成法人指出在小尺寸鑽針供應商增加且價格競爭激烈之下尖點以生產高難度微尺寸的鑽針為主是非日商中出貨量最高的業者看好車用等高階產品帶動鑽針需求回溫以及縮減有虧損的轉投資業務成效顯著即使營收表現可能低於預期但獲利表現有望力拚優於去年表現對該公司後續營運樂觀看待'], 'input_ids': tensor([[ 101, 7148, 7036, 2449, 2211, 7953, 4906, 2825, 8020, 8021, 3189, 3791,\n",
            "         6303, 3298, 1062, 2357, 5018,  676, 2108, 6512, 1841, 1606, 2108, 1394,\n",
            "          882, 4245, 3119, 4158, 1023, 1039, 4922, 2527, 3912, 1164, 5147, 5857,\n",
            "         1039, 3680, 5500, 4922, 2527, 1825, 3315, 4659, 7626, 1039, 1184,  676,\n",
            "         2108, 1394,  882, 4245, 3119, 1023, 1039, 4922, 2527, 3912, 1164, 4158,\n",
            "         1023, 1039, 3680, 5500, 4922, 2527, 1825, 3315, 4659, 7626, 3173, 1378,\n",
            "         2395, 1039, 2211, 7953, 6134, 4850, 5018,  676, 2108, 1394,  882, 4245,\n",
            "         3119, 5645, 1343, 2399, 1398, 3309, 4685, 3683, 3938, 2208, 6818, 2768,\n",
            "          712, 6206, 3221,  791, 2399, 1062, 1385, 1822, 6121, 5471, 4193, 3119,\n",
            "         3150, 5032, 4526, 6310, 3146, 7269, 3309, 4245, 6880, 6134, 4412,  679,\n",
            "         2511,  722, 2094, 1062, 1385, 6211, 3563, 2206, 5636, 6818, 2407,  943,\n",
            "         3299, 4245, 3119, 1439, 4412, 2399, 3938,  679, 6882, 3119, 3150, 6752,\n",
            "         2832, 6536, 2094, 1062, 1385, 6211, 3563, 4638, 3938, 6000, 3126, 4660,\n",
            "         2347, 1353, 2746, 1762, 5018,  676, 2108, 4638, 3688, 1164, 4372, 2990,\n",
            "         1285, 5018,  676, 2108, 3688, 1164, 4372, 4158, 3221, 5632, 2399,  809,\n",
            "          889, 7674, 2428, 1726, 1168,  809,  677, 4638, 3717, 3976, 1146, 1162,\n",
            "         6733, 5018,  753, 2108, 1350, 1343, 2399, 1398, 3309, 1872, 1217, 1350,\n",
            "          943, 4636, 1146, 7953,  809, 1392, 7517, 3511, 1243,  889, 4692, 5018,\n",
            "          676, 2108, 7148, 7036, 4638, 4245, 3119, 1304, 3683, 4158, 4496, 5543,\n",
            "         1164, 4500, 4372, 3300, 6888, 1168, 3200, 2108, 3717, 3976, 1920, 5147,\n",
            "         1762, 2340, 1381, 8039, 7148, 2096, 3302, 1243, 4158, 3146, 7768, 4941,\n",
            "         1240, 5147, 1762, 8039, 5445, 1143, 1072,  752, 3511, 4245, 3119, 1304,\n",
            "         3683, 1179, 5147, 4158, 2211, 7953, 1398, 3635, 1062, 1440, 3299, 1394,\n",
            "          882, 4245, 3119, 4158, 1023, 1039, 6733,  677, 3299, 3938, 2208, 6733,\n",
            "         1343, 2399, 1398, 3309, 3938, 2208, 5168, 6243, 1184, 3299, 1394,  882,\n",
            "         4245, 3119, 6888, 1023, 1039, 6733, 1343, 2399, 1398, 3309, 3938, 2208,\n",
            "         2245, 3307, 5018, 1724, 2108, 2211, 7953, 6291, 4158, 4496, 3511, 7444,\n",
            "         3724, 2347, 6852, 4041, 6868, 1057, 3909, 2108, 4680, 1184, 1062, 1385,\n",
            "         4692, 1168, 4638, 3221, 3633, 2382, 4638, 7444, 3724, 3717, 3976, 7521,\n",
            "          844, 5018, 1724, 2108, 7148, 7036, 4496, 5543, 1164, 4500, 4372, 1377,\n",
            "         5204, 2898, 1762, 2768, 2340, 1381, 7148, 2096, 4941, 1240, 5147, 1762,\n",
            "         2768, 1143, 1072, 1179, 5147, 5635, 2768, 3791,  782, 2900, 1139, 1762,\n",
            "         2207, 2223, 2189, 7148, 7036,  897, 2746, 1555, 1872, 1217,  684, 1019,\n",
            "         3419, 5000, 4261, 4080, 4164,  722,  678, 2211, 7953,  809, 4495, 4496,\n",
            "         7770, 7432, 2428, 2544, 2223, 2189, 4638, 7148, 7036, 4158,  712, 3221,\n",
            "         7478, 3189, 1555,  704, 1139, 6515, 7030, 3297, 7770, 4638, 3511, 5442,\n",
            "         4692, 1962, 6722, 4500, 5023, 7770, 7389, 4496, 1501, 2380, 1240, 7148,\n",
            "         7036, 7444, 3724, 1726, 3984,  809, 1350, 5240, 3938, 3300, 6000, 3010,\n",
            "         4638, 6752, 2832, 6536, 3511, 1243, 2768, 3126, 7549, 5865, 1315,  886,\n",
            "         4245, 3119, 6134, 4412, 1377, 5543,  856, 3176, 7521, 3309,  852, 4363,\n",
            "         1164, 6134, 4412, 3300, 3307, 1213, 2874, 1032, 3176, 1343, 2399, 6134,\n",
            "         4412, 2205, 6283, 1062, 1385, 2527, 5265, 4245, 6880, 3556, 6223, 4692,\n",
            "         2521,  102,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['民陣昨日（日）發起國際人權日遊行稱有萬人參與警方則稱高峰期有萬人網民今日（日）再度號召黎明行動大三罷計劃於大埔沙田灣仔屯門荃灣觀塘深水埗黃大仙油尖旺及將軍澳十區開花香港將留意市面交通情況港鐵表示今早頭班車開出前分別在粉嶺站和屯門站附近發現有外物被投擲至路軌範圍內及架空電纜上車務人員移走有關物件後東鐵綫和西鐵綫頭班車已依時開出沒有受到影響另外在沙田站附近兩列分別上下行方向的列車觸及路軌範圍內的外來雜物列車服務一度受阻現已回復正常兩列受影響列車已返回車廠檢查沙田站：往紅磡方向列車服務暫時運作正常沙田站：警方接報指有垃圾筒跌入路軌內；據報站內有廣播表示列車服務受阻粉嶺站：警方接報指有懷疑晾衫架或衣架架於電纜上屯門站：警方接報指路軌上有疑似鐵枝或鐵通物件但初步沒有影響列車服務港鐵表示東鐵綫的整體行車時間會較平日長至分鐘班次亦會較正常疏落；預計進入車站及於月台候車的時間會較長請預留充裕時間東鐵綫班次會較正常疏落（港鐵網頁）港鐵表示輕鐵所有路綫維持至分鐘一班；但由於個別輕鐵車站設施及信號設備被破壞輕鐵服務調整如下 綫由綫替代 綫在天水圍區由天逸改經濕地公園天榮及天水圍輕鐵站並返回元朗方向 綫不經翠湖及友愛站在天水圍區由天榮改經濕地公園天逸頌富及天耀站並返回屯門方向在屯門區由市中心改經安定及兆麟並改以三聖為終點站 綫前往兆康站方向由綫替代 綫前往屯門碼頭站方向由綫替代 綫在屯門區由市中心改經屯門河田屯門醫院站並返回元朗方向其他路綫維持不變'], 'input_ids': tensor([[ 101, 3696, 7369, 3219, 3189, 8020, 3189, 8021, 4634, 6629, 1751, 7396,\n",
            "          782, 3609, 3189, 6879, 6121, 4935, 3300, 5857,  782, 1347, 5645, 6356,\n",
            "         3175, 1179, 4935, 7770, 2292, 3309, 3300, 5857,  782, 5206, 3696,  791,\n",
            "         3189, 8020, 3189, 8021, 1086, 2428, 5998, 1374, 7944, 3209, 6121, 1240,\n",
            "         1920,  676, 5394, 6243, 1205, 3176, 1920, 1815, 3763, 4506, 4124,  798,\n",
            "         2254, 7271, 5768, 4124, 6223, 1851, 3918, 3717, 1817, 7941, 1920,  803,\n",
            "         3779, 2211, 3200, 1350, 2200, 6725, 4078, 1282, 1281, 7274, 5709, 7676,\n",
            "         3949, 2200, 4522, 2692, 2356, 7481,  769, 6858, 2658, 3785, 3949, 7136,\n",
            "         6134, 4850,  791, 3193, 7531, 4408, 6722, 7274, 1139, 1184, 1146, 1162,\n",
            "         1762, 5106, 2327, 4991, 1469, 2254, 7271, 4991, 7353, 6818, 4634, 4412,\n",
            "         3300, 1912, 4289, 6158, 2832, 3096, 5635, 6662, 6724, 5061, 1752, 1058,\n",
            "         1350, 3373, 4958, 7442, 5271,  677, 6722, 1243,  782, 1519, 4919, 6624,\n",
            "         3300, 7302, 4289,  816, 2527, 3346, 7136, 5202, 1469, 6205, 7136, 5202,\n",
            "         7531, 4408, 6722, 2347,  898, 3229, 7274, 1139, 3760, 3300, 1358, 1168,\n",
            "         2512, 7513, 1369, 1912, 1762, 3763, 4506, 4991, 7353, 6818, 1060, 1154,\n",
            "         1146, 1162,  677,  678, 6121, 3175, 1403, 4638, 1154, 6722, 6240, 1350,\n",
            "         6662, 6724, 5061, 1752, 1058, 4638, 1912,  889, 7429, 4289, 1154, 6722,\n",
            "         3302, 1243,  671, 2428, 1358, 7349, 4412, 2347, 1726, 2541, 3633, 2382,\n",
            "         1060, 1154, 1358, 2512, 7513, 1154, 6722, 2347, 6819, 1726, 6722, 2449,\n",
            "         3596, 3389, 3763, 4506, 4991, 8038, 2518, 5148, 4835, 3175, 1403, 1154,\n",
            "         6722, 3302, 1243, 3271, 3229, 6880,  868, 3633, 2382, 3763, 4506, 4991,\n",
            "         8038, 6356, 3175, 2970, 1841, 2900, 3300, 1796, 1769, 5030, 6649, 1057,\n",
            "         6662, 6724, 1058, 8039, 3087, 1841, 4991, 1058, 3300, 2451, 3064, 6134,\n",
            "         4850, 1154, 6722, 3302, 1243, 1358, 7349, 5106, 2327, 4991, 8038, 6356,\n",
            "         3175, 2970, 1841, 2900, 3300, 2755, 4542, 3256, 6136, 3373, 2772, 6132,\n",
            "         3373, 3373, 3176, 7442, 5271,  677, 2254, 7271, 4991, 8038, 6356, 3175,\n",
            "         2970, 1841, 2900, 6662, 6724,  677, 3300, 4542,  849, 7136, 3363, 2772,\n",
            "         7136, 6858, 4289,  816,  852, 1159, 3635, 3760, 3300, 2512, 7513, 1154,\n",
            "         6722, 3302, 1243, 3949, 7136, 6134, 4850, 3346, 7136, 5202, 4638, 3146,\n",
            "         7768, 6121, 6722, 3229, 7279, 3298, 6733, 2398, 3189, 7269, 5635, 1146,\n",
            "         7132, 4408, 3613,  771, 3298, 6733, 3633, 2382, 4541, 5862, 8039, 7521,\n",
            "         6243, 6868, 1057, 6722, 4991, 1350, 3176, 3299, 1378,  952, 6722, 4638,\n",
            "         3229, 7279, 3298, 6733, 7269, 6313, 7521, 4522, 1041, 6168, 3229, 7279,\n",
            "         3346, 7136, 5202, 4408, 3613, 3298, 6733, 3633, 2382, 4541, 5862, 8020,\n",
            "         3949, 7136, 5206, 7514, 8021, 3949, 7136, 6134, 4850, 6738, 7136, 2792,\n",
            "         3300, 6662, 5202, 5204, 2898, 5635, 1146, 7132,  671, 4408, 8039,  852,\n",
            "         4507, 3176,  943, 1162, 6738, 7136, 6722, 4991, 6257, 3177, 1350,  928,\n",
            "         5998, 6257,  991, 6158, 4788, 1889, 6738, 7136, 3302, 1243, 6310, 3146,\n",
            "         1963,  678, 5202, 4507, 5202, 3296,  807, 5202, 1762, 1921, 3717, 1752,\n",
            "         1281, 4507, 1921, 6871, 3121, 5195, 4086, 1765, 1062, 1754, 1921, 3532,\n",
            "         1350, 1921, 3717, 1752, 6738, 7136, 4991,  699, 6819, 1726, 1039, 3306,\n",
            "         3175, 1403, 5202,  679, 5195, 5428, 3959, 1350, 1351, 2695, 4991, 1762,\n",
            "         1921, 3717, 1752, 1281, 4507, 1921, 3532,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['台股邁入萬一行情勞動基金也交出好成績今年前月收益達億元獲利率創歷年同期新高由於各基金屬性及法規限制不同可投資標的也不同因此收益有所差異其中跟勞工退休金最相關的新制舊制二大基金已一掃去年月股災虧錢陰霾今年以來截至月底分別大賺和攤開基金運用局公告今年月底新舊制勞退基金的持股資料前者前大持股是台積電中華電信鴻海而後者則是台積電台塑鴻海持股比重高且股價已站上元大關的台積電當然挹注可觀收益即使是手上沒有台積電股票的勞工一樣也可以感受到台積電的投資收益因為勞保局每年月底前會將新制勞退基金前年度的盈虧分配到勞工退休金個人專戶裡以目前提繳新制退休金勞工人數約萬人今年前月累積億元收益計算平均每位勞工約分配到萬元不過要提醒的是每位勞工的退休金個人專戶所累積的金額不同分配到的收益也會不同因為新制退休金的累積與個人薪資及有無再自願提繳退休金等因素有關簡單說雖然收益率相同但退休金個人專戶裡所累積的本金越高分配的收益金額才會越高勞工想掌握新制退休金相關資訊可透過勞保局提供的勞工退休金個人專戶管道查詢例如臨櫃到勞保局各地辦事處查詢或使用自然人憑證勞動保障卡自行查詢'], 'input_ids': tensor([[ 101, 1378, 5500, 6914, 1057, 5857,  671, 6121, 2658, 1246, 1240, 1825,\n",
            "         7032,  738,  769, 1139, 1962, 2768, 5245,  791, 2399, 1184, 3299, 3119,\n",
            "         4660, 6888, 1023, 1039, 4363, 1164, 4372, 1201, 3644, 2399, 1398, 3309,\n",
            "         3173, 7770, 4507, 3176, 1392, 1825, 7032, 2253, 2595, 1350, 3791, 6211,\n",
            "         7361, 1169,  679, 1398, 1377, 2832, 6536, 3560, 4638,  738,  679, 1398,\n",
            "         1728, 3634, 3119, 4660, 3300, 2792, 2345, 4530, 1071,  704, 6656, 1246,\n",
            "         2339, 6842,  828, 7032, 3297, 4685, 7302, 4638, 3173, 1169, 5648, 1169,\n",
            "          753, 1920, 1825, 7032, 2347,  671, 2954, 1343, 2399, 3299, 5500, 4134,\n",
            "         6000, 7092, 7374, 7467,  791, 2399,  809,  889, 2779, 5635, 3299, 2419,\n",
            "         1146, 1162, 1920, 6553, 1469, 3113, 7274, 1825, 7032, 6880, 4500, 2229,\n",
            "         1062, 1440,  791, 2399, 3299, 2419, 3173, 5648, 1169, 1246, 6842, 1825,\n",
            "         7032, 4638, 2898, 5500, 6536, 3160, 1184, 5442, 1184, 1920, 2898, 5500,\n",
            "         3221, 1378, 4948, 7442,  704, 5836, 7442,  928, 7862, 3862, 5445, 2527,\n",
            "         5442, 1179, 3221, 1378, 4948, 7442, 1378, 1848, 7862, 3862, 2898, 5500,\n",
            "         3683, 7028, 7770,  684, 5500, 1019, 2347, 4991,  677, 1039, 1920, 7302,\n",
            "         4638, 1378, 4948, 7442, 4534, 4197, 2922, 3800, 1377, 6223, 3119, 4660,\n",
            "         1315,  886, 3221, 2797,  677, 3760, 3300, 1378, 4948, 7442, 5500, 4873,\n",
            "         4638, 1246, 2339,  671, 3564,  738, 1377,  809, 2697, 1358, 1168, 1378,\n",
            "         4948, 7442, 4638, 2832, 6536, 3119, 4660, 1728, 4158, 1246,  924, 2229,\n",
            "         3680, 2399, 3299, 2419, 1184, 3298, 2200, 3173, 1169, 1246, 6842, 1825,\n",
            "         7032, 1184, 2399, 2428, 4638, 4659, 6000, 1146, 6981, 1168, 1246, 2339,\n",
            "         6842,  828, 7032,  943,  782, 2201, 2786, 6174,  809, 4680, 1184, 2990,\n",
            "         5260, 3173, 1169, 6842,  828, 7032, 1246, 2339,  782, 3149, 5147, 5857,\n",
            "          782,  791, 2399, 1184, 3299, 5168, 4948, 1023, 1039, 3119, 4660, 6243,\n",
            "         5050, 2398, 1772, 3680,  855, 1246, 2339, 5147, 1146, 6981, 1168, 5857,\n",
            "         1039,  679, 6882, 6206, 2990, 7008, 4638, 3221, 3680,  855, 1246, 2339,\n",
            "         4638, 6842,  828, 7032,  943,  782, 2201, 2786, 2792, 5168, 4948, 4638,\n",
            "         7032, 7540,  679, 1398, 1146, 6981, 1168, 4638, 3119, 4660,  738, 3298,\n",
            "          679, 1398, 1728, 4158, 3173, 1169, 6842,  828, 7032, 4638, 5168, 4948,\n",
            "         5645,  943,  782, 5959, 6536, 1350, 3300, 4192, 1086, 5632, 7544, 2990,\n",
            "         5260, 6842,  828, 7032, 5023, 1728, 5162, 3300, 7302, 5080, 1606, 6303,\n",
            "         7426, 4197, 3119, 4660, 4372, 4685, 1398,  852, 6842,  828, 7032,  943,\n",
            "          782, 2201, 2786, 6174, 2792, 5168, 4948, 4638, 3315, 7032, 6632, 7770,\n",
            "         1146, 6981, 4638, 3119, 4660, 7032, 7540, 2798, 3298, 6632, 7770, 1246,\n",
            "         2339, 2682, 2958, 2995, 3173, 1169, 6842,  828, 7032, 4685, 7302, 6536,\n",
            "         6244, 1377, 6851, 6882, 1246,  924, 2229, 2990,  897, 4638, 1246, 2339,\n",
            "         6842,  828, 7032,  943,  782, 2201, 2786, 5052, 6887, 3389, 6273,  891,\n",
            "         1963, 5631, 3602, 1168, 1246,  924, 2229, 1392, 1765, 6794,  752, 5993,\n",
            "         3389, 6273, 2772,  886, 4500, 5632, 4197,  782, 2731, 6349, 1246, 1240,\n",
            "          924, 7397, 1305, 5632, 6121, 3389, 6273,  102,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['台灣國產製造桌上型點膠機大廠點膠科技公司為回饋客戶支持推出年終限時回饋方案優惠機型包括自動點膠機出膠控制器優惠活動自即日起至年月日截止機會難得業者宜把握良機搶購點膠科技自動點膠機器人擁有五大特點：（） 高規格設計加介面上傳下載程式容易（）可圓弧補間的控制系統解決各種空間的點膠路徑（）具組程式組別記憶功能符合多樣產品種類使用（）可分外接自動化原件成為多功能生產設備（）單機即可操作安裝最簡易近期又開發成功的容積式精密出膠機特點包括：（）機械式直接加壓於膠水不需要額外空氣氣壓源無膠水量多量少需補償問題（）透過微電腦控制計算能穩定精準的控制出膠量（）具備回吸功能能避免膠水滴漏（）具備回吸功能能避免膠水滴漏（）可以直接連上系列機器工作此新產品適用於各種低黏度膠水使用如  等並可精密出膠於充填微量點膠單點點膠線段點膠分裝點膠封裝點膠等洽詢電話：（）網址：'], 'input_ids': tensor([[ 101, 1378, 4124, 1751, 4496, 6182, 6863, 3430,  677, 1798, 7953, 5608,\n",
            "         3582, 1920, 2449, 7953, 5608, 4906, 2825, 1062, 1385, 4158, 1726, 7637,\n",
            "         2145, 2786, 3118, 2898, 2972, 1139, 2399, 5173, 7361, 3229, 1726, 7637,\n",
            "         3175, 3428, 1032, 2669, 3582, 1798, 1259, 2886, 5632, 1240, 7953, 5608,\n",
            "         3582, 1139, 5608, 2971, 1169, 1690, 1032, 2669, 3833, 1240, 5632, 1315,\n",
            "         3189, 6629, 5635, 2399, 3299, 3189, 2779, 3632, 3582, 3298, 7432, 2533,\n",
            "         3511, 5442, 2139, 2828, 2995, 5679, 3582, 3024, 6554, 7953, 5608, 4906,\n",
            "         2825, 5632, 1240, 7953, 5608, 3582, 1690,  782, 3075, 3300,  758, 1920,\n",
            "         4294, 7953, 8038, 8020, 8021, 7770, 6211, 3419, 6257, 6243, 1217,  792,\n",
            "         7481,  677, 1001,  678, 6734, 4923, 2466, 2159, 3211, 8020, 8021, 1377,\n",
            "         1755, 2479, 6171, 7279, 4638, 2971, 1169, 5143, 5186, 6237, 3748, 1392,\n",
            "         4934, 4958, 7279, 4638, 7953, 5608, 6662, 2529, 8020, 8021, 1072, 5175,\n",
            "         4923, 2466, 5175, 1162, 6250, 2741, 1216, 5543, 5016, 1394, 1914, 3564,\n",
            "         4496, 1501, 4934, 7546,  886, 4500, 8020, 8021, 1377, 1146, 1912, 2970,\n",
            "         5632, 1240, 1265, 1333,  816, 2768, 4158, 1914, 1216, 5543, 4495, 4496,\n",
            "         6257,  991, 8020, 8021, 1606, 3582, 1315, 1377, 3082,  868, 2128, 6172,\n",
            "         3297, 5080, 3211, 6818, 3309, 1348, 7274, 4634, 2768, 1216, 4638, 2159,\n",
            "         4948, 2466, 5125, 2166, 1139, 5608, 3582, 4294, 7953, 1259, 2886, 8038,\n",
            "         8020, 8021, 3582, 3462, 2466, 4684, 2970, 1217, 1886, 3176, 5608, 3717,\n",
            "          679, 7444, 6206, 7540, 1912, 4958, 3706, 3706, 1886, 3975, 4192, 5608,\n",
            "         3717, 7030, 1914, 7030, 2208, 7444, 6171, 1030, 1558, 7539, 8020, 8021,\n",
            "         6851, 6882, 2544, 7442, 5582, 2971, 1169, 6243, 5050, 5543, 4952, 2137,\n",
            "         5125, 3976, 4638, 2971, 1169, 1139, 5608, 7030, 8020, 8021, 1072,  991,\n",
            "         1726, 1429, 1216, 5543, 5543, 6912, 1048, 5608, 3717, 4017, 4026, 8020,\n",
            "         8021, 1072,  991, 1726, 1429, 1216, 5543, 5543, 6912, 1048, 5608, 3717,\n",
            "         4017, 4026, 8020, 8021, 1377,  809, 4684, 2970, 6865,  677, 5143, 1154,\n",
            "         3582, 1690, 2339,  868, 3634, 3173, 4496, 1501, 6900, 4500, 3176, 1392,\n",
            "         4934,  856, 7945, 2428, 5608, 3717,  886, 4500, 1963, 5023,  699, 1377,\n",
            "         5125, 2166, 1139, 5608, 3176, 1041, 1856, 2544, 7030, 7953, 5608, 1606,\n",
            "         7953, 7953, 5608, 5221, 3667, 7953, 5608, 1146, 6172, 7953, 5608, 2196,\n",
            "         6172, 7953, 5608, 5023, 3835, 6273, 7442, 6282, 8038, 8020, 8021, 5206,\n",
            "         1770, 8038,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['近期醫療產業再添多宗併購案包括：西門子宣布將收購美國血管手術機器人製造公司 拜耳擬百分百收購細胞療法公司 都為生醫類股增添活力法人表示今年上半年醫療產業併購案已超過  件金額達去年的六成而且大多鎖定創新醫療相關領域成為推升股價上攻的關鍵要素統計今年以來 世界醫療保健指數那斯達克生技指數各上漲 而代表創新醫療的  健康科技指數漲幅更大達 為傳統醫療類股的三倍第一金全球  精準醫療基金經理人常李奕翰表示創新醫療相關族群今年來漲勢凌厲併購投資活動扮演重要推手以近期為例德國西門子即宣布以收購美國血管手術機器人製造公司 以及拜耳擬百分百收購細胞再生療法公司  剩餘股權等都帶動相關公司股價大漲根據  投行   統計今年上半年健康醫療產業併購案已超過  件總金額達  億美元為去年全年  億美元的六成水準而且多數併購都與創新醫療相關如：羅氏收購基因治療廠商  嬌生併購外科手術機器人公司   等常李奕翰指出併購活絡的原因是傳統藥廠生技公司為了強化自身產品線市佔率透過跨業同行整併往新醫療方式新產品邁進這些新醫療新產品包括：預防醫學基因療法免疫療法 人工智慧輔助醫學影像伴隨式診斷醫療機器人無線監測與遠距照護醫療大數據建構與處理等常李奕翰表示對於藥廠生技或醫療新創公司藉由併購方式可以降低進入門檻強化產品研發實力快速取得市場擴大產品出海口；對於一般人來說投資布局創新醫療產業同樣可以參與成長的機會一舉數得第一金投信獨立經營管理本基金經金管會核准或同意生效惟不表示絕無風險基金經理公司以往之經理績效不保證基金之最低投資收益；基金經理公司除盡善良管理人之注意義務外不負責基金之盈虧亦不保證最低之收益投資人申購前應詳閱基金公開說明書有關基金應負擔之費用（境外基金含分銷費用反稀釋費用）及基金之相關投資風險已揭露於基金之公開說明書或投資人須知中本公司及各銷售機構備有公開說明書歡迎索取或自行至本公司官網（）公開資訊觀測站（）或境外基金資訊觀測站（）下載投資人應注意基金投資之風險包括匯率風險利率風險債券交易市場流動性不足之風險及投資無擔保公司債之風險；基金或有因利率變動債券交易市場流動性不足及定期存單提前解約而影響基金淨值下跌之風險同時或有受益人大量贖回時致延遲給付贖回價款之可能基金高收益債券之投資占顯著比重者適合能承受較高風險之非保守型之投資人由於高收益債券之信用評等未達投資等級或未經信用評等且對利率變動的敏感度甚高故本基金可能會因利率上升市場流動性下降或債券發行機構違約不支付本金利息或破產而蒙受虧損投資人應審慎評估本基金不適合無法承擔相關風險之投資人投資人投資以高收益債券為訴求之基金不宜占其投資組合過高之比重投資高收益債券之基金可能投資美國   債券（境內基金投資比例最高可達基金總資產 ）該債券屬私募性質易發生流動性不足財務訊息揭露不完整或價格不透明導致高波動性之風險部分可配息基金配息前未先扣除應負擔之相關費用且基金的配息可能由基金的收益或本金中支付任何涉及由本金支出的部份可能導致原始投資金額以同等比例減損基金配息率不代表基金報酬率且過去配息率不代表未來配息率；基金淨值可能因市場因素而上下波動投資人可至本公司官網查詢最近  個月內由本金支付之配息組成項目基金配息之年化配息率為估算值計算公式為每單位配息金額  除息日前一日之淨值 × 一年配息次數 × 各期間報酬率 含息 是假設收益分配均滾入再投資於本基金之期間累積報酬率內容涉及新興市場部分因其波動性與風險程度較高且政治與經濟情勢穩定度可能低於已開發國家可能使資產價值受不同程度之影響現階段法令限制投資於中國證券市場僅限掛牌上市之有價證券且境外基金總金額不得超過基金淨資產價值 中國大陸為外匯管制市場投資相關有價證券可能有資金無法即時匯回之風險或可能因特殊情事致延遲給付買回價款投資人另須留意中國巿場特定政治經濟法規與巿場等投資風險匯率走勢可能影響所投資之海外資產而使資產價值變動本資料提及之經濟走勢預測不必然代表該基金之績效基金投資風險請詳閱基金公開說明書投資人因不同時間進場將有不同之投資績效過去之績效亦不代表未來績效之保證以過去績效進行模擬投資組合之報酬率僅為歷史資料模擬投資組合之結果不代表任何基金或相關投資組合之實際報酬率及未來績效保證；不同時間進行模擬操作結果可能不同本資料提及之企業指數或投資標的僅為舉例說明之用不代表任何投資之推薦有關未成立之基金初期資產配置僅為暫訂之規劃實際投資配置可能依市場狀況而改變基金風險報酬等級依投信投顧公會分類標準由低至高分為  等五個等級此分類係基於一般市況反映市場價格波動風險無法涵蓋所有風險不宜作為投資唯一依據投資人仍應注意所投資基金之個別風險並考量個人風險承擔能力資金可運用期間等始為投資判斷本基金之風險可能含有產業景氣循環變動流動性不足外匯管制投資地區政經社會變動或其他投資風險遞延手續費  級別持有未滿  年手續費率分別為 於買回時以申購金額贖回金額孰低計收滿  年者免付本新聞稿內容僅供參考若將新聞稿再編製者應以本公司所公開資料為主不得為誇大不實之報導'], 'input_ids': tensor([[ 101, 6818, 3309, 7015, 4615, 4496, 3511, 1086, 3924, 1914, 2134,  882,\n",
            "         6554, 3428, 1259, 2886, 8038, 6205, 7271, 2094, 2146, 2357, 2200, 3119,\n",
            "         6554, 5401, 1751, 6117, 5052, 2797, 6123, 3582, 1690,  782, 6182, 6863,\n",
            "         1062, 1385, 2876, 5455, 3093, 4636, 1146, 4636, 3119, 6554, 5169, 5528,\n",
            "         4615, 3791, 1062, 1385, 6963, 4158, 4495, 7015, 7546, 5500, 1872, 3924,\n",
            "         3833, 1213, 3791,  782, 6134, 4850,  791, 2399,  677, 1288, 2399, 7015,\n",
            "         4615, 4496, 3511,  882, 6554, 3428, 2347, 6631, 6882,  816, 7032, 7540,\n",
            "         6888, 1343, 2399, 4638, 1063, 2768, 5445,  684, 1920, 1914, 7115, 2137,\n",
            "         1201, 3173, 7015, 4615, 4685, 7302, 7526, 1818, 2768, 4158, 2972, 1285,\n",
            "         5500, 1019,  677, 3122, 4638, 7302, 7107, 6206, 5162, 5186, 6243,  791,\n",
            "         2399,  809,  889,  686, 4518, 7015, 4615,  924,  978, 2900, 3149, 6929,\n",
            "         3172, 6888, 1046, 4495, 2825, 2900, 3149, 1392,  677, 4039, 5445,  807,\n",
            "         6134, 1201, 3173, 7015, 4615, 4638,  978, 2434, 4906, 2825, 2900, 3149,\n",
            "         4039, 2388, 3291, 1920, 6888, 4158, 1001, 5186, 7015, 4615, 7546, 5500,\n",
            "         4638,  676,  945, 5018,  671, 7032, 1059, 4413, 5125, 3976, 7015, 4615,\n",
            "         1825, 7032, 5195, 4415,  782, 2382, 3330, 1945, 5432, 6134, 4850, 1201,\n",
            "         3173, 7015, 4615, 4685, 7302, 3184, 5408,  791, 2399,  889, 4039, 1248,\n",
            "         1119, 1341,  882, 6554, 2832, 6536, 3833, 1240, 2815, 4028, 7028, 6206,\n",
            "         2972, 2797,  809, 6818, 3309, 4158,  891, 2548, 1751, 6205, 7271, 2094,\n",
            "         1315, 2146, 2357,  809, 3119, 6554, 5401, 1751, 6117, 5052, 2797, 6123,\n",
            "         3582, 1690,  782, 6182, 6863, 1062, 1385,  809, 1350, 2876, 5455, 3093,\n",
            "         4636, 1146, 4636, 3119, 6554, 5169, 5528, 1086, 4495, 4615, 3791, 1062,\n",
            "         1385, 1197, 7626, 5500, 3609, 5023, 6963, 2380, 1240, 4685, 7302, 1062,\n",
            "         1385, 5500, 1019, 1920, 4039, 3418, 3087, 2832, 6121, 5186, 6243,  791,\n",
            "         2399,  677, 1288, 2399,  978, 2434, 7015, 4615, 4496, 3511,  882, 6554,\n",
            "         3428, 2347, 6631, 6882,  816, 5244, 7032, 7540, 6888, 1023, 5401, 1039,\n",
            "         4158, 1343, 2399, 1059, 2399, 1023, 5401, 1039, 4638, 1063, 2768, 3717,\n",
            "         3976, 5445,  684, 1914, 3149,  882, 6554, 6963, 5645, 1201, 3173, 7015,\n",
            "         4615, 4685, 7302, 1963, 8038, 5397, 3694, 3119, 6554, 1825, 1728, 3780,\n",
            "         4615, 2449, 1555, 2081, 4495,  882, 6554, 1912, 4906, 2797, 6123, 3582,\n",
            "         1690,  782, 1062, 1385, 5023, 2382, 3330, 1945, 5432, 2900, 1139,  882,\n",
            "         6554, 3833, 5181, 4638, 1333, 1728, 3221, 1001, 5186, 5973, 2449, 4495,\n",
            "         2825, 1062, 1385, 4158,  749, 2485, 1265, 5632, 6716, 4496, 1501, 5221,\n",
            "         2356,  861, 4372, 6851, 6882, 6659, 3511, 1398, 6121, 3146,  882, 2518,\n",
            "         3173, 7015, 4615, 3175, 2466, 3173, 4496, 1501, 6914, 6868, 6857,  763,\n",
            "         3173, 7015, 4615, 3173, 4496, 1501, 1259, 2886, 8038, 7521, 7344, 7015,\n",
            "         2119, 1825, 1728, 4615, 3791, 1048, 4554, 4615, 3791,  782, 2339, 3255,\n",
            "         2716, 6737, 1221, 7015, 2119, 2512, 1008,  845, 7401, 2466, 6262, 3174,\n",
            "         7015, 4615, 3582, 1690,  782, 4192, 5221, 4675, 3947, 5645, 6895, 6655,\n",
            "         4212, 6362, 7015, 4615, 1920, 3149, 3087, 2456, 3539, 5645, 5993, 4415,\n",
            "         5023, 2382, 3330, 1945, 5432, 6134, 4850, 2205, 3176, 5973, 2449, 4495,\n",
            "         2825, 2772, 7015, 4615, 3173, 1201, 1062, 1385, 5964, 4507,  882, 6554,\n",
            "         3175, 2466, 1377,  809, 7360,  856, 6868,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['一週回顧及表現成熟市場 兩黨達成協議暫停美國債務上限直到明年大選過後； 上週五發布報告稱如果美對中餘下商品關稅提高到 中國接下來一年經濟成長將降低 並且全球將有顯著的負面溢出效應中美貿易衝突升級令美股上週下跌 ； 同屬義大利執政聯盟的政黨 日對總理孔蒂發起不信任投票引起政治不確定性升高歐洲股市下跌 新興市場 美國白宮暗示中國購買美國產品有助關稅談判然而中國強硬回應認為美國態度反覆目前沒有談判的實質意義；另外美將中國列為匯率操縱國並將與  接洽以消除不公平競爭中國股市大跌 ； 拉丁美洲股市在個股利多消息下不跌反漲；印度央行  日宣布降息  個基點為今年以來第四度降息印度股市上漲 債券市場 隨著貿易戰一再升溫美國  年期政府債券殖利率下滑至 與  個月期殖利率利差大幅擴大美國政府債券指數價格上漲 美國投資等級債券也上漲 ； 上週新興市場多個國家宣布降息包含泰國印度和紐西蘭央行紐西蘭儲備銀行行長   更在新聞發布會上表示未來還會繼續降息甚至不排除負利率新興國家央行降息潮帶動新興市場主權債上漲 原物料匯率 美國原油庫存上升加上經濟不確定性影響之下油價受到重挫沙國已與其他產油國討論遏制油價下跌的選項； 市場避險情緒激增加上本週許多國家降息推升金價突破  元單週上漲 資料來源  （顯示數據為週漲跌幅結果 資料截至 ）市場報酬率資料來源  （圖中顯示數據為週漲跌幅結果 資料截至 ）三大市場關鍵事件及分析 美國指控中國操縱匯率美國財政部將中國列為匯率操縱國但從近期人民幣貶值幅度來看中國只是跟隨其他新興市場貨幣走弱在貿易盈餘減少且勞務帳赤字龐大下人民幣未來仍有貶值壓力資料來源：鉅亨買基金整理 印度與巴基斯坦衝突印度廢除賦與查摩與喀什米爾省獨立地位的憲法第  條並派軍隊前往這兩個省份引起巴基斯坦與中國不滿更傳出巴基斯坦與印度軍隊展開小規模交火資料來源：時代雜誌鉅亨買基金整理 金價升破每盎司  美元大關黃金價格升破每盎司  美元的關卡且從去年底以來在美元指數維持強勢的情形下黃金一路走高顯示各國貨幣的實質購買力全面下降資料來源：鉅亨買基金整理本週關鍵數據行事曆資料來源 鉅亨買基金整理鉅亨投顧獨立經營管理本資料僅供參考鉅亨買基金已盡力就可靠之資料來源提供正確之意見與消息但無法保證該等資料之完整性內容涉及新興市場部分因其波動性與風險程度可能較高且其政治與經濟情勢穩定度可能低於已開發國家也可能使資產價值受不同程度之影響匯率走勢亦可能影響所投資之海外資產價值變動投資人應依其本身之判斷投資若有損益或因使用本資料所生之直接或間接損失應由投資人自行負責本公司無須負擔任何責任本文提及之經濟走勢預測不必然代表基金之績效基金投資風險請詳閱基金公開說明書及投資人須知基金經金管會核准或同意生效惟不表示絕無風險基金經理公司以往之經理績效不保證基金最低投資收益；基金經理公司除盡善良管理人之注意義務外不負責基金之盈虧亦不保證最低之收益投資人申購前應詳閱基金公開說明書及投資人須知各銷售機構備有基金公開說明書及投資人須知歡迎索取有關基金應負擔之費用（境外基金含分銷費用）已揭露於基金之公開說明書或投資人須知中投資人可至公開資訊觀測站或境外基金資訊觀測站中查詢投資人投資以高收益債券為訴求之基金不宜占其投資組合過高之比重基金經金管會核准或同意生效惟不表示絕無風險由於高收益債券之信用評等未達投資等級或未經信用評等且對利率變動的敏感度甚高故基金可能會因利率上升市場流動性下降或債券發行機構違約不支付本金利息或破產而蒙受虧損投資人應審慎評估該等基金不適合無法承擔相關風險之投資人基金經理公司以往之經理績效不保證基金最低投資收益；基金經理公司除盡善良管理人之注意義務外不負責基金之盈虧亦不保證最低之收益投資人申購前應詳閱基金公開說明書及投資人須知投資於   債券境內高收益債券基金最高可投資基金總資產  境內以投資新興市場國家為主之債券型基金及平衡型基金最高可投資基金總資產  境外高收益債券基金可能有部分投資於美國   債券該債券屬私募性質較可能發生流動性不足財務訊息揭露不完整或因價格不透明導致波動性較大之風險不動產證券化型基金得投資於高收益債券其投資總金額不得超過基金淨資產價值之 投資人因不同時間進場將有不同之投資績效過去之績效亦不代表未來績效之保證基金配息率不代表基金報酬率且過去配息率不代表未來配息率；基金淨值可能因市場因素而上下波動基金配息前未先扣除應負擔之相關費用基金的配息可能由基金的收益或本金中支付任何涉及由本金支出的部份可能導致原始投資金額減損鉅亨證券投資顧問股份有限公司  客服信箱：公司地址：台北市信義區松仁路  號  樓  室  服務專線：  服務時間：'], 'input_ids': tensor([[ 101,  671, 6867, 1726, 7547, 1350, 6134, 4412, 2768, 4225, 2356, 1842,\n",
            "         1060, 7955, 6888, 2768, 1295, 6359, 3271,  977, 5401, 1751, 1002, 1243,\n",
            "          677, 7361, 4684, 1168, 3209, 2399, 1920, 6908, 6882, 2527, 8039,  677,\n",
            "         6867,  758, 4634, 2357, 1841, 1440, 4935, 1963, 3362, 5401, 2205,  704,\n",
            "         7626,  678, 1555, 1501, 7302, 4922, 2990, 7770, 1168,  704, 1751, 2970,\n",
            "          678,  889,  671, 2399, 5195, 4089, 2768, 7269, 2200, 7360,  856,  699,\n",
            "          684, 1059, 4413, 2200, 3300, 7549, 5865, 4638, 6511, 7481, 3980, 1139,\n",
            "         3126, 2746,  704, 5401, 6530, 3211, 6128, 4960, 1285, 5159,  808, 5401,\n",
            "         5500,  677, 6867,  678, 6649, 8039, 1398, 2253, 5412, 1920, 1164, 1822,\n",
            "         3124, 5474, 4673, 4638, 3124, 7955, 3189, 2205, 5244, 4415, 2096, 5881,\n",
            "         4634, 6629,  679,  928,  818, 2832, 4873, 2471, 6629, 3124, 3780,  679,\n",
            "         4825, 2137, 2595, 1285, 7770, 3627, 3828, 5500, 2356,  678, 6649, 3173,\n",
            "         5646, 2356, 1842, 5401, 1751, 4635, 2152, 3266, 4850,  704, 1751, 6554,\n",
            "         6525, 5401, 1751, 4496, 1501, 3300, 1221, 7302, 4922, 6312, 1161, 4197,\n",
            "         5445,  704, 1751, 2485, 4801, 1726, 2746, 6291, 4158, 5401, 1751, 2706,\n",
            "         2428, 1353, 6208, 4680, 1184, 3760, 3300, 6312, 1161, 4638, 2179, 6549,\n",
            "         2692, 5412, 8039, 1369, 1912, 5401, 2200,  704, 1751, 1154, 4158, 1274,\n",
            "         4372, 3082, 5241, 1751,  699, 2200, 5645, 2970, 3835,  809, 3867, 7370,\n",
            "          679, 1062, 2398, 5000, 4261,  704, 1751, 5500, 2356, 1920, 6649, 8039,\n",
            "         2861,  672, 5401, 3828, 5500, 2356, 1762,  943, 5500, 1164, 1914, 3867,\n",
            "         2622,  678,  679, 6649, 1353, 4039, 8039, 1313, 2428, 1925, 6121, 3189,\n",
            "         2146, 2357, 7360, 2622,  943, 1825, 7953, 4158,  791, 2399,  809,  889,\n",
            "         5018, 1724, 2428, 7360, 2622, 1313, 2428, 5500, 2356,  677, 4039, 1002,\n",
            "         1171, 2356, 1842, 7401, 5865, 6530, 3211, 2782,  671, 1086, 1285, 3984,\n",
            "         5401, 1751, 2399, 3309, 3124, 2424, 1002, 1171, 3658, 1164, 4372,  678,\n",
            "         3998, 5635, 5645,  943, 3299, 3309, 3658, 1164, 4372, 1164, 2345, 1920,\n",
            "         2388, 3097, 1920, 5401, 1751, 3124, 2424, 1002, 1171, 2900, 3149, 1019,\n",
            "         3419,  677, 4039, 5401, 1751, 2832, 6536, 5023, 5159, 1002, 1171,  738,\n",
            "          677, 4039, 8039,  677, 6867, 3173, 5646, 2356, 1842, 1914,  943, 1751,\n",
            "         2157, 2146, 2357, 7360, 2622, 1259, 1419, 3805, 1751, 1313, 2428, 1469,\n",
            "         5153, 6205, 5984, 1925, 6121, 5153, 6205, 5984, 1033,  991, 7065, 6121,\n",
            "         6121, 7269, 3291, 1762, 3173, 5472, 4634, 2357, 3298,  677, 6134, 4850,\n",
            "         3313,  889, 6917, 3298, 5262, 5265, 7360, 2622, 4493, 5635,  679, 2961,\n",
            "         7370, 6511, 1164, 4372, 3173, 5646, 1751, 2157, 1925, 6121, 7360, 2622,\n",
            "         4060, 2380, 1240, 3173, 5646, 2356, 1842,  712, 3609, 1002,  677, 4039,\n",
            "         1333, 4289, 3160, 1274, 4372, 5401, 1751, 1333, 3779, 2430, 2100,  677,\n",
            "         1285, 1217,  677, 5195, 4089,  679, 4825, 2137, 2595, 2512, 7513,  722,\n",
            "          678, 3779, 1019, 1358, 1168, 7028, 2919, 3763, 1751, 2347, 5645, 1071,\n",
            "          800, 4496, 3779, 1751, 6245, 6316, 6883, 1169, 3779, 1019,  678, 6649,\n",
            "         4638, 6908, 7517, 8039, 2356, 1842, 6912, 7402, 2658, 5219, 4080, 1872,\n",
            "         1217,  677, 3315, 6867, 6258, 1914, 1751, 2157, 7360, 2622, 2972, 1285,\n",
            "         7032, 1019, 4960, 4788, 1039, 1606, 6867,  677, 4039, 6536, 3160,  889,\n",
            "         3975, 8020, 7549, 4850, 3149, 3087, 4158,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['記者溫于德台北報導歲偷拍狼王忠祥三度偷拍女子如廁畫面直到最後一人受害後察覺有異取出相機鏡頭後報警處理才揪出王男狼行士林地檢署查出王男其中兩次利用 水管相機遠端犯案且直到偵查接近終結才承認犯案堪稱態度不佳依妨害秘密罪嫌將王男提起公訴並建請法官從重量刑據悉沒有前科的王男是韓裔台僑曾留學美國也曾在竹科開科技公司住大直明水路一間多坪的豪宅已婚育有個小孩最大的已上國中檢警去年到他家搜索時王妻得知丈夫涉嫌偷拍傷心直說怎麼可能請繼續往下閱讀起訴指出年月日上午時許王男在台北市內湖區港墘路維修中心廁所內以不詳工具竊錄女子如廁畫面及隱私部位；第二次則在去年月日中午時許於內湖區洲子街星巴克廁所內先將 相機鏡頭裝設在廁所內層板下方待下午時許有女子如廁後王男隨即利用手機遠端遙控開啟相機錄影功能竊錄成功至於王男偷拍之所以會被揭穿是因王男持續在星巴克內偷拍到第二名女子如廁畫面遭發現立刻取出相機鏡頭並報警處理王男見警方到場倉皇離開但檢方早已掌握王男身分經向院方聲請搜索獲准檢警在王男住處起獲筆記型電腦部手機支攝影機部外接硬碟及隨身碟共個檢方表示王男自年月起有多次以手機竊錄女子如廁或身體隱私部位行為且王到案後均否認犯罪或辯稱忘記了直到偵查終結才承認犯罪堪稱犯後態度不佳建請法官從重量刑'], 'input_ids': tensor([[ 101, 6250, 5442, 3984,  754, 2548, 1378, 1266, 1841, 2206, 3641,  982,\n",
            "         2864, 4331, 4374, 2566, 4872,  676, 2428,  982, 2864, 1957, 2094, 1963,\n",
            "         2438, 4529, 7481, 4684, 1168, 3297, 2527,  671,  782, 1358, 2154, 2527,\n",
            "         2175, 6221, 3300, 4530, 1357, 1139, 4685, 3582, 7128, 7531, 2527, 1841,\n",
            "         6356, 5993, 4415, 2798, 2998, 1139, 4374, 4511, 4331, 6121, 1894, 3360,\n",
            "         1765, 3596, 5392, 3389, 1139, 4374, 4511, 1071,  704, 1060, 3613, 1164,\n",
            "         4500, 3717, 5052, 4685, 3582, 6895, 4999, 4306, 3428,  684, 4684, 1168,\n",
            "          980, 3389, 2970, 6818, 5173, 5178, 2798, 2824, 6291, 4306, 3428, 1838,\n",
            "         4935, 2706, 2428,  679,  881,  898, 1981, 2154, 4908, 2166, 5389, 2066,\n",
            "         2200, 4374, 4511, 2990, 6629, 1062, 6260,  699, 2456, 6313, 3791, 2135,\n",
            "         2537, 7028, 7030, 1152, 3087, 2634, 3760, 3300, 1184, 4906, 4638, 4374,\n",
            "         4511, 3221, 7502, 6167, 1378, 1009, 3295, 4522, 2119, 5401, 1751,  738,\n",
            "         3295, 1762, 5001, 4906, 7274, 4906, 2825, 1062, 1385,  857, 1920, 4684,\n",
            "         3209, 3717, 6662,  671, 7279, 1914, 1790, 4638, 6498, 2125, 2347, 2042,\n",
            "         5509, 3300,  943, 2207, 2111, 3297, 1920, 4638, 2347,  677, 1751,  704,\n",
            "         3596, 6356, 1343, 2399, 1168,  800, 2157, 3017, 5164, 3229, 4374, 1988,\n",
            "         2533, 4761,  675, 1923, 3868, 2066,  982, 2864, 1003, 2552, 4684, 6303,\n",
            "         2582, 7938, 1377, 5543, 6313, 5262, 5265, 2518,  678, 7288, 6364, 6629,\n",
            "         6260, 2900, 1139, 2399, 3299, 3189,  677, 1286, 3229, 6258, 4374, 4511,\n",
            "         1762, 1378, 1266, 2356, 1058, 3959, 1281, 3949, 1869, 6662, 5204,  934,\n",
            "          704, 2552, 2438, 2792, 1058,  809,  679, 6284, 2339, 1072, 4988, 7087,\n",
            "         1957, 2094, 1963, 2438, 4529, 7481, 1350, 7403, 4900, 6956,  855, 8039,\n",
            "         5018,  753, 3613, 1179, 1762, 1343, 2399, 3299, 3189,  704, 1286, 3229,\n",
            "         6258, 3176, 1058, 3959, 1281, 3828, 2094, 6125, 3215, 2349, 1046, 2438,\n",
            "         2792, 1058, 1044, 2200, 4685, 3582, 7128, 7531, 6172, 6257, 1762, 2438,\n",
            "         2792, 1058, 2251, 3352,  678, 3175, 2521,  678, 1286, 3229, 6258, 3300,\n",
            "         1957, 2094, 1963, 2438, 2527, 4374, 4511, 7401, 1315, 1164, 4500, 2797,\n",
            "         3582, 6895, 4999, 6891, 2971, 7274, 1564, 4685, 3582, 7087, 2512, 1216,\n",
            "         5543, 4988, 7087, 2768, 1216, 5635, 3176, 4374, 4511,  982, 2864,  722,\n",
            "         2792,  809, 3298, 6158, 2999, 4959, 3221, 1728, 4374, 4511, 2898, 5265,\n",
            "         1762, 3215, 2349, 1046, 1058,  982, 2864, 1168, 5018,  753, 1399, 1957,\n",
            "         2094, 1963, 2438, 4529, 7481, 6901, 4634, 4412, 4989, 1174, 1357, 1139,\n",
            "         4685, 3582, 7128, 7531,  699, 1841, 6356, 5993, 4415, 4374, 4511, 6210,\n",
            "         6356, 3175, 1168, 1842,  942, 4640, 7431, 7274,  852, 3596, 3175, 3193,\n",
            "         2347, 2958, 2995, 4374, 4511, 6716, 1146, 5195, 1403, 7368, 3175, 5476,\n",
            "         6313, 3017, 5164, 4363, 1114, 3596, 6356, 1762, 4374, 4511,  857, 5993,\n",
            "         6629, 4363, 5022, 6250, 1798, 7442, 5582, 6956, 2797, 3582, 3118, 3109,\n",
            "         2512, 3582, 6956, 1912, 2970, 4801, 4817, 1350, 7401, 6716, 4817, 1066,\n",
            "          943, 3596, 3175, 6134, 4850, 4374, 4511, 5632, 2399, 3299, 6629, 3300,\n",
            "         1914, 3613,  809, 2797, 3582, 4988, 7087, 1957, 2094, 1963, 2438, 2772,\n",
            "         6716, 7768, 7403, 4900, 6956,  855, 6121, 4158,  684, 4374, 1168, 3428,\n",
            "         2527, 1772, 1415, 6291, 4306, 5389, 2772, 6800, 4935, 2563, 6250,  749,\n",
            "         4684, 1168,  980, 3389, 5173, 5178, 2798,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['多媒體創作軟體廠訊連科技  本業獲利表現持穩 訂閱制營運步入軌道且優於先前預期人臉辨識業務也有上百個案例正在洽談中第  季將有業外處分投資性不動產的收益入帳估將貢獻第  季每股純益約  元法人看好訊連第  季  可望挑戰逾  年來新高訊連子公司  先前公告處分投資性不動產預計處分收益約  萬美元 約合新台幣  萬元本季就可望完成交易挹注第  季財報表現法人預估此次子公司處分投資性不動產將貢獻訊連第  季每股純益約  元且由於本業獲利表現持穩訊連第  季  可望挑戰逾  年來新高訊連日前推出新一代創意導演家族包含威力導演 等  套旗艦級多媒體創作軟體由於創意導演家族先前採取買斷制遭遇營運困境訊連因而推出訂閱制進行營運轉型來自訂閱制的訂單比率由  年的 大幅成長至去年的近  成表現超越先前預期訊連執行長黃肇雄表示今年目前為止已有逾  成既有用戶轉為訂閱制更有高達  成的台灣用戶轉向訂閱顯示租賃模式表現持續良好預期今年第  季起可產生可觀的循環性營收除  訂閱制的創意導演家族外訊連其他三大引擎包括  人臉辨識及正在開發中的    支援  與  平台其中人臉辨識具高度成長潛力已有上百個正在洽談中的案例將成為訊連營運成長的重要引擎目前訊連  整合即時通知系統  已成功打入美國醫院與零售商並獲國內金融警政與停車場等採用將在明後年陸續建置可望為後市營運增添強勁成長動能訊連第  季稅後純益  萬元季增 年減 每股純益  元；上半年稅後純益  億元年減 每股純益  元'], 'input_ids': tensor([[ 101, 1914, 2054, 7768, 1201,  868, 6727, 7768, 2449, 6244, 6865, 4906,\n",
            "         2825, 3315, 3511, 4363, 1164, 6134, 4412, 2898, 4952, 6242, 7288, 1169,\n",
            "         4245, 6880, 3635, 1057, 6724, 6887,  684, 1032, 3176, 1044, 1184, 7521,\n",
            "         3309,  782, 5622, 6795, 6352, 3511, 1243,  738, 3300,  677, 4636,  943,\n",
            "         3428,  891, 3633, 1762, 3835, 6312,  704, 5018, 2108, 2200, 3300, 3511,\n",
            "         1912, 5993, 1146, 2832, 6536, 2595,  679, 1240, 4496, 4638, 3119, 4660,\n",
            "         1057, 2379,  844, 2200, 6513, 4368, 5018, 2108, 3680, 5500, 5155, 4660,\n",
            "         5147, 1039, 3791,  782, 4692, 1962, 6244, 6865, 5018, 2108, 1377, 3307,\n",
            "         2904, 2782, 6874, 2399,  889, 3173, 7770, 6244, 6865, 2094, 1062, 1385,\n",
            "         1044, 1184, 1062, 1440, 5993, 1146, 2832, 6536, 2595,  679, 1240, 4496,\n",
            "         7521, 6243, 5993, 1146, 3119, 4660, 5147, 5857, 5401, 1039, 5147, 1394,\n",
            "         3173, 1378, 2395, 5857, 1039, 3315, 2108, 2218, 1377, 3307, 2130, 2768,\n",
            "          769, 3211, 2922, 3800, 5018, 2108, 6512, 1841, 6134, 4412, 3791,  782,\n",
            "         7521,  844, 3634, 3613, 2094, 1062, 1385, 5993, 1146, 2832, 6536, 2595,\n",
            "          679, 1240, 4496, 2200, 6513, 4368, 6244, 6865, 5018, 2108, 3680, 5500,\n",
            "         5155, 4660, 5147, 1039,  684, 4507, 3176, 3315, 3511, 4363, 1164, 6134,\n",
            "         4412, 2898, 4952, 6244, 6865, 5018, 2108, 1377, 3307, 2904, 2782, 6874,\n",
            "         2399,  889, 3173, 7770, 6244, 6865, 3189, 1184, 2972, 1139, 3173,  671,\n",
            "          807, 1201, 2692, 2206, 4028, 2157, 3184, 1259, 1419, 2014, 1213, 2206,\n",
            "         4028, 5023, 1947, 3186, 5677, 5159, 1914, 2054, 7768, 1201,  868, 6727,\n",
            "         7768, 4507, 3176, 1201, 2692, 2206, 4028, 2157, 3184, 1044, 1184, 2967,\n",
            "         1357, 6525, 3174, 1169, 6901, 6878, 4245, 6880, 1737, 1862, 6244, 6865,\n",
            "         1728, 5445, 2972, 1139, 6242, 7288, 1169, 6868, 6121, 4245, 6880, 6752,\n",
            "         1798,  889, 5632, 6242, 7288, 1169, 4638, 6242, 1606, 3683, 4372, 4507,\n",
            "         2399, 4638, 1920, 2388, 2768, 7269, 5635, 1343, 2399, 4638, 6818, 2768,\n",
            "         6134, 4412, 6631, 6632, 1044, 1184, 7521, 3309, 6244, 6865, 1822, 6121,\n",
            "         7269, 7941, 5488, 7413, 6134, 4850,  791, 2399, 4680, 1184, 4158, 3632,\n",
            "         2347, 3300, 6874, 2768, 3188, 3300, 4500, 2786, 6752, 4158, 6242, 7288,\n",
            "         1169, 3291, 3300, 7770, 6888, 2768, 4638, 1378, 4124, 4500, 2786, 6752,\n",
            "         1403, 6242, 7288, 7549, 4850, 4909, 6534, 3563, 2466, 6134, 4412, 2898,\n",
            "         5265, 5679, 1962, 7521, 3309,  791, 2399, 5018, 2108, 6629, 1377, 4496,\n",
            "         4495, 1377, 6223, 4638, 2542, 4472, 2595, 4245, 3119, 7370, 6242, 7288,\n",
            "         1169, 4638, 1201, 2692, 2206, 4028, 2157, 3184, 1912, 6244, 6865, 1071,\n",
            "          800,  676, 1920, 2471, 3083, 1259, 2886,  782, 5622, 6795, 6352, 1350,\n",
            "         3633, 1762, 7274, 4634,  704, 4638, 3118, 3001, 5645, 2398, 1378, 1071,\n",
            "          704,  782, 5622, 6795, 6352, 1072, 7770, 2428, 2768, 7269, 4051, 1213,\n",
            "         2347, 3300,  677, 4636,  943, 3633, 1762, 3835, 6312,  704, 4638, 3428,\n",
            "          891, 2200, 2768, 4158, 6244, 6865, 4245, 6880, 2768, 7269, 4638, 7028,\n",
            "         6206, 2471, 3083, 4680, 1184, 6244, 6865, 3146, 1394, 1315, 3229, 6858,\n",
            "         4761, 5143, 5186, 2347, 2768, 1216, 2802, 1057, 5401, 1751, 7015, 7368,\n",
            "         5645, 7439, 1545, 1555,  699, 4363, 1751, 1058, 7032, 6084, 6356, 3124,\n",
            "         5645,  977, 6722, 1842, 5023, 2967, 4500, 2200, 1762, 3209, 2527, 2399,\n",
            "         7380, 5265, 2456, 5390, 1377, 3307, 4158,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['彤兒歲就用雙手在個琴鍵上玩轉旋律父母發現女兒的音樂天賦後決定讓她上古典鋼琴課大學念國立台南藝術大學並主修古典鋼琴一直跟古典鋼琴為伍的她卻沒想到開啟駐唱之路後招來不少怪怪粉絲彤兒原本打算大學畢業後出國進修音樂但在大三時家裡發生財務危機只好放棄出國念書的夢想學長得知後引薦她到學校附近一家餐廳駐唱也展開了她的駐唱之旅\\u3000不過當時從未學過的彤兒學一天之後就硬著頭皮上陣效果未如預期佳又讓演出空檔冷場而遭老闆罵我那時候從來沒有過社會經驗也不知怎麼跟台下觀眾互動所以一下台就被老闆罵回家後很難過偷哭好幾天後來有向一些前輩詢問學習一些技巧慢慢就上手了現在都能很快跟觀眾互動當作是一個學習的難忘經驗之後彤兒在餐廳駐唱年並因而接觸到尾牙商演的工作大學畢業後以表演維生不過期間遇到不少變態男粉絲讓她難以招架曾有一位喝醉酒的粉絲主動走到表演台前向我要電話號碼當時那個表演舞台僅有半坪大他一上來就把我逼到牆壁後來我趕快跟工作人員使眼色他們才趕快把他請下台\\u3000不僅如此她也曾遇過有幻想狂的粉絲甚至還跟蹤她到駐唱餐廳他先在臉書傳訊息給我叫我老婆把我當作他的交往對象然後自言自語會以男友身分責罵我我沒理會他他就到我駐唱的餐廳等我那陣子每次演唱都會看到他我覺得蠻可怕的彤兒自餐廳駐唱後認識了喜歡玩獨立樂團的同學和朋友也從此開始學習創作流行音樂；接觸直播工作後靈感湧現更加激起創作的動力目前已創作多首歌曲她說自己寫詞較為直白雖接近芭樂歌曲卻能打中人心她也坦言曾一度擔心創作沒風格而失眠但在歌迷的鼓勵下才繼續激發創作的動力'], 'input_ids': tensor([[ 101, 2502, 1051, 3641, 2218, 4500, 7427, 2797, 1762,  943, 4433, 7107,\n",
            "          677, 4381, 6752, 3181, 2526, 4266, 3678, 4634, 4412, 1957, 1051, 4638,\n",
            "         7509, 3556, 1921, 6548, 2527, 3748, 2137, 6366, 1961,  677, 1367, 1073,\n",
            "         7086, 4433, 6307, 1920, 2119, 2573, 1751, 4989, 1378, 1298, 5971, 6123,\n",
            "         1920, 2119,  699,  712,  934, 1367, 1073, 7086, 4433,  671, 4684, 6656,\n",
            "         1367, 1073, 7086, 4433, 4158,  824, 4638, 1961, 1320, 3760, 2682, 1168,\n",
            "         7274, 1564, 7688, 1548,  722, 6662, 2527, 2875,  889,  679, 2208, 2597,\n",
            "         2597, 5106, 5187, 2502, 1051, 1333, 3315, 2802, 5050, 1920, 2119, 4525,\n",
            "         3511, 2527, 1139, 1751, 6868,  934, 7509, 3556,  852, 1762, 1920,  676,\n",
            "         3229, 2157, 6174, 4634, 4495, 6512, 1243, 1314, 3582, 1372, 1962, 3123,\n",
            "         3468, 1139, 1751, 2573, 3292, 4638, 1918, 2682, 2119, 7269, 2533, 4761,\n",
            "         2527, 2471, 5956, 1961, 1168, 2119, 3413, 7353, 6818,  671, 2157, 7623,\n",
            "         2453, 7688, 1548,  738, 2245, 7274,  749, 1961, 4638, 7688, 1548,  722,\n",
            "         3180,  679, 6882, 4534, 3229, 2537, 3313, 2119, 6882, 4638, 2502, 1051,\n",
            "         2119,  671, 1921,  722, 2527, 2218, 4801, 5865, 7531, 4649,  677, 7369,\n",
            "         3126, 3362, 3313, 1963, 7521, 3309,  881, 1348, 6366, 4028, 1139, 4958,\n",
            "         3593, 1107, 1842, 5445, 6901, 5439, 7293, 5393, 2769, 6929, 3229,  952,\n",
            "         2537,  889, 3760, 3300, 6882, 4852, 3298, 5195, 7710,  738,  679, 4761,\n",
            "         2582, 7938, 6656, 1378,  678, 6223, 4707,  757, 1240, 2792,  809,  671,\n",
            "          678, 1378, 2218, 6158, 5439, 7293, 5393, 1726, 2157, 2527, 2523, 7432,\n",
            "         6882,  982, 1526, 1962, 2407, 1921, 2527,  889, 3300, 1403,  671,  763,\n",
            "         1184, 6742, 6273, 1558, 2119, 5424,  671,  763, 2825, 2341, 2714, 2714,\n",
            "         2218,  677, 2797,  749, 4412, 1762, 6963, 5543, 2523, 2571, 6656, 6223,\n",
            "         4707,  757, 1240, 4534,  868, 3221,  671,  943, 2119, 5424, 4638, 7432,\n",
            "         2563, 5195, 7710,  722, 2527, 2502, 1051, 1762, 7623, 2453, 7688, 1548,\n",
            "         2399,  699, 1728, 5445, 2970, 6240, 1168, 2227, 4280, 1555, 4028, 4638,\n",
            "         2339,  868, 1920, 2119, 4525, 3511, 2527,  809, 6134, 4028, 5204, 4495,\n",
            "          679, 6882, 3309, 7279, 6878, 1168,  679, 2208, 6365, 2706, 4511, 5106,\n",
            "         5187, 6366, 1961, 7432,  809, 2875, 3373, 3295, 3300,  671,  855, 1600,\n",
            "         7004, 6983, 4638, 5106, 5187,  712, 1240, 6624, 1168, 6134, 4028, 1378,\n",
            "         1184, 1403, 2769, 6206, 7442, 6282, 5998, 4826, 4534, 3229, 6929,  943,\n",
            "         6134, 4028, 5659, 1378, 1006, 3300, 1288, 1790, 1920,  800,  671,  677,\n",
            "          889, 2218, 2828, 2769, 6873, 1168, 4274, 1880, 2527,  889, 2769, 6634,\n",
            "         2571, 6656, 2339,  868,  782, 1519,  886, 4706, 5682,  800,  947, 2798,\n",
            "         6634, 2571, 2828,  800, 6313,  678, 1378,  679, 1006, 1963, 3634, 1961,\n",
            "          738, 3295, 6878, 6882, 3300, 2404, 2682, 4312, 4638, 5106, 5187, 4493,\n",
            "         5635, 6917, 6656, 6697, 1961, 1168, 7688, 1548, 7623, 2453,  800, 1044,\n",
            "         1762, 5622, 3292, 1001, 6244, 2622, 5183, 2769, 1373, 2769, 5439, 2038,\n",
            "         2828, 2769, 4534,  868,  800, 4638,  769, 2518, 2205, 6496, 4197, 2527,\n",
            "         5632, 6241, 5632, 6295, 3298,  809, 4511, 1351, 6716, 1146, 6519, 5393,\n",
            "         2769, 2769, 3760, 4415, 3298,  800,  800, 2218, 1168, 2769, 7688, 1548,\n",
            "         4638, 7623, 2453, 5023, 2769, 6929, 7369, 2094, 3680, 3613, 4028, 1548,\n",
            "         6963, 3298, 4692, 1168,  800, 2769, 6221,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['垃圾列車攝影比賽活動網頁上滿是網友上傳的地鐵髒亂不堪照片像是車廂內滿地垃圾沒吃完的食物和不明液體嘔吐物等甚至還有排泄物噁心程度讓人不忍直視工會表示由於（大都會運輸署）削減了清潔隊員的工作充滿垃圾的地鐵車又回來了如果您遇到一輛骯髒的地鐵車那是因為沒有工作人員要清理它因為他們決定將預算花在其他方面例如數百萬美元的顧問工會希望通過民眾參加垃圾列車攝影比賽幫助證明該恢復應有的清潔員這項比賽投稿開放到月日只要年滿歲的人都可參加最後贏家將由公開投票選出'], 'input_ids': tensor([[ 101, 1796, 1769, 1154, 6722, 3109, 2512, 3683, 6555, 3833, 1240, 5206,\n",
            "         7514,  677, 4021, 3221, 5206, 1351,  677, 1001, 4638, 1765, 7136, 7766,\n",
            "          748,  679, 1838, 4212, 4275, 1008, 3221, 6722, 2439, 1058, 4021, 1765,\n",
            "         1796, 1769, 3760, 1391, 2130, 4638, 7608, 4289, 1469,  679, 3209, 3890,\n",
            "         7768, 1653, 1402, 4289, 5023, 4493, 5635, 6917, 3300, 2961, 3786, 4289,\n",
            "         1679, 2552, 4923, 2428, 6366,  782,  679, 2556, 4684, 6213, 2339, 3298,\n",
            "         6134, 4850, 4507, 3176, 8020, 1920, 6963, 3298, 6880, 6745, 5392, 8021,\n",
            "         1181, 3938,  749, 3926, 4049, 7386, 1519, 4638, 2339,  868, 1041, 4021,\n",
            "         1796, 1769, 4638, 1765, 7136, 6722, 1348, 1726,  889,  749, 1963, 3362,\n",
            "         2644, 6878, 1168,  671, 6739, 7756, 7766, 4638, 1765, 7136, 6722, 6929,\n",
            "         3221, 1728, 4158, 3760, 3300, 2339,  868,  782, 1519, 6206, 3926, 4415,\n",
            "         2124, 1728, 4158,  800,  947, 3748, 2137, 2200, 7521, 5050, 5709, 1762,\n",
            "         1071,  800, 3175, 7481,  891, 1963, 3149, 4636, 5857, 5401, 1039, 4638,\n",
            "         7547, 1558, 2339, 3298, 2361, 3307, 6858, 6882, 3696, 4707, 1347, 1217,\n",
            "         1796, 1769, 1154, 6722, 3109, 2512, 3683, 6555, 2396, 1221, 6349, 3209,\n",
            "         6283, 2612, 2541, 2746, 3300, 4638, 3926, 4049, 1519, 6857, 7517, 3683,\n",
            "         6555, 2832, 4943, 7274, 3123, 1168, 3299, 3189, 1372, 6206, 2399, 4021,\n",
            "         3641, 4638,  782, 6963, 1377, 1347, 1217, 3297, 2527, 6560, 2157, 2200,\n",
            "         4507, 1062, 7274, 2832, 4873, 6908, 1139,  102,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['他不服上訴去年二審認定他依法規製造合格商品改判無罪歷經年多訴訟他不曾沮喪我胸有成竹經得起考驗開庭時法官還講怪怪很有名我也有買你們的槍連法警都小聲替我加油聊起低潮廖英熙不曾愁眉苦臉常以乾笑帶過倒楣事何其多但在死神面前都不算什麼第一次看見死亡是至愛的雙親父親本在雲林經營雜貨店家境小康廖英熙在個小孩中排行第六國小時舉家隨父親搬到台北經營毛衣編織廠父親卻越忙越窮錢都被我姊姊和姊夫掌握加上個哥哥也不成才我急著出社會賺錢高中畢業就去當兵與父親永別前的最後畫面是父親騎腳踏車追上將入伍的他把身上僅有的元塞到他手裡我從來沒有那麼難過為什麼我那麼認真我的責任很重大回到家鄉總是要抬頭讓人家說廖家還有一個像樣的人對我來講是心理慰藉年海軍陸戰隊身體操勞遠比不上心痛父親因癌症過世的消息軍中隱瞞到他打靶考試結束才告知趕到靈堂時最後一面已是冰冷遺體悲痛的極致是欲哭無淚他難掩落寞地感嘆：我最痛苦最寂寞的時候爸爸走掉了相隔不到半年母親也因腦中風過世'], 'input_ids': tensor([[ 101,  800,  679, 3302,  677, 6260, 1343, 2399,  753, 2182, 6291, 2137,\n",
            "          800,  898, 3791, 6211, 6182, 6863, 1394, 3419, 1555, 1501, 3121, 1161,\n",
            "         4192, 5389, 3644, 5195, 2399, 1914, 6260, 6253,  800,  679, 3295, 3775,\n",
            "         1603, 2769, 5541, 3300, 2768, 5001, 5195, 2533, 6629, 5440, 7710, 7274,\n",
            "         2431, 3229, 3791, 2135, 6917, 6341, 2597, 2597, 2523, 3300, 1399, 2769,\n",
            "          738, 3300, 6525,  872,  947, 4638, 3541, 6865, 3791, 6356, 6963, 2207,\n",
            "         5476, 3296, 2769, 1217, 3779, 5464, 6629,  856, 4060, 2445, 5739, 4224,\n",
            "          679, 3295, 2687, 4691, 5736, 5622, 2382,  809,  746, 5010, 2380, 6882,\n",
            "          948, 3508,  752,  862, 1071, 1914,  852, 1762, 3647, 4868, 7481, 1184,\n",
            "         6963,  679, 5050,  784, 7938, 5018,  671, 3613, 4692, 6210, 3647,  767,\n",
            "         3221, 5635, 2695, 4638, 7427, 6217, 4266, 6217, 3315, 1762, 7437, 3360,\n",
            "         5195, 4245, 7429, 6515, 2421, 2157, 1862, 2207, 2434, 2445, 5739, 4224,\n",
            "         1762,  943, 2207, 2111,  704, 2961, 6121, 5018, 1063, 1751, 2207, 3229,\n",
            "         5647, 2157, 7401, 4266, 6217, 3021, 1168, 1378, 1266, 5195, 4245, 3688,\n",
            "         6132, 5226, 5251, 2449, 4266, 6217, 1320, 6632, 2564, 6632, 4981, 7092,\n",
            "         6963, 6158, 2769, 1992, 1992, 1469, 1992, 1923, 2958, 2995, 1217,  677,\n",
            "          943, 1520, 1520,  738,  679, 2768, 2798, 2769, 2593, 5865, 1139, 4852,\n",
            "         3298, 6553, 7092, 7770,  704, 4525, 3511, 2218, 1343, 4534, 1070, 5645,\n",
            "         4266, 6217, 3719, 1162, 1184, 4638, 3297, 2527, 4529, 7481, 3221, 4266,\n",
            "         6217, 7697, 5589, 6672, 6722, 6841,  677, 2200, 1057,  824, 4638,  800,\n",
            "         2828, 6716,  677, 1006, 3300, 4638, 1039, 1853, 1168,  800, 2797, 6174,\n",
            "         2769, 2537,  889, 3760, 3300, 6929, 7938, 7432, 6882, 4158,  784, 7938,\n",
            "         2769, 6929, 7938, 6291, 4696, 2769, 4638, 6519,  818, 2523, 7028, 1920,\n",
            "         1726, 1168, 2157, 6965, 5244, 3221, 6206, 2848, 7531, 6366,  782, 2157,\n",
            "         6303, 2445, 2157, 6917, 3300,  671,  943, 1008, 3564, 4638,  782, 2205,\n",
            "         2769,  889, 6341, 3221, 2552, 4415, 2720, 5964, 2399, 3862, 6725, 7380,\n",
            "         2782, 7386, 6716, 7768, 3082, 1246, 6895, 3683,  679,  677, 2552, 4578,\n",
            "         4266, 6217, 1728, 4617, 4568, 6882,  686, 4638, 3867, 2622, 6725,  704,\n",
            "         7403, 4739, 1168,  800, 2802, 7487, 5440, 6275, 5178, 3338, 2798, 1440,\n",
            "         4761, 6634, 1168, 7470, 1828, 3229, 3297, 2527,  671, 7481, 2347, 3221,\n",
            "         1102, 1107, 6909, 7768, 2650, 4578, 4638, 3513, 5636, 3221, 3617, 1526,\n",
            "         4192, 3907,  800, 7432, 2973, 5862, 2174, 1765, 2697, 1647, 8038, 2769,\n",
            "         3297, 4578, 5736, 3297, 2163, 2174, 4638, 3229,  952, 4268, 4268, 6624,\n",
            "         2957,  749, 4685, 7392,  679, 1168, 1288, 2399, 3678, 6217,  738, 1728,\n",
            "         5582,  704, 7591, 6882,  686,  102,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['大盤趨勢繼上周美國宣佈自  月份開始對中國祭出  千億的關稅之後中國在今天也傳出將禁止各省級政府對美國採買大豆產品消息一出台股轉而續跌向下不是因為農產品很重要而是因為中國不懼美國打壓貿易戰將會走到底基於這樣的態度市場認為中國擺明走自己的路即便美國的關稅再向上調升中國也不會改變堅決的態度中方的角度來看先前的寬鬆政策已經收到了初步的功效而中國華為在其它的國家的建置也得到了不錯的結果這些結果是中國不理美國的主要理由也是中國決意打到底的關鍵支撐點不過美國仍堅持課徵關稅背後的原因就是害怕中國的科技如果沒有採取適當的措施將會在未來超越美國成為美國最大的對手因此這個時間點不打貿易戰未來可能就沒有機會了台股方面則因台股是外銷售出口國基於兩強相爭的過程中台灣自然是無法避免受到影響而前波低點出在  月份市場也在觀察這個低點是否能夠守的住如果這個支撐守不住則不排回測年初一月的低點不過美方將日期押在 代表這後續仍會有轉圜的空間營收獲利成長的好股票逢拉回不妨多加留意華冠投顧 鍾騏遠分析師華冠證券投資顧問股份有限公司  證管投顧新字第  號本資料僅供參考投資時應審慎評估'], 'input_ids': tensor([[ 101, 1920, 4676, 6638, 1248, 5262,  677, 1453, 5401, 1751, 2146,  854,\n",
            "         5632, 3299,  819, 7274, 1993, 2205,  704, 1751, 4874, 1139, 1283, 1023,\n",
            "         4638, 7302, 4922,  722, 2527,  704, 1751, 1762,  791, 1921,  738, 1001,\n",
            "         1139, 2200, 4881, 3632, 1392, 4689, 5159, 3124, 2424, 2205, 5401, 1751,\n",
            "         2967, 6525, 1920, 6486, 4496, 1501, 3867, 2622,  671, 1139, 1378, 5500,\n",
            "         6752, 5445, 5265, 6649, 1403,  678,  679, 3221, 1728, 4158, 6803, 4496,\n",
            "         1501, 2523, 7028, 6206, 5445, 3221, 1728, 4158,  704, 1751,  679, 2758,\n",
            "         5401, 1751, 2802, 1886, 6530, 3211, 2782, 2200, 3298, 6624, 1168, 2419,\n",
            "         1825, 3176, 6857, 3564, 4638, 2706, 2428, 2356, 1842, 6291, 4158,  704,\n",
            "         1751, 3099, 3209, 6624, 5632, 2346, 4638, 6662, 1315,  912, 5401, 1751,\n",
            "         4638, 7302, 4922, 1086, 1403,  677, 6310, 1285,  704, 1751,  738,  679,\n",
            "         3298, 3121, 6365, 1830, 3748, 4638, 2706, 2428,  704, 3175, 4638, 6235,\n",
            "         2428,  889, 4692, 1044, 1184, 4638, 2184, 7777, 3124, 5032, 2347, 5195,\n",
            "         3119, 1168,  749, 1159, 3635, 4638, 1216, 3126, 5445,  704, 1751, 5836,\n",
            "         4158, 1762, 1071, 2124, 4638, 1751, 2157, 4638, 2456, 5390,  738, 2533,\n",
            "         1168,  749,  679, 7097, 4638, 5178, 3362, 6857,  763, 5178, 3362, 3221,\n",
            "          704, 1751,  679, 4415, 5401, 1751, 4638,  712, 6206, 4415, 4507,  738,\n",
            "         3221,  704, 1751, 3748, 2692, 2802, 1168, 2419, 4638, 7302, 7107, 3118,\n",
            "         3052, 7953,  679, 6882, 5401, 1751,  793, 1830, 2898, 6307, 2547, 7302,\n",
            "         4922, 5520, 2527, 4638, 1333, 1728, 2218, 3221, 2154, 2586,  704, 1751,\n",
            "         4638, 4906, 2825, 1963, 3362, 3760, 3300, 2967, 1357, 6900, 4534, 4638,\n",
            "         2974, 3177, 2200, 3298, 1762, 3313,  889, 6631, 6632, 5401, 1751, 2768,\n",
            "         4158, 5401, 1751, 3297, 1920, 4638, 2205, 2797, 1728, 3634, 6857,  943,\n",
            "         3229, 7279, 7953,  679, 2802, 6530, 3211, 2782, 3313,  889, 1377, 5543,\n",
            "         2218, 3760, 3300, 3582, 3298,  749, 1378, 5500, 3175, 7481, 1179, 1728,\n",
            "         1378, 5500, 3221, 1912, 7077, 1545, 1139, 1366, 1751, 1825, 3176, 1060,\n",
            "         2485, 4685, 4261, 4638, 6882, 4923,  704, 1378, 4124, 5632, 4197, 3221,\n",
            "         4192, 3791, 6912, 1048, 1358, 1168, 2512, 7513, 5445, 1184, 3797,  856,\n",
            "         7953, 1139, 1762, 3299,  819, 2356, 1842,  738, 1762, 6223, 2175, 6857,\n",
            "          943,  856, 7953, 3221, 1415, 5543, 1917, 2127, 4638,  857, 1963, 3362,\n",
            "         6857,  943, 3118, 3052, 2127,  679,  857, 1179,  679, 2961, 1726, 3947,\n",
            "         2399, 1159,  671, 3299, 4638,  856, 7953,  679, 6882, 5401, 3175, 2200,\n",
            "         3189, 3309, 2852, 1762,  807, 6134, 6857, 2527, 5265,  793, 3298, 3300,\n",
            "         6752, 1758, 4638, 4958, 7279, 4245, 3119, 4363, 1164, 2768, 7269, 4638,\n",
            "         1962, 5500, 4873, 6864, 2861, 1726,  679, 1981, 1914, 1217, 4522, 2692,\n",
            "         5836, 1094, 2832, 7547, 7109, 7698, 6895, 1146, 3358, 2374, 5836, 1094,\n",
            "         6349, 1171, 2832, 6536, 7547, 1558, 5500,  819, 3300, 7361, 1062, 1385,\n",
            "         6349, 5052, 2832, 7547, 3173, 2099, 5018, 5998, 3315, 6536, 3160, 1006,\n",
            "          897, 1347, 5440, 2832, 6536, 3229, 2746, 2182, 2708, 6268,  844,  102,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['記者魏瑾筠張文川綜合報導桃園市議員歐炳辰因圖利罪被判刑六年提上訴最高法院昨天駁回上訴定讞必須入獄服刑且議員職務也將解職對此歐炳辰昨回應說：法院既然這樣認定也沒有辦法歐炳辰為現任觀音區市議員加入市議會無黨團結聯盟觀音區市議員應選二席另一席是民進黨吳宗憲由於歐炳辰將因貪污治罪條例判刑而解職遺缺不適用遞補須依地方制度法規定直轄市議員同一選舉區缺額達二分之一以上時應補選市府民政局長湯蕙禎表示待行政院確定解職處分後即進行補選程序請繼續往下閱讀判決指出二一一年間桃市升格前東和鋼鐵公司為了設廠有意價購十八筆觀音鄉有土地因價格過高而延宕觀音鄉鄉務會議已經審議通過讓售價格為九千一百萬元但歐炳辰林清井劉奕發為圖利東和鋼鐵在會議紀錄不實登載可以七千一百萬元出售土地使東和鋼鐵在扣除開發成本後不法獲利一八九萬元桃園地院一審判歐炳辰劉奕發無罪林清井依偽造文書罪判刑二年；高院二審依圖利罪改判三人均有罪但因未論及沒收被最高院發回更審；高院更一審去年一月維持二審的罪名與刑度並宣告追徵沒收東和鋼鐵的不法獲利三人上訴後最高法院認為歐炳辰等三人都已做出對自己不利的供述且參酌與會人士的證詞對照會議紀錄足以認定三人共同登載不實的會議紀錄且三人的上訴仍爭執於事實審的證據取捨與判斷不符上訴三審的法定理由駁回上訴'], 'input_ids': tensor([[ 101, 6250, 5442, 7794, 4458, 5035, 2484, 3152, 2335, 5198, 1394, 1841,\n",
            "         2206, 3425, 1754, 2356, 6359, 1519, 3627, 4154, 6801, 1728, 1756, 1164,\n",
            "         5389, 6158, 1161, 1152, 1063, 2399, 2990,  677, 6260, 3297, 7770, 3791,\n",
            "         7368, 3219, 1921, 7684, 1726,  677, 6260, 2137, 6368, 2553, 7519, 1057,\n",
            "         4352, 3302, 1152,  684, 6359, 1519, 5480, 1243,  738, 2200, 6237, 5480,\n",
            "         2205, 3634, 3627, 4154, 6801, 3219, 1726, 2746, 6303, 8038, 3791, 7368,\n",
            "         3188, 4197, 6857, 3564, 6291, 2137,  738, 3760, 3300, 6794, 3791, 3627,\n",
            "         4154, 6801, 4158, 4412,  818, 6223, 7509, 1281, 2356, 6359, 1519, 1217,\n",
            "         1057, 2356, 6359, 3298, 4192, 7955, 1757, 5178, 5474, 4673, 6223, 7509,\n",
            "         1281, 2356, 6359, 1519, 2746, 6908,  753, 2375, 1369,  671, 2375, 3221,\n",
            "         3696, 6868, 7955, 1425, 2134, 2740, 4507, 3176, 3627, 4154, 6801, 2200,\n",
            "         1728, 6517, 3738, 3780, 5389, 3454,  891, 1161, 1152, 5445, 6237, 5480,\n",
            "         6909, 5375,  679, 6900, 4500, 6894, 6171, 7519,  898, 1765, 3175, 1169,\n",
            "         2428, 3791, 6211, 2137, 4684, 6749, 2356, 6359, 1519, 1398,  671, 6908,\n",
            "         5647, 1281, 5375, 7540, 6888,  753, 1146,  722,  671,  809,  677, 3229,\n",
            "         2746, 6171, 6908, 2356, 2424, 3696, 3124, 2229, 7269, 3966, 5936, 4885,\n",
            "         6134, 4850, 2521, 6121, 3124, 7368, 4825, 2137, 6237, 5480, 5993, 1146,\n",
            "         2527, 1315, 6868, 6121, 6171, 6908, 4923, 2415, 6313, 5262, 5265, 2518,\n",
            "          678, 7288, 6364, 1161, 3748, 2900, 1139,  753,  671,  671, 2399, 7279,\n",
            "         3425, 2356, 1285, 3419, 1184, 3346, 1469, 7086, 7136, 1062, 1385, 4158,\n",
            "          749, 6257, 2449, 3300, 2692, 1019, 6554, 1282, 1061, 5022, 6223, 7509,\n",
            "         6965, 3300, 1759, 1765, 1728, 1019, 3419, 6882, 7770, 5445, 2454, 2133,\n",
            "         6223, 7509, 6965, 6965, 1243, 3298, 6359, 2347, 5195, 2182, 6359, 6858,\n",
            "         6882, 6366, 1545, 1019, 3419, 4158,  736, 1283,  671, 4636, 5857, 1039,\n",
            "          852, 3627, 4154, 6801, 3360, 3926,  759, 1208, 1945, 4634, 4158, 1756,\n",
            "         1164, 3346, 1469, 7086, 7136, 1762, 3298, 6359, 5145, 7087,  679, 2179,\n",
            "         4633, 6734, 1377,  809,  673, 1283,  671, 4636, 5857, 1039, 1139, 1545,\n",
            "         1759, 1765,  886, 3346, 1469, 7086, 7136, 1762, 2807, 7370, 7274, 4634,\n",
            "         2768, 3315, 2527,  679, 3791, 4363, 1164,  671, 1061,  736, 5857, 1039,\n",
            "         3425, 1754, 1765, 7368,  671, 2182, 1161, 3627, 4154, 6801, 1208, 1945,\n",
            "         4634, 4192, 5389, 3360, 3926,  759,  898,  984, 6863, 3152, 3292, 5389,\n",
            "         1161, 1152,  753, 2399, 8039, 7770, 7368,  753, 2182,  898, 1756, 1164,\n",
            "         5389, 3121, 1161,  676,  782, 1772, 3300, 5389,  852, 1728, 3313, 6316,\n",
            "         1350, 3760, 3119, 6158, 3297, 7770, 7368, 4634, 1726, 3291, 2182, 8039,\n",
            "         7770, 7368, 3291,  671, 2182, 1343, 2399,  671, 3299, 5204, 2898,  753,\n",
            "         2182, 4638, 5389, 1399, 5645, 1152, 2428,  699, 2146, 1440, 6841, 2547,\n",
            "         3760, 3119, 3346, 1469, 7086, 7136, 4638,  679, 3791, 4363, 1164,  676,\n",
            "          782,  677, 6260, 2527, 3297, 7770, 3791, 7368, 6291, 4158, 3627, 4154,\n",
            "         6801, 5023,  676,  782, 6963, 2347,  976, 1139, 2205, 5632, 2346,  679,\n",
            "         1164, 4638,  897, 6835,  684, 1347, 6980, 5645, 3298,  782, 1894, 4638,\n",
            "         6349, 6270, 2205, 4212, 3298, 6359, 5145, 7087, 6639,  809, 6291, 2137,\n",
            "          676,  782, 1066, 1398, 4633, 6734,  679, 2179, 4638, 3298, 6359, 5145,\n",
            "         7087,  684,  676,  782, 4638,  677, 6260,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([1])}\n",
            "tensor([1], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n",
            "{'review_text': ['捲入馬勝金融集團（）吸金案今年月才被新北地院依違反銀行法判刑年的馬勝前講師廖泰宇涉嫌在馬勝案爆發後自立門戶成立以太幣（）投資團隊以老鼠會形式招攬投資吸金逾億元涉嫌違反銀行法台北地檢署今指揮調查局北部地區機動工作站兵分路搜索並約談廖泰宇等嫌到案另傳喚名證人檢調漏夜偵訊歲的廖泰宇曾多次以泰旺企管顧問公司董事長身分接受媒體訪問自稱原為口吃患者靠閱讀本書花年投資逾萬元向號稱激發潛能的大師安東尼羅賓等人學習從歲月入不到萬元到歲已經月入近萬元檢調獲報以廖泰宇為首的吸金集團從年開始迄今共推出種全球性的投資方案分別為凱莉星球以太世界；前者以出租電腦或手機中空餘的儲存空間為賣點；後者則是推廣投資以太幣挖礦機；種方案的投資單位從至萬美元不等獲利槓桿聲稱可達至倍但集團卻要求投資人以高於行情的比兌換檢調調查廖泰宇在全台各地廣開投資說明會招攬會員宣稱投資以太幣可快速回本保證獲利他為了促使下線努力招攬會員還設立分紅獎金只要招攬到名願意投資萬美元單位的會員就可以獲得新台幣萬元獎金招攬下線投資的金額愈多獎金就愈豐厚但之後陸續有會員拿不到錢懷疑遭到詐騙憤而提告；檢調蒐證後展開偵辦檢調今搜索處地點以涉嫌人身分約談廖泰宇等人除主嫌廖泰宇之外其餘人均為廖泰宇旗下的下線中時'], 'input_ids': tensor([[ 101, 2947, 1057, 7679, 1245, 7032, 6084, 7415, 1757, 8020, 8021, 1429,\n",
            "         7032, 3428,  791, 2399, 3299, 2798, 6158, 3173, 1266, 1765, 7368,  898,\n",
            "         6889, 1353, 7065, 6121, 3791, 1161, 1152, 2399, 4638, 7679, 1245, 1184,\n",
            "         6341, 2374, 2445, 3805, 2126, 3868, 2066, 1762, 7679, 1245, 3428, 4255,\n",
            "         4634, 2527, 5632, 4989, 7271, 2786, 2768, 4989,  809, 1922, 2395, 8020,\n",
            "         8021, 2832, 6536, 1757, 7386,  809, 5439, 7962, 3298, 2501, 2466, 2875,\n",
            "         3117, 2832, 6536, 1429, 7032, 6874, 1023, 1039, 3868, 2066, 6889, 1353,\n",
            "         7065, 6121, 3791, 1378, 1266, 1765, 3596, 5392,  791, 2900, 3000, 6310,\n",
            "         3389, 2229, 1266, 6956, 1765, 1281, 3582, 1240, 2339,  868, 4991, 1070,\n",
            "         1146, 6662, 3017, 5164,  699, 5147, 6312, 2445, 3805, 2126, 5023, 2066,\n",
            "         1168, 3428, 1369, 1001, 1598, 1399, 6349,  782, 3596, 6310, 4026, 1915,\n",
            "          980, 6244, 3641, 4638, 2445, 3805, 2126, 3295, 1914, 3613,  809, 3805,\n",
            "         3200,  821, 5052, 7547, 1558, 1062, 1385, 5869,  752, 7269, 6716, 1146,\n",
            "         2970, 1358, 2054, 7768, 6256, 1558, 5632, 4935, 1333, 4158, 1366, 1391,\n",
            "         2642, 5442, 7479, 7288, 6364, 3315, 3292, 5709, 2399, 2832, 6536, 6874,\n",
            "         5857, 1039, 1403, 5998, 4935, 4080, 4634, 4051, 5543, 4638, 1920, 2374,\n",
            "         2128, 3346, 2225, 5397, 6540, 5023,  782, 2119, 5424, 2537, 3641, 3299,\n",
            "         1057,  679, 1168, 5857, 1039, 1168, 3641, 2347, 5195, 3299, 1057, 6818,\n",
            "         5857, 1039, 3596, 6310, 4363, 1841,  809, 2445, 3805, 2126, 4158, 7674,\n",
            "         4638, 1429, 7032, 7415, 1757, 2537, 2399, 7274, 1993, 6812,  791, 1066,\n",
            "         2972, 1139, 4934, 1059, 4413, 2595, 4638, 2832, 6536, 3175, 3428, 1146,\n",
            "         1162, 4158, 1134, 5799, 3215, 4413,  809, 1922,  686, 4518, 8039, 1184,\n",
            "         5442,  809, 1139, 4909, 7442, 5582, 2772, 2797, 3582,  704, 4958, 7626,\n",
            "         4638, 1033, 2100, 4958, 7279, 4158, 6546, 7953, 8039, 2527, 5442, 1179,\n",
            "         3221, 2972, 2451, 2832, 6536,  809, 1922, 2395, 2905, 4846, 3582, 8039,\n",
            "         4934, 3175, 3428, 4638, 2832, 6536, 1606,  855, 2537, 5635, 5857, 5401,\n",
            "         1039,  679, 5023, 4363, 1164, 3544, 3447, 5476, 4935, 1377, 6888, 5635,\n",
            "          945,  852, 7415, 1757, 1320, 6206, 3724, 2832, 6536,  782,  809, 7770,\n",
            "         3176, 6121, 2658, 4638, 3683, 1047, 2994, 3596, 6310, 6310, 3389, 2445,\n",
            "         3805, 2126, 1762, 1059, 1378, 1392, 1765, 2451, 7274, 2832, 6536, 6303,\n",
            "         3209, 3298, 2875, 3117, 3298, 1519, 2146, 4935, 2832, 6536,  809, 1922,\n",
            "         2395, 1377, 2571, 6862, 1726, 3315,  924, 6349, 4363, 1164,  800, 4158,\n",
            "          749,  914,  886,  678, 5221, 1222, 1213, 2875, 3117, 3298, 1519, 6917,\n",
            "         6257, 4989, 1146, 5148, 4354, 7032, 1372, 6206, 2875, 3117, 1168, 1399,\n",
            "         7544, 2692, 2832, 6536, 5857, 5401, 1039, 1606,  855, 4638, 3298, 1519,\n",
            "         2218, 1377,  809, 4363, 2533, 3173, 1378, 2395, 5857, 1039, 4354, 7032,\n",
            "         2875, 3117,  678, 5221, 2832, 6536, 4638, 7032, 7540, 2689, 1914, 4354,\n",
            "         7032, 2218, 2689, 6493, 1331,  852,  722, 2527, 7380, 5265, 3300, 3298,\n",
            "         1519, 2897,  679, 1168, 7092, 2755, 4542, 6901, 1168, 6266, 7700, 2734,\n",
            "         5445, 2990, 1440, 8039, 3596, 6310, 5883, 6349, 2527, 2245, 7274,  980,\n",
            "         6794, 3596, 6310,  791, 3017, 5164, 5993, 1765, 7953,  809, 3868, 2066,\n",
            "          782, 6716, 1146, 5147, 6312, 2445, 3805, 2126, 5023,  782, 7370,  712,\n",
            "         2066, 2445, 3805, 2126,  722, 1912, 1071,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([1])}\n",
            "tensor([1], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n",
            "{'review_text': ['一對閨蜜到西班牙的伊維薩島遊玩的過程異常艱辛回程時還因為丟失護照差點回不了家最後只能申請緊急護照才結束這一場驚魂記事後女子在檢查遊玩照片時赫然發現原來任她怎麼找都離異消失的護照竟然就在這據報導歲的庫克 與好姊妹準備到西班牙遊玩時先是遇到英國旅行社鼻祖—湯瑪士庫克 破產導致兩人的行程被打亂由於當時已經沒有直航機她們被迫換機換車歷經了一番波折兩人終於成功抵達目的地不過不幸女神似乎沒有放過兩個人在旅行的第二天兩人到當地最有名的夜店時庫克卻悲劇的發現她的護照離奇地消失了任憑她怎麼翻箱倒櫃就是沒有找到護照庫克表示當時她沿著自己先前的腳步不停搜索她檢查了廁所也問了失物招領仔細的看著周遭的一切但護照就是不見了她的朋友貝卡一直安慰她告訴她也許護照放在飯店中最後庫克仍舊沒有找到護照只好辦理緊急護照由於護照申請所需的時間使她必須在伊維薩島多待幾天就在庫克一切的事宜都準備就緒要登機前卻被告知她的付款有問題無法登機可憐的庫克又被迫多留在伊維薩島幾天在假期的最後一天庫克將這幾天遊玩的照片一一刷過竟發現原來她找了許久的護照就在當時夜店的地板上且離她的長腿不過一塊地磚的距離這令庫克非常震驚也為自己的天兵行為感到好笑她表示儘管這個假期發生了很多不幸但她仍擁有最美好的時光她將永生難忘中時電子報'], 'input_ids': tensor([[ 101,  671, 2205, 7286, 6057, 1168, 6205, 4408, 4280, 4638,  823, 5204,\n",
            "         5958, 2294, 6879, 4381, 4638, 6882, 4923, 4530, 2382, 5681, 6789, 1726,\n",
            "         4923, 3229, 6917, 1728, 4158,  694, 1927, 6362, 4212, 2345, 7953, 1726,\n",
            "          679,  749, 2157, 3297, 2527, 1372, 5543, 4509, 6313, 5215, 2593, 6362,\n",
            "         4212, 2798, 5178, 3338, 6857,  671, 1842, 7711, 7789, 6250,  752, 2527,\n",
            "         1957, 2094, 1762, 3596, 3389, 6879, 4381, 4212, 4275, 3229, 6622, 4197,\n",
            "         4634, 4412, 1333,  889,  818, 1961, 2582, 7938, 2823, 6963, 7431, 4530,\n",
            "         3867, 1927, 4638, 6362, 4212, 4994, 4197, 2218, 1762, 6857, 3087, 1841,\n",
            "         2206, 3641, 4638, 2430, 1046, 5645, 1962, 1992, 1987, 3976,  991, 1168,\n",
            "         6205, 4408, 4280, 6879, 4381, 3229, 1044, 3221, 6878, 1168, 5739, 1751,\n",
            "         3180, 6121, 4852, 7965, 4862,  100, 3966, 4454, 1894, 2430, 1046, 4788,\n",
            "         4496, 2206, 5636, 1060,  782, 4638, 6121, 4923, 6158, 2802,  748, 4507,\n",
            "         3176, 4534, 3229, 2347, 5195, 3760, 3300, 4684, 5661, 3582, 1961,  947,\n",
            "         6158, 6833, 2994, 3582, 2994, 6722, 3644, 5195,  749,  671, 4528, 3797,\n",
            "         2835, 1060,  782, 5173, 3176, 2768, 1216, 2850, 6888, 4680, 4638, 1765,\n",
            "          679, 6882,  679, 2401, 1957, 4868,  849,  725, 3760, 3300, 3123, 6882,\n",
            "         1060,  943,  782, 1762, 3180, 6121, 4638, 5018,  753, 1921, 1060,  782,\n",
            "         1168, 4534, 1765, 3297, 3300, 1399, 4638, 1915, 2421, 3229, 2430, 1046,\n",
            "         1320, 2650, 1206, 4638, 4634, 4412, 1961, 4638, 6362, 4212, 7431, 1936,\n",
            "         1765, 3867, 1927,  749,  818, 2731, 1961, 2582, 7938, 5436, 5056,  948,\n",
            "         3602, 2218, 3221, 3760, 3300, 2823, 1168, 6362, 4212, 2430, 1046, 6134,\n",
            "         4850, 4534, 3229, 1961, 3784, 5865, 5632, 2346, 1044, 1184, 4638, 5589,\n",
            "         3635,  679,  977, 3017, 5164, 1961, 3596, 3389,  749, 2438, 2792,  738,\n",
            "         1558,  749, 1927, 4289, 2875, 7526,  798, 5169, 4638, 4692, 5865, 1453,\n",
            "         6901, 4638,  671, 1147,  852, 6362, 4212, 2218, 3221,  679, 6210,  749,\n",
            "         1961, 4638, 3301, 1351, 6509, 1305,  671, 4684, 2128, 2720, 1961, 1440,\n",
            "         6260, 1961,  738, 6258, 6362, 4212, 3123, 1762, 7613, 2421,  704, 3297,\n",
            "         2527, 2430, 1046,  793, 5648, 3760, 3300, 2823, 1168, 6362, 4212, 1372,\n",
            "         1962, 6794, 4415, 5215, 2593, 6362, 4212, 4507, 3176, 6362, 4212, 4509,\n",
            "         6313, 2792, 7444, 4638, 3229, 7279,  886, 1961, 2553, 7519, 1762,  823,\n",
            "         5204, 5958, 2294, 1914, 2521, 2407, 1921, 2218, 1762, 2430, 1046,  671,\n",
            "         1147, 4638,  752, 2139, 6963, 3976,  991, 2218, 5219, 6206, 4633, 3582,\n",
            "         1184, 1320, 6158, 1440, 4761, 1961, 4638,  802, 3621, 3300, 1558, 7539,\n",
            "         4192, 3791, 4633, 3582, 1377, 2730, 4638, 2430, 1046, 1348, 6158, 6833,\n",
            "         1914, 4522, 1762,  823, 5204, 5958, 2294, 2407, 1921, 1762,  969, 3309,\n",
            "         4638, 3297, 2527,  671, 1921, 2430, 1046, 2200, 6857, 2407, 1921, 6879,\n",
            "         4381, 4638, 4212, 4275,  671,  671, 1170, 6882, 4994, 4634, 4412, 1333,\n",
            "          889, 1961, 2823,  749, 6258,  719, 4638, 6362, 4212, 2218, 1762, 4534,\n",
            "         3229, 1915, 2421, 4638, 1765, 3352,  677,  684, 7431, 1961, 4638, 7269,\n",
            "         5597,  679, 6882,  671, 1846, 1765, 4834, 4638, 6655, 7431, 6857,  808,\n",
            "         2430, 1046, 7478, 2382, 7448, 7711,  738, 4158, 5632, 2346, 4638, 1921,\n",
            "         1070, 6121, 4158, 2697, 1168, 1962, 5010, 1961, 6134, 4850, 1029, 5052,\n",
            "         6857,  943,  969, 3309, 4634, 4495,  749,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['記者王捷台南報導在台南自稱溫柔恰查某的國民黨市議員洪玉鳳與她的丈夫被控以假人頭方式盜領助理費檢調昨兵分路搜索查扣電腦帳冊傳喚人到案說明檢察官訊後認為洪玉鳳與丈夫涉嫌貪汙治罪條例第條偽造文書等有逃亡串證之虞今天向法院聲請羈押人頭助理則獲萬元交保其餘請回洪玉鳳目前連任屆市議員在台南任民代超過年但檢調指追查合併後的屆市議員任期僅得知不法獲利約數百萬元而這年來洪一共涉貪了多少錢又貪了多少年目前檢方還在調查全案檢方將以貪汙治罪條例偵辦未來若判刑確定依據選罷法第條洪玉鳳恐怕無望連任請繼續往下閱讀日一早南部地區機動工作站的幹員湧入洪玉鳳的服務處搜索在政界掀起討論檢調兵分路到市議會洪家並扣回電腦帳冊傳喚相關人到案檢方認為洪玉鳳與丈夫涉嫌貪汙治罪條例第五條偽造文書等有逃亡串證疑慮因此向法院聲請羈押而替洪詐取助理費的頭人頭助理則是萬元交保依據地方民意代表費用支給及村里長事務補助費補助條例的第六條規定市議員最多可以請位公費助理每個月補助萬元其中每位助理的月薪不可以超過萬這筆助理費是實報實銷且直接匯入助理的戶頭洪玉鳳必須能實質掌握人頭助理的帳戶才可以盜領助理費至於洪玉鳳的人頭助理領多少錢其他助理又領多少錢檢方沒透露另外除了貪助理費外洪玉鳳年前就遭到檢舉與丈夫年來以議會為家水電費由全民買單洪玉鳳認為當時認為只是使用議會規定的休息室不是把整個家都搬進議會住在議會期間問政效率更高'], 'input_ids': tensor([[ 101, 6250, 5442, 4374, 2949, 1378, 1298, 1841, 2206, 1762, 1378, 1298,\n",
            "         5632, 4935, 3984, 3382, 2623, 3389, 3378, 4638, 1751, 3696, 7955, 2356,\n",
            "         6359, 1519, 3825, 4373, 7854, 5645, 1961, 4638,  675, 1923, 6158, 2971,\n",
            "          809,  969,  782, 7531, 3175, 2466, 4671, 7526, 1221, 4415, 6527, 3596,\n",
            "         6310, 3219, 1070, 1146, 6662, 3017, 5164, 3389, 2807, 7442, 5582, 2379,\n",
            "         1084, 1001, 1598,  782, 1168, 3428, 6303, 3209, 3596, 2175, 2135, 6244,\n",
            "         2527, 6291, 4158, 3825, 4373, 7854, 5645,  675, 1923, 3868, 2066, 6517,\n",
            "         3732, 3780, 5389, 3454,  891, 5018, 3454,  984, 6863, 3152, 3292, 5023,\n",
            "         3300, 6845,  767,  706, 6349,  722, 5997,  791, 1921, 1403, 3791, 7368,\n",
            "         5476, 6313, 5398, 2852,  782, 7531, 1221, 4415, 1179, 4363, 5857, 1039,\n",
            "          769,  924, 1071, 7626, 6313, 1726, 3825, 4373, 7854, 4680, 1184, 6865,\n",
            "          818, 2234, 2356, 6359, 1519, 1762, 1378, 1298,  818, 3696,  807, 6631,\n",
            "         6882, 2399,  852, 3596, 6310, 2900, 6841, 3389, 1394,  882, 2527, 4638,\n",
            "         2234, 2356, 6359, 1519,  818, 3309, 1006, 2533, 4761,  679, 3791, 4363,\n",
            "         1164, 5147, 3149, 4636, 5857, 1039, 5445, 6857, 2399,  889, 3825,  671,\n",
            "         1066, 3868, 6517,  749, 1914, 2208, 7092, 1348, 6517,  749, 1914, 2208,\n",
            "         2399, 4680, 1184, 3596, 3175, 6917, 1762, 6310, 3389, 1059, 3428, 3596,\n",
            "         3175, 2200,  809, 6517, 3732, 3780, 5389, 3454,  891,  980, 6794, 3313,\n",
            "          889, 5735, 1161, 1152, 4825, 2137,  898, 3087, 6908, 5394, 3791, 5018,\n",
            "         3454, 3825, 4373, 7854, 2607, 2586, 4192, 3307, 6865,  818, 6313, 5262,\n",
            "         5265, 2518,  678, 7288, 6364, 3189,  671, 3193, 1298, 6956, 1765, 1281,\n",
            "         3582, 1240, 2339,  868, 4991, 4638, 2402, 1519, 3963, 1057, 3825, 4373,\n",
            "         7854, 4638, 3302, 1243, 5993, 3017, 5164, 1762, 3124, 4518, 2952, 6629,\n",
            "         6245, 6316, 3596, 6310, 1070, 1146, 6662, 1168, 2356, 6359, 3298, 3825,\n",
            "         2157,  699, 2807, 1726, 7442, 5582, 2379, 1084, 1001, 1598, 4685, 7302,\n",
            "          782, 1168, 3428, 3596, 3175, 6291, 4158, 3825, 4373, 7854, 5645,  675,\n",
            "         1923, 3868, 2066, 6517, 3732, 3780, 5389, 3454,  891, 5018,  758, 3454,\n",
            "          984, 6863, 3152, 3292, 5023, 3300, 6845,  767,  706, 6349, 4542, 2719,\n",
            "         1728, 3634, 1403, 3791, 7368, 5476, 6313, 5398, 2852, 5445, 3296, 3825,\n",
            "         6266, 1357, 1221, 4415, 6527, 4638, 7531,  782, 7531, 1221, 4415, 1179,\n",
            "         3221, 5857, 1039,  769,  924,  898, 3087, 1765, 3175, 3696, 2692,  807,\n",
            "         6134, 6527, 4500, 3118, 5183, 1350, 3333, 7027, 7269,  752, 1243, 6171,\n",
            "         1221, 6527, 6171, 1221, 3454,  891, 4638, 5018, 1063, 3454, 6211, 2137,\n",
            "         2356, 6359, 1519, 3297, 1914, 1377,  809, 6313,  855, 1062, 6527, 1221,\n",
            "         4415, 3680,  943, 3299, 6171, 1221, 5857, 1039, 1071,  704, 3680,  855,\n",
            "         1221, 4415, 4638, 3299, 5959,  679, 1377,  809, 6631, 6882, 5857, 6857,\n",
            "         5022, 1221, 4415, 6527, 3221, 2179, 1841, 2179, 7077,  684, 4684, 2970,\n",
            "         1274, 1057, 1221, 4415, 4638, 2786, 7531, 3825, 4373, 7854, 2553, 7519,\n",
            "         5543, 2179, 6549, 2958, 2995,  782, 7531, 1221, 4415, 4638, 2379, 2786,\n",
            "         2798, 1377,  809, 4671, 7526, 1221, 4415, 6527, 5635, 3176, 3825, 4373,\n",
            "         7854, 4638,  782, 7531, 1221, 4415, 7526, 1914, 2208, 7092, 1071,  800,\n",
            "         1221, 4415, 1348, 7526, 1914, 2208, 7092, 3596, 3175, 3760, 6851, 7463,\n",
            "         1369, 1912, 7370,  749, 6517, 1221, 4415,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([1])}\n",
            "tensor([1], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n",
            "{'review_text': ['撰文黃清照雖然道瓊指數在短線連續上漲後並未站上月線及季線加上量能持續萎縮市場信心不足下短線賣壓並未順利化解不過台股從來不看道瓊與台股連動最深的指數是費城半導體指數費半在美股四大指數中是唯一率先站上季線的雖然收黑但卻留下跳空缺口短底已經形成此情勢將有利台股多方漲勢因台股權重以電子股為大宗費半接下來的走勢也將左右台股  月動向台股本周表現非常強不僅相較其他亞股抗跌強勢股也持續不斷創新高除了費半助攻外主要在於四大政府基金因明年選舉行情將至加上中美貿易戰有望恢復談判川普釋軟及香港利空不跌等等國際局勢下內資不顧外資連日賣超短線出現三連紅 日指數突破  點大關台股市值短線就增加近  億元光是台積電就增加逾千億元台積電目前已經站回月線向下跳空缺口也即將回補完畢指數能否順勢跟上以技術面觀察加權及  指數技術面均出現黃金交叉不過美中不足是量能不足無法繼續上推從此可以看出市場買氣信心不足若以箱型區間來看台股目前也在箱型頂部位置貿然追多似乎也不合適此時選股極其重要尤其是現在半年報出爐後許多沒業績並不如預期好卻又超漲的股票將會被打回原形 設計領漲 聯詠最低估 設計大廠聯發科  搶下中國  等手機品牌的  晶片訂單並傳出今年有機會打入華為供應鏈掌握  手機商機除了聯發科大漲外也帶動  設計股出現比價行情類股連番上漲類比科矽創晶焱世芯  瑞昱等短線漲幅均達 左右漲勢驚人聯發科上半年財報   元相較於去年    元稍微小幅衰退股價卻大漲將近漲停板但是有一檔  設計股上半年財報亮眼那就是聯詠   元相較於去年    元  月營收  億元 下半年公司步入旺季今年我認為全年將有賺  元的機會聯詠為聯電集團下一員位居台灣第二大的  設計公司主要專注於平面顯示器驅動  設計並為全球第三大廠以大尺寸面板驅動  為主要業務目前在全球約有 市占率華為為聯詠大客戶之一雖然華為先前受到美國打壓但第二季營運並未紹到太大影響今年  三率 毛利營業稅後淨利率 都表現較去年更佳業績也大幅成長相較於聯發科上半年小幅衰退聯詠上半年表現的優異成績更是讓替股價抱屈籌碼方面外資自  月開始大幅賣超聯詠除息前後不停出清投信則是相反除息後開始小幅布局而股價也自  月至今打出雙腳隨著中美貿易戰緩頰華為禁令稍微鬆綁股價跌到此價位籌碼可以說是相對安定外資賣不下去短線很可能出現強彈外資回補後若股價能站上  元等幅測距將有機會重回  元以上投資人值得留意矽晶圓環球晶股價將落底而眾所周知半導體產業分上中下游上游  設計到中游晶圓製造再到下游的晶圓測試封裝而其中晶圓製造中的晶圓又來自矽晶圓產業日本矽晶圓巨擘   日於日股盤後公布上季  年  月 財報：因智慧手機銷售量停滯資料中心的投資減速導致半導體需求減少造成  吋矽晶圓開始調整數量庫存調整銷售量萎縮加上  吋矽晶圓整體需求疲弱拖累合併營收較去年同期下滑 至  億日圓合併營益大減 至  億日圓合併純益大減 至  億日圓由於矽晶圓銷售減少市場解讀為韓廠減產半導體雖說如此但矽晶圓與被動元件不同之處在於矽晶圓報價合約採長約制而矽晶圓指標股環球晶  年長約出貨量有彈性且半導體景氣循環復甦供應端重拾紀律矽晶圓單位售價的下滑幅度將比市場擔憂好得多而對環球晶而言目前股價潛藏三大利多：第一環球晶股價落後大盤市場對其預期偏低跌深就是最好的利多第二環球晶過去五年穩定配息配息率平均為 若配息率以八成去計算對比現在股價 年的現金殖利率可高達 第三目前環球晶本益比不到  倍自  年來歷史本益比區間為  倍目前  倍為歷史下緣若半導體產業景氣反轉向上矽晶圓價格穩定環球晶起碼能回到  倍本益比的位置雖說矽晶圓復甦較晚但我仍認為股價會率先打出短底我認為  元為此波低點股價將準備落底反彈了來源：萬寶週刊  期更多精彩內容請至萬寶週刊'], 'input_ids': tensor([[ 101, 3066, 3152, 7941, 3926, 4212, 7426, 4197, 6887, 4475, 2900, 3149,\n",
            "         1762, 4764, 5221, 6865, 5265,  677, 4039, 2527,  699, 3313, 4991,  677,\n",
            "         3299, 5221, 1350, 2108, 5221, 1217,  677, 7030, 5543, 2898, 5265, 5848,\n",
            "         5240, 2356, 1842,  928, 2552,  679, 6639,  678, 4764, 5221, 6546, 1886,\n",
            "          699, 3313, 7518, 1164, 1265, 6237,  679, 6882, 1378, 5500, 2537,  889,\n",
            "          679, 4692, 6887, 4475, 5645, 1378, 5500, 6865, 1240, 3297, 3918, 4638,\n",
            "         2900, 3149, 3221, 6527, 1814, 1288, 2206, 7768, 2900, 3149, 6527, 1288,\n",
            "         1762, 5401, 5500, 1724, 1920, 2900, 3149,  704, 3221, 1546,  671, 4372,\n",
            "         1044, 4991,  677, 2108, 5221, 4638, 7426, 4197, 3119, 7946,  852, 1320,\n",
            "         4522,  678, 6663, 4958, 5375, 1366, 4764, 2419, 2347, 5195, 2501, 2768,\n",
            "         3634, 2658, 1248, 2200, 3300, 1164, 1378, 5500, 1914, 3175, 4039, 1248,\n",
            "         1728, 1378, 5500, 3609, 7028,  809, 7442, 2094, 5500, 4158, 1920, 2134,\n",
            "         6527, 1288, 2970,  678,  889, 4638, 6624, 1248,  738, 2200, 2340, 1381,\n",
            "         1378, 5500, 3299, 1240, 1403, 1378, 5500, 3315, 1453, 6134, 4412, 7478,\n",
            "         2382, 2485,  679, 1006, 4685, 6733, 1071,  800,  765, 5500, 2834, 6649,\n",
            "         2485, 1248, 5500,  738, 2898, 5265,  679, 3174, 1201, 3173, 7770, 7370,\n",
            "          749, 6527, 1288, 1221, 3122, 1912,  712, 6206, 1762, 3176, 1724, 1920,\n",
            "         3124, 2424, 1825, 7032, 1728, 3209, 2399, 6908, 5647, 6121, 2658, 2200,\n",
            "         5635, 1217,  677,  704, 5401, 6530, 3211, 2782, 3300, 3307, 2612, 2541,\n",
            "         6312, 1161, 2335, 3249, 7026, 6727, 1350, 7676, 3949, 1164, 4958,  679,\n",
            "         6649, 5023, 5023, 1751, 7396, 2229, 1248,  678, 1058, 6536,  679, 7547,\n",
            "         1912, 6536, 6865, 3189, 6546, 6631, 4764, 5221, 1139, 4412,  676, 6865,\n",
            "         5148, 3189, 2900, 3149, 4960, 4788, 7953, 1920, 7302, 1378, 5500, 2356,\n",
            "          966, 4764, 5221, 2218, 1872, 1217, 6818, 1023, 1039, 1045, 3221, 1378,\n",
            "         4948, 7442, 2218, 1872, 1217, 6874, 1283, 1023, 1039, 1378, 4948, 7442,\n",
            "         4680, 1184, 2347, 5195, 4991, 1726, 3299, 5221, 1403,  678, 6663, 4958,\n",
            "         5375, 1366,  738, 1315, 2200, 1726, 6171, 2130, 4525, 2900, 3149, 5543,\n",
            "         1415, 7518, 1248, 6656,  677,  809, 2825, 6123, 7481, 6223, 2175, 1217,\n",
            "         3609, 1350, 2900, 3149, 2825, 6123, 7481, 1772, 1139, 4412, 7941, 7032,\n",
            "          769, 1349,  679, 6882, 5401,  704,  679, 6639, 3221, 7030, 5543,  679,\n",
            "         6639, 4192, 3791, 5262, 5265,  677, 2972, 2537, 3634, 1377,  809, 4692,\n",
            "         1139, 2356, 1842, 6525, 3706,  928, 2552,  679, 6639, 5735,  809, 5056,\n",
            "         1798, 1281, 7279,  889, 4692, 1378, 5500, 4680, 1184,  738, 1762, 5056,\n",
            "         1798, 7515, 6956,  855, 5390, 6530, 4197, 6841, 1914,  849,  725,  738,\n",
            "          679, 1394, 6900, 3634, 3229, 6908, 5500, 3513, 1071, 7028, 6206, 2215,\n",
            "         1071, 3221, 4412, 1762, 1288, 2399, 1841, 1139, 4257, 2527, 6258, 1914,\n",
            "         3760, 3511, 5245,  699,  679, 1963, 7521, 3309, 1962, 1320, 1348, 6631,\n",
            "         4039, 4638, 5500, 4873, 2200, 3298, 6158, 2802, 1726, 1333, 2501, 6257,\n",
            "         6243, 7526, 4039, 5474, 6271, 3297,  856,  844, 6257, 6243, 1920, 2449,\n",
            "         5474, 4634, 4906, 3024,  678,  704, 1751, 5023, 2797, 3582, 1501, 4277,\n",
            "         4638, 3253, 4275, 6242, 1606,  699, 1001, 1139,  791, 2399, 3300, 3582,\n",
            "         3298, 2802, 1057, 5836, 4158,  897, 2746, 7122, 2958, 2995, 2797, 3582,\n",
            "         1555, 3582, 7370,  749, 5474, 4634, 4906,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['牛仔褲大王如興近年以併購之姿在市場崛起如興和中和羊毛同步宣布今天停牌外界揣測如興是為併購中和羊毛未料如興是出售中和羊毛持股如興持股中和羊毛股權今天以總價億元一舉轉售給漢神資產扣除借款等如興一舉進帳億元如興指出出售中和羊毛股權後僅剩下不到張持股除了處分中和羊毛持股外如興還出售柬埔寨工廠以美金萬元（約新台幣億元）為底價出售如興一改過往積極併購腳步對此如興解釋是為強化財務結構降低利息支出有助集團整體效益強化全球市場競爭力替股東創造權益接手中和羊毛的漢神資產是國揚集團侯西峰旗下事業之一包括漢神百貨漢來飯店漢神巨蛋天鷹保全等都在旗下'], 'input_ids': tensor([[ 101, 4281,  798, 6194, 1920, 4374, 1963, 5646, 6818, 2399,  809,  882,\n",
            "         6554,  722, 2013, 1762, 2356, 1842, 2307, 6629, 1963, 5646, 1469,  704,\n",
            "         1469, 5399, 3688, 1398, 3635, 2146, 2357,  791, 1921,  977, 4277, 1912,\n",
            "         4518, 2996, 3947, 1963, 5646, 3221, 4158,  882, 6554,  704, 1469, 5399,\n",
            "         3688, 3313, 3160, 1963, 5646, 3221, 1139, 1545,  704, 1469, 5399, 3688,\n",
            "         2898, 5500, 1963, 5646, 2898, 5500,  704, 1469, 5399, 3688, 5500, 3609,\n",
            "          791, 1921,  809, 5244, 1019, 1023, 1039,  671, 5647, 6752, 1545, 5183,\n",
            "         4031, 4868, 6536, 4496, 2807, 7370,  955, 3621, 5023, 1963, 5646,  671,\n",
            "         5647, 6868, 2379, 1023, 1039, 1963, 5646, 2900, 1139, 1139, 1545,  704,\n",
            "         1469, 5399, 3688, 5500, 3609, 2527, 1006, 1197,  678,  679, 1168, 2484,\n",
            "         2898, 5500, 7370,  749, 5993, 1146,  704, 1469, 5399, 3688, 2898, 5500,\n",
            "         1912, 1963, 5646, 6917, 1139, 1545, 3391, 1815, 2181, 2339, 2449,  809,\n",
            "         5401, 7032, 5857, 1039, 8020, 5147, 3173, 1378, 2395, 1023, 1039, 8021,\n",
            "         4158, 2419, 1019, 1139, 1545, 1963, 5646,  671, 3121, 6882, 2518, 4948,\n",
            "         3513,  882, 6554, 5589, 3635, 2205, 3634, 1963, 5646, 6237, 7026, 3221,\n",
            "         4158, 2485, 1265, 6512, 1243, 5178, 3539, 7360,  856, 1164, 2622, 3118,\n",
            "         1139, 3300, 1221, 7415, 1757, 3146, 7768, 3126, 4660, 2485, 1265, 1059,\n",
            "         4413, 2356, 1842, 5000, 4261, 1213, 3296, 5500, 3346, 1201, 6863, 3609,\n",
            "         4660, 2970, 2797,  704, 1469, 5399, 3688, 4638, 4031, 4868, 6536, 4496,\n",
            "         3221, 1751, 2993, 7415, 1757,  908, 6205, 2292, 3186,  678,  752, 3511,\n",
            "          722,  671, 1259, 2886, 4031, 4868, 4636, 6515, 4031,  889, 7613, 2421,\n",
            "         4031, 4868, 2342, 6028, 1921, 7877,  924, 1059, 5023, 6963, 1762, 3186,\n",
            "          678,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['記者楊國文台北報導歲廖姓男子被控前年起強迫當時僅歲的小女友小玲（化名）和他度性交但廖男辯稱作愛時雖對小玲半推半就但絕未強迫她小玲則指稱過程中雖未打罵她但廖會說愛我就要給我高等法院認定廖並未涉強制性交罪的重罪而是個與少女性交罪但考量廖未獲少女少女母親原諒判廖月刑徒刑未獲緩刑也不得易科罰金可上訴若廖上訴遭駁回恐須入獄判決指出年月起到同年月月間歲的廖男和歲的小玲是男女朋友分別在廖男桃園住處小玲住處等地共度性交但小玲母親小玲指控廖當時違反小玲的意願發生性關係因此提告請繼續往下閱讀廖男應訊坦承和小玲度性交第一次性交時雖然是半推半就也有脫掉她的褲子但沒有強迫威脅她並當庭提出萬元要與小玲和解但遭小玲小玲母親拒絕；小玲則指稱廖雖未以蠻力毆打強迫她但要求她說愛我就要給我啊高等法院認為即使雙方第一次性交時是在半推半就的情況下小玲仍有自主權可以決定是否要發生性關係並未遭強迫違反其意願而性交且若是違反其意願而性交應不至於繼續發生性關係審酌告訴人小玲母親均不願意原諒廖男判廖月徒刑仍可上訴'], 'input_ids': tensor([[ 101, 6250, 5442, 3501, 1751, 3152, 1378, 1266, 1841, 2206, 3641, 2445,\n",
            "         1998, 4511, 2094, 6158, 2971, 1184, 2399, 6629, 2485, 6833, 4534, 3229,\n",
            "         1006, 3641, 4638, 2207, 1957, 1351, 2207, 4386, 8020, 1265, 1399, 8021,\n",
            "         1469,  800, 2428, 2595,  769,  852, 2445, 4511, 6800, 4935,  868, 2695,\n",
            "         3229, 7426, 2205, 2207, 4386, 1288, 2972, 1288, 2218,  852, 5179, 3313,\n",
            "         2485, 6833, 1961, 2207, 4386, 1179, 2900, 4935, 6882, 4923,  704, 7426,\n",
            "         3313, 2802, 5393, 1961,  852, 2445, 3298, 6303, 2695, 2769, 2218, 6206,\n",
            "         5183, 2769, 7770, 5023, 3791, 7368, 6291, 2137, 2445,  699, 3313, 3868,\n",
            "         2485, 1169, 2595,  769, 5389, 4638, 7028, 5389, 5445, 3221,  943, 5645,\n",
            "         2208, 1957, 2595,  769, 5389,  852, 5440, 7030, 2445, 3313, 4363, 2208,\n",
            "         1957, 2208, 1957, 3678, 6217, 1333, 6315, 1161, 2445, 3299, 1152, 2530,\n",
            "         1152, 3313, 4363, 5227, 1152,  738,  679, 2533, 3211, 4906, 5391, 7032,\n",
            "         1377,  677, 6260, 5735, 2445,  677, 6260, 6901, 7684, 1726, 2607, 7519,\n",
            "         1057, 4352, 1161, 3748, 2900, 1139, 2399, 3299, 6629, 1168, 1398, 2399,\n",
            "         3299, 3299, 7279, 3641, 4638, 2445, 4511, 1469, 3641, 4638, 2207, 4386,\n",
            "         3221, 4511, 1957, 3301, 1351, 1146, 1162, 1762, 2445, 4511, 3425, 1754,\n",
            "          857, 5993, 2207, 4386,  857, 5993, 5023, 1765, 1066, 2428, 2595,  769,\n",
            "          852, 2207, 4386, 3678, 6217, 2207, 4386, 2900, 2971, 2445, 4534, 3229,\n",
            "         6889, 1353, 2207, 4386, 4638, 2692, 7544, 4634, 4495, 2595, 7302,  913,\n",
            "         1728, 3634, 2990, 1440, 6313, 5262, 5265, 2518,  678, 7288, 6364, 2445,\n",
            "         4511, 2746, 6244, 1788, 2824, 1469, 2207, 4386, 2428, 2595,  769, 5018,\n",
            "          671, 3613, 2595,  769, 3229, 7426, 4197, 3221, 1288, 2972, 1288, 2218,\n",
            "          738, 3300, 5562, 2957, 1961, 4638, 6194, 2094,  852, 3760, 3300, 2485,\n",
            "         6833, 2014, 5545, 1961,  699, 4534, 2431, 2990, 1139, 5857, 1039, 6206,\n",
            "         5645, 2207, 4386, 1469, 6237,  852, 6901, 2207, 4386, 2207, 4386, 3678,\n",
            "         6217, 2867, 5179, 8039, 2207, 4386, 1179, 2900, 4935, 2445, 7426, 3313,\n",
            "          809, 6116, 1213, 3676, 2802, 2485, 6833, 1961,  852, 6206, 3724, 1961,\n",
            "         6303, 2695, 2769, 2218, 6206, 5183, 2769, 1557, 7770, 5023, 3791, 7368,\n",
            "         6291, 4158, 1315,  886, 7427, 3175, 5018,  671, 3613, 2595,  769, 3229,\n",
            "         3221, 1762, 1288, 2972, 1288, 2218, 4638, 2658, 3785,  678, 2207, 4386,\n",
            "          793, 3300, 5632,  712, 3609, 1377,  809, 3748, 2137, 3221, 1415, 6206,\n",
            "         4634, 4495, 2595, 7302,  913,  699, 3313, 6901, 2485, 6833, 6889, 1353,\n",
            "         1071, 2692, 7544, 5445, 2595,  769,  684, 5735, 3221, 6889, 1353, 1071,\n",
            "         2692, 7544, 5445, 2595,  769, 2746,  679, 5635, 3176, 5262, 5265, 4634,\n",
            "         4495, 2595, 7302,  913, 2182, 6980, 1440, 6260,  782, 2207, 4386, 3678,\n",
            "         6217, 1772,  679, 7544, 2692, 1333, 6315, 2445, 4511, 1161, 2445, 3299,\n",
            "         2530, 1152,  793, 1377,  677, 6260,  102,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['人涉嫌參與月日中西區衝突事件並被控暴動的案件今（日）在西九龍法院再提訊繼案件第一次提訊時已有一名女被告潛逃今再多一名被告未有現身遭法庭發出拘捕令控方亦申請修改控罪地點及將案件轉交區域法院主任裁判官羅德泉將案押後至下月日在區域法院的答辯但場地上仍會在西九龍裁判法院處理眾人續准保釋但被禁離境仍有約數十名支持者到庭內支持被告並護送他們離開林樂兒攝名被告依次為：陳偉林甄凱盈陳澤峰布紫晴何栢耀梁志鵬楊位醒彭雨彤劉耀銓廖頌賢陳永琪廖天駿林皓正廖紫婷李樹樺胡嘉俊及張雯曦第被告甄凱盈自首次提堂未有現身第被告廖天駿今亦告缺席羅官批准控方申請對廖發出拘捕令案件現餘下名被告控方修訂控罪指被告於年月日在上環摩利臣街和文華里之間干諾道中和德輔道中的一帶連同其他人參與暴動而原先的控罪地點為香港上環干諾道中及文華里交界附近除了未有現身的名被告現餘下的名被告的案件會轉交區域法院官下令被告保釋期內不得離境羅官上次提堂時撤銷眾被告的宵禁令和禁離香港的限制今考慮續准他們保釋但禁止他們離境據了解第被告在首次提堂前飛往台灣至於今未有現身的廖天駿控方不清楚他是否在港另外涉於月日金鐘參與暴動的被告洪聰滿早前與律政司商討於下月至日外遊今獲法庭批准案件編號：'], 'input_ids': tensor([[ 101,  782, 3868, 2066, 1347, 5645, 3299, 3189,  704, 6205, 1281, 6128,\n",
            "         4960,  752,  816,  699, 6158, 2971, 3274, 1240, 4638, 3428,  816,  791,\n",
            "         8020, 3189, 8021, 1762, 6205,  736, 7983, 3791, 7368, 1086, 2990, 6244,\n",
            "         5262, 3428,  816, 5018,  671, 3613, 2990, 6244, 3229, 2347, 3300,  671,\n",
            "         1399, 1957, 6158, 1440, 4051, 6845,  791, 1086, 1914,  671, 1399, 6158,\n",
            "         1440, 3313, 3300, 4412, 6716, 6901, 3791, 2431, 4634, 1139, 2872, 2936,\n",
            "          808, 2971, 3175,  771, 4509, 6313,  934, 3121, 2971, 5389, 1765, 7953,\n",
            "         1350, 2200, 3428,  816, 6752,  769, 1281, 1818, 3791, 7368,  712,  818,\n",
            "         6161, 1161, 2135, 5397, 2548, 3787, 2200, 3428, 2852, 2527, 5635,  678,\n",
            "         3299, 3189, 1762, 1281, 1818, 3791, 7368, 4638, 5031, 6800,  852, 1842,\n",
            "         1765,  677,  793, 3298, 1762, 6205,  736, 7983, 6161, 1161, 3791, 7368,\n",
            "         5993, 4415, 4707,  782, 5265, 1114,  924, 7026,  852, 6158, 4881, 7431,\n",
            "         1862,  793, 3300, 5147, 3149, 1282, 1399, 3118, 2898, 5442, 1168, 2431,\n",
            "         1058, 3118, 2898, 6158, 1440,  699, 6362, 6843,  800,  947, 7431, 7274,\n",
            "         3360, 3556, 1051, 3109, 1399, 6158, 1440,  898, 3613, 4158, 8038, 7376,\n",
            "          971, 3360, 4488, 1134, 4659, 7376, 4075, 2292, 2357, 5166, 3252,  862,\n",
            "          100, 5438, 3448, 2562, 7868, 3501,  855, 7008, 2510, 7433, 2502, 1208,\n",
            "         5438, 7069, 2445, 7520, 6545, 7376, 3719, 4427, 2445, 1921, 7695, 3360,\n",
            "         4645, 3633, 2445, 5166, 2051, 3330, 3572, 3573, 5529, 1649,  916, 1350,\n",
            "         2484, 7435, 3286, 5018, 6158, 1440, 4488, 1134, 4659, 5632, 7674, 3613,\n",
            "         2990, 1828, 3313, 3300, 4412, 6716, 5018, 6158, 1440, 2445, 1921, 7695,\n",
            "          791,  771, 1440, 5375, 2375, 5397, 2135, 2821, 1114, 2971, 3175, 4509,\n",
            "         6313, 2205, 2445, 4634, 1139, 2872, 2936,  808, 3428,  816, 4412, 7626,\n",
            "          678, 1399, 6158, 1440, 2971, 3175,  934, 6242, 2971, 5389, 2900, 6158,\n",
            "         1440, 3176, 2399, 3299, 3189, 1762,  677, 4472, 3040, 1164, 5628, 6125,\n",
            "         1469, 3152, 5836, 7027,  722, 7279, 2397, 6330, 6887,  704, 1469, 2548,\n",
            "         6737, 6887,  704, 4638,  671, 2380, 6865, 1398, 1071,  800,  782, 1347,\n",
            "         5645, 3274, 1240, 5445, 1333, 1044, 4638, 2971, 5389, 1765, 7953, 4158,\n",
            "         7676, 3949,  677, 4472, 2397, 6330, 6887,  704, 1350, 3152, 5836, 7027,\n",
            "          769, 4518, 7353, 6818, 7370,  749, 3313, 3300, 4412, 6716, 4638, 1399,\n",
            "         6158, 1440, 4412, 7626,  678, 4638, 1399, 6158, 1440, 4638, 3428,  816,\n",
            "         3298, 6752,  769, 1281, 1818, 3791, 7368, 2135,  678,  808, 6158, 1440,\n",
            "          924, 7026, 3309, 1058,  679, 2533, 7431, 1862, 5397, 2135,  677, 3613,\n",
            "         2990, 1828, 3229, 3059, 7077, 4707, 6158, 1440, 4638, 2156, 4881,  808,\n",
            "         1469, 4881, 7431, 7676, 3949, 4638, 7361, 1169,  791, 5440, 2719, 5265,\n",
            "         1114,  800,  947,  924, 7026,  852, 4881, 3632,  800,  947, 7431, 1862,\n",
            "         3087,  749, 6237, 5018, 6158, 1440, 1762, 7674, 3613, 2990, 1828, 1184,\n",
            "         7606, 2518, 1378, 4124, 5635, 3176,  791, 3313, 3300, 4412, 6716, 4638,\n",
            "         2445, 1921, 7695, 2971, 3175,  679, 3926, 3504,  800, 3221, 1415, 1762,\n",
            "         3949, 1369, 1912, 3868, 3176, 3299, 3189, 7032, 7132, 1347, 5645, 3274,\n",
            "         1240, 4638, 6158, 1440, 3825, 5475, 4021, 3193, 1184, 5645, 2526, 3124,\n",
            "         1385, 1555, 6245, 3176,  678, 3299, 5635, 3189, 1912, 6879,  791, 4363,\n",
            "         3791, 2431, 2821, 1114, 3428,  816, 5226,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['陳武傑 分析師武傑關注個股  傳奇 東隆興 鈊象 宏齊 敦泰台股盤勢分析留意低點在國際利空消息滿天飛的情況下亞股一片綠油油台北股市也未能幸免早盤下跌   點開出指數一路走低下跌   點整場並未有起色一路在盤下游走終場下跌   點作收收在  點成交量  億今天在外資持續賣超下三大法人合計賣超  億加權指數一如昨日預期的一樣 讓大家看到了下殺力道 對於台股目前就是築底結構基本上沒有太多分析的空間但要留意低點的情況；目前看來 短線上並未看到止穩訊號下殺力道可能還會上演但會員朋友不用擔心操作上武傑會持續觀察盤面狀況幫大家找尋最佳進場時機點再通知大家會員跟緊訊息佈局即可想了解更多分析的朋友們都可以免費在武財神  陳武傑   粉絲頁上了解今天盤面上個股強勢的個股有 泰碩 智伸科 光群雷 力山 立積 科嘉  等有這些股票的投資朋友要留意後勢並小心操作弱勢股方面 聰泰 誠美材 傳奇 南茂 台表科 亞太電 等還是要提醒大家小心謹慎操作與分配規劃好自己的資金留意自身的買賣點按紀律操作以上均可留意這些族群集團與題材股的買點與賣點祝大家操作順利以上內容由華冠投顧 陳武傑分析師 整理提供投資人於投資前請審慎評估遵守紀律嚴設停利停損'], 'input_ids': tensor([[ 101, 7376, 3636,  989, 1146, 3358, 2374, 3636,  989, 7302, 3800,  943,\n",
            "         5500, 1001, 1936, 3346, 7384, 5646,  100, 6496, 2131, 7968, 3142, 3805,\n",
            "         1378, 5500, 4676, 1248, 1146, 3358, 4522, 2692,  856, 7953, 1762, 1751,\n",
            "         7396, 1164, 4958, 3867, 2622, 4021, 1921, 7606, 4638, 2658, 3785,  678,\n",
            "          765, 5500,  671, 4275, 5199, 3779, 3779, 1378, 1266, 5500, 2356,  738,\n",
            "         3313, 5543, 2401, 1048, 3193, 4676,  678, 6649, 7953, 7274, 1139, 2900,\n",
            "         3149,  671, 6662, 6624,  856,  678, 6649, 7953, 3146, 1842,  699, 3313,\n",
            "         3300, 6629, 5682,  671, 6662, 1762, 4676,  678, 3952, 6624, 5173, 1842,\n",
            "          678, 6649, 7953,  868, 3119, 3119, 1762, 7953, 2768,  769, 7030, 1023,\n",
            "          791, 1921, 1762, 1912, 6536, 2898, 5265, 6546, 6631,  678,  676, 1920,\n",
            "         3791,  782, 1394, 6243, 6546, 6631, 1023, 1217, 3609, 2900, 3149,  671,\n",
            "         1963, 3219, 3189, 7521, 3309, 4638,  671, 3564, 6366, 1920, 2157, 4692,\n",
            "         1168,  749,  678, 3669, 1213, 6887, 2205, 3176, 1378, 5500, 4680, 1184,\n",
            "         2218, 3221, 5064, 2419, 5178, 3539, 1825, 3315,  677, 3760, 3300, 1922,\n",
            "         1914, 1146, 3358, 4638, 4958, 7279,  852, 6206, 4522, 2692,  856, 7953,\n",
            "         4638, 2658, 3785, 8039, 4680, 1184, 4692,  889, 4764, 5221,  677,  699,\n",
            "         3313, 4692, 1168, 3632, 4952, 6244, 5998,  678, 3669, 1213, 6887, 1377,\n",
            "         5543, 6917, 3298,  677, 4028,  852, 3298, 1519, 3301, 1351,  679, 4500,\n",
            "         3085, 2552, 3082,  868,  677, 3636,  989, 3298, 2898, 5265, 6223, 2175,\n",
            "         4676, 7481, 4311, 3785, 2396, 1920, 2157, 2823, 2204, 3297,  881, 6868,\n",
            "         1842, 3229, 3582, 7953, 1086, 6858, 4761, 1920, 2157, 3298, 1519, 6656,\n",
            "         5215, 6244, 2622,  854, 2229, 1315, 1377, 2682,  749, 6237, 3291, 1914,\n",
            "         1146, 3358, 4638, 3301, 1351,  947, 6963, 1377,  809, 1048, 6527, 1762,\n",
            "         3636, 6512, 4868, 7376, 3636,  989, 5106, 5187, 7514,  677,  749, 6237,\n",
            "          791, 1921, 4676, 7481,  677,  943, 5500, 2485, 1248, 4638,  943, 5500,\n",
            "         3300, 3805, 4820, 3255,  847, 4906, 1045, 5408, 7440, 1213, 2255, 4989,\n",
            "         4948, 4906, 1649, 5023, 3300, 6857,  763, 5500, 4873, 4638, 2832, 6536,\n",
            "         3301, 1351, 6206, 4522, 2692, 2527, 1248,  699, 2207, 2552, 3082,  868,\n",
            "         2483, 1248, 5500, 3175, 7481, 5475, 3805, 6296, 5401, 3332, 1001, 1936,\n",
            "         1298, 5744, 1378, 6134, 4906,  765, 1922, 7442, 5023, 6917, 3221, 6206,\n",
            "         2990, 7008, 1920, 2157, 2207, 2552, 6346, 2708, 3082,  868, 5645, 1146,\n",
            "         6981, 6211, 1205, 1962, 5632, 2346, 4638, 6536, 7032, 4522, 2692, 5632,\n",
            "         6716, 4638, 6525, 6546, 7953, 2902, 5145, 2526, 3082,  868,  809,  677,\n",
            "         1772, 1377, 4522, 2692, 6857,  763, 3184, 5408, 7415, 1757, 5645, 7539,\n",
            "         3332, 5500, 4638, 6525, 7953, 5645, 6546, 7953, 4867, 1920, 2157, 3082,\n",
            "          868, 7518, 1164,  809,  677, 1058, 2159, 4507, 5836, 1094, 2832, 7547,\n",
            "         7376, 3636,  989, 1146, 3358, 2374, 3146, 4415, 2990,  897, 2832, 6536,\n",
            "          782, 3176, 2832, 6536, 1184, 6313, 2182, 2708, 6268,  844, 6905, 2127,\n",
            "         5145, 2526, 1713, 6257,  977, 1164,  977, 3010,  102,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['記者林昱孜高雄報導來自高雄市的胡姓女子（歲）日前赴日本福岡旅遊卻遭租車業者誣賴肇逃甚至在上曝光個資害她遭網友公審肉搜最後證實為不實指控但網友仍不放過胡女不堪入耳言語持續灌爆她臉書令她不堪其擾昨日到警局正式針對其中名曝光她個資的網友提告剩下的至人將待蒐集好資料再一併處理胡女已至警局報案提告網友（圖翻攝胡女丈夫臉書）本月中旬胡女日前赴日本福岡旅遊向業者租車不慎發生車禍不料卻遭業者誣賴肇逃為此將其護照資訊等個資網掀起網路霸凌網友不但肉搜出臉書辱罵就連工作地點家人也備受其擾嚴重影響生活品質曾向媒體透露壓力很大超想死胡女丈夫連輸秀出報案三連單表示一切將進入司法程序夫妻兩人日晚間一同至翠屏派出所報案針對其中一名網友違反個資法提出告訴；同時也向警方表示筆錄做完即將趕赴日本是否處理此事相關事宜不願透露至於後續的名在網路辱罵不堪留言的網友也將待回國後整理完再一併提告日本租車公司發布聲明啟示（圖翻攝）警方獲報後已展開調查將傳喚網友到案說明並呼籲網友保持理性切勿人身攻擊；至於胡女想對日本租車公司提告警方受限台灣沒有日本管轄權告知可委託律師跨海提告'], 'input_ids': tensor([[ 101, 6250, 5442, 3360, 3222, 2104, 7770, 7413, 1841, 2206,  889, 5632,\n",
            "         7770, 7413, 2356, 4638, 5529, 1998, 1957, 2094, 8020, 3641, 8021, 3189,\n",
            "         1184, 6626, 3189, 3315, 4886, 2271, 3180, 6879, 1320, 6901, 4909, 6722,\n",
            "         3511, 5442, 6298, 6552, 5488, 6845, 4493, 5635, 1762,  677, 3284, 1045,\n",
            "          943, 6536, 2154, 1961, 6901, 5206, 1351, 1062, 2182, 5489, 3017, 3297,\n",
            "         2527, 6349, 2179, 4158,  679, 2179, 2900, 2971,  852, 5206, 1351,  793,\n",
            "          679, 3123, 6882, 5529, 1957,  679, 1838, 1057, 5455, 6241, 6295, 2898,\n",
            "         5265, 4118, 4255, 1961, 5622, 3292,  808, 1961,  679, 1838, 1071, 3101,\n",
            "         3219, 3189, 1168, 6356, 2229, 3633, 2466, 7036, 2205, 1071,  704, 1399,\n",
            "         3284, 1045, 1961,  943, 6536, 4638, 5206, 1351, 2990, 1440, 1197,  678,\n",
            "         4638, 5635,  782, 2200, 2521, 5883, 7415, 1962, 6536, 3160, 1086,  671,\n",
            "          882, 5993, 4415, 5529, 1957, 2347, 5635, 6356, 2229, 1841, 3428, 2990,\n",
            "         1440, 5206, 1351, 8020, 1756, 5436, 3109, 5529, 1957,  675, 1923, 5622,\n",
            "         3292, 8021, 3315, 3299,  704, 3194, 5529, 1957, 3189, 1184, 6626, 3189,\n",
            "         3315, 4886, 2271, 3180, 6879, 1403, 3511, 5442, 4909, 6722,  679, 2708,\n",
            "         4634, 4495, 6722, 4884,  679, 3160, 1320, 6901, 3511, 5442, 6298, 6552,\n",
            "         5488, 6845, 4158, 3634, 2200, 1071, 6362, 4212, 6536, 6244, 5023,  943,\n",
            "         6536, 5206, 2952, 6629, 5206, 6662, 7464, 1119, 5206, 1351,  679,  852,\n",
            "         5489, 3017, 1139, 5622, 3292, 6802, 5393, 2218, 6865, 2339,  868, 1765,\n",
            "         7953, 2157,  782,  738,  991, 1358, 1071, 3101, 1713, 7028, 2512, 7513,\n",
            "         4495, 3833, 1501, 6549, 3295, 1403, 2054, 7768, 6851, 7463, 1886, 1213,\n",
            "         2523, 1920, 6631, 2682, 3647, 5529, 1957,  675, 1923, 6865, 6745, 4899,\n",
            "         1139, 1841, 3428,  676, 6865, 1606, 6134, 4850,  671, 1147, 2200, 6868,\n",
            "         1057, 1385, 3791, 4923, 2415, 1923, 1988, 1060,  782, 3189, 3241, 7279,\n",
            "          671, 1398, 5635, 5428, 2242, 3836, 1139, 2792, 1841, 3428, 7036, 2205,\n",
            "         1071,  704,  671, 1399, 5206, 1351, 6889, 1353,  943, 6536, 3791, 2990,\n",
            "         1139, 1440, 6260, 8039, 1398, 3229,  738, 1403, 6356, 3175, 6134, 4850,\n",
            "         5022, 7087,  976, 2130, 1315, 2200, 6634, 6626, 3189, 3315, 3221, 1415,\n",
            "         5993, 4415, 3634,  752, 4685, 7302,  752, 2139,  679, 7544, 6851, 7463,\n",
            "         5635, 3176, 2527, 5265, 4638, 1399, 1762, 5206, 6662, 6802, 5393,  679,\n",
            "         1838, 4522, 6241, 4638, 5206, 1351,  738, 2200, 2521, 1726, 1751, 2527,\n",
            "         3146, 4415, 2130, 1086,  671,  882, 2990, 1440, 3189, 3315, 4909, 6722,\n",
            "         1062, 1385, 4634, 2357, 5476, 3209, 1564, 4850, 8020, 1756, 5436, 3109,\n",
            "         8021, 6356, 3175, 4363, 1841, 2527, 2347, 2245, 7274, 6310, 3389, 2200,\n",
            "         1001, 1598, 5206, 1351, 1168, 3428, 6303, 3209,  699, 1461, 5100, 5206,\n",
            "         1351,  924, 2898, 4415, 2595, 1147, 1257,  782, 6716, 3122, 3080, 8039,\n",
            "         5635, 3176, 5529, 1957, 2682, 2205, 3189, 3315, 4909, 6722, 1062, 1385,\n",
            "         2990, 1440, 6356, 3175, 1358, 7361, 1378, 4124, 3760, 3300, 3189, 3315,\n",
            "         5052, 6749, 3609, 1440, 4761, 1377, 1999, 6249, 2526, 2374, 6659, 3862,\n",
            "         2990, 1440,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['元大金  旗下元大銀行辦理資訊作業發生疏失導致部分錄音資料消失金管會今  日表示元大銀有未確實執行內部控制制度的缺失依法核處新台幣  萬元罰鍰金管會副局長莊琇媛表示原大眾銀行（已在去年  月  日併入元大銀行）對於客戶部分錄音檔未完整備份元大銀行在合併移交時未就該錄音備份檔抽核調聽以確認移交資料完整性；且因元大銀去年  月銷毀儲存上述原始錄音系統的機器設備時也未進行備份資料完整性確認致原大眾銀行部分錄音資料未完整備份即予銷毀因此認定元大銀行資訊作業風險管理未妥內控有缺失依銀行法第  條第  款規定核處新台幣  萬元的罰鍰莊琇媛說明會發現部分錄音資料消失主要是有客戶對金融商品的課稅有疑慮打電話詢問理專理專向客戶說明完後擔心講錯想去調閱錄音檔確認結果發現當初沒有備份到此檔而原始檔也被銷毀元大銀行才會主動向金管會作重大偶發事件通報莊琇媛補充因電腦維護成本高所以銀行才會銷毀電腦的原始檔保留備份檔且元大銀行從  年至  年的錄音資料都不完整若之後還有客戶有疑慮要調資料金管會要求元大銀行要加強對客戶權益的保障有爭議要妥善處理'], 'input_ids': tensor([[ 101, 1039, 1920, 7032, 3186,  678, 1039, 1920, 7065, 6121, 6794, 4415,\n",
            "         6536, 6244,  868, 3511, 4634, 4495, 4541, 1927, 2206, 5636, 6956, 1146,\n",
            "         7087, 7509, 6536, 3160, 3867, 1927, 7032, 5052, 3298,  791, 3189, 6134,\n",
            "         4850, 1039, 1920, 7065, 3300, 3313, 4825, 2179, 1822, 6121, 1058, 6956,\n",
            "         2971, 1169, 1169, 2428, 4638, 5375, 1927,  898, 3791, 3417, 5993, 3173,\n",
            "         1378, 2395, 5857, 1039, 5391, 7106, 7032, 5052, 3298, 1199, 2229, 7269,\n",
            "         5800, 4416, 2056, 6134, 4850, 1333, 1920, 4707, 7065, 6121, 8020, 2347,\n",
            "         1762, 1343, 2399, 3299, 3189,  882, 1057, 1039, 1920, 7065, 6121, 8021,\n",
            "         2205, 3176, 2145, 2786, 6956, 1146, 7087, 7509, 3593, 3313, 2130, 3146,\n",
            "          991,  819, 1039, 1920, 7065, 6121, 1762, 1394,  882, 4919,  769, 3229,\n",
            "         3313, 2218, 6283, 7087, 7509,  991,  819, 3593, 2853, 3417, 6310, 5481,\n",
            "          809, 4825, 6291, 4919,  769, 6536, 3160, 2130, 3146, 2595, 8039,  684,\n",
            "         1728, 1039, 1920, 7065, 1343, 2399, 3299, 7077, 3672, 1033, 2100,  677,\n",
            "         6835, 1333, 1993, 7087, 7509, 5143, 5186, 4638, 3582, 1690, 6257,  991,\n",
            "         3229,  738, 3313, 6868, 6121,  991,  819, 6536, 3160, 2130, 3146, 2595,\n",
            "         4825, 6291, 5636, 1333, 1920, 4707, 7065, 6121, 6956, 1146, 7087, 7509,\n",
            "         6536, 3160, 3313, 2130, 3146,  991,  819, 1315,  750, 7077, 3672, 1728,\n",
            "         3634, 6291, 2137, 1039, 1920, 7065, 6121, 6536, 6244,  868, 3511, 7591,\n",
            "         7402, 5052, 4415, 3313, 1980, 1058, 2971, 3300, 5375, 1927,  898, 7065,\n",
            "         6121, 3791, 5018, 3454, 5018, 3621, 6211, 2137, 3417, 5993, 3173, 1378,\n",
            "         2395, 5857, 1039, 4638, 5391, 7106, 5800, 4416, 2056, 6303, 3209, 3298,\n",
            "         4634, 4412, 6956, 1146, 7087, 7509, 6536, 3160, 3867, 1927,  712, 6206,\n",
            "         3221, 3300, 2145, 2786, 2205, 7032, 6084, 1555, 1501, 4638, 6307, 4922,\n",
            "         3300, 4542, 2719, 2802, 7442, 6282, 6273, 1558, 4415, 2201, 4415, 2201,\n",
            "         1403, 2145, 2786, 6303, 3209, 2130, 2527, 3085, 2552, 6341, 7097, 2682,\n",
            "         1343, 6310, 7288, 7087, 7509, 3593, 4825, 6291, 5178, 3362, 4634, 4412,\n",
            "         4534, 1159, 3760, 3300,  991,  819, 1168, 3634, 3593, 5445, 1333, 1993,\n",
            "         3593,  738, 6158, 7077, 3672, 1039, 1920, 7065, 6121, 2798, 3298,  712,\n",
            "         1240, 1403, 7032, 5052, 3298,  868, 7028, 1920,  981, 4634,  752,  816,\n",
            "         6858, 1841, 5800, 4416, 2056, 6171, 1041, 1728, 7442, 5582, 5204, 6362,\n",
            "         2768, 3315, 7770, 2792,  809, 7065, 6121, 2798, 3298, 7077, 3672, 7442,\n",
            "         5582, 4638, 1333, 1993, 3593,  924, 4522,  991,  819, 3593,  684, 1039,\n",
            "         1920, 7065, 6121, 2537, 2399, 5635, 2399, 4638, 7087, 7509, 6536, 3160,\n",
            "         6963,  679, 2130, 3146, 5735,  722, 2527, 6917, 3300, 2145, 2786, 3300,\n",
            "         4542, 2719, 6206, 6310, 6536, 3160, 7032, 5052, 3298, 6206, 3724, 1039,\n",
            "         1920, 7065, 6121, 6206, 1217, 2485, 2205, 2145, 2786, 3609, 4660, 4638,\n",
            "          924, 7397, 3300, 4261, 6359, 6206, 1980, 1587, 5993, 4415,  102,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['歲中二男生於月初在旺角警署和太子站外牆噴上辱罵字句遭便衣警員目睹並尾隨至住所少年翌日出門時被捕他早前承認兩項刑事毀壞罪是反修例運動至今最年輕被告之一辯方今（日）於西九龍裁判法院少年庭求情時指被告已明白其表達方式不當現已得到教訓彭官也提他不要受人影響最後採納報告建議判兒童保護令個月期間被告交由祖母照顧男童須守宵禁令其控罪亦被撤銷不留案底歲的被告在西九龍法院少年庭塗污旺角警署外牆被判兒童保護令年資料圖片認為男童是人做就跟住做彭官庭上透露報告內容指男童與在場人士不相識認為男童是人哋做就跟住做他在判刑前特別再問男童是否知道用了錯誤的表達方式再籲他不要受人影響而男童在接受兒童保護令期間須由祖母照顧並須守晚上時至清晨時的宵禁令若有家人陪同或事先獲監護主任批准則可豁免男童亦須聽從指示交友及參與活動男童亦須按報告建議於半年後上庭讓裁判官了解其進度報告男童將不留案底歲男童今由祖父母父親姐姐與姨姨陪同其學校社工亦有到庭旁聽他早前承認於月日毀壞旺角警署和太子站出口外牆裁判官今判處兒童保護令後辯方申請撤銷控罪獲批即男童不會留有案底旺角警署及太子站外噴字句案情指便衣警員晚上時半目睹蒙面的被告在旺角警署噴上死黑警全家比狗其後又於太子站噴上天滅  便衣警尾隨被告至進入某住宅待他翌晨出門上學時截查拘捕被告警誡下承認犯案感到後悔律師指塗鴉屬輕微刑毀辯方大律師林凱依求情指報告正面塗鴉屬較輕的刑事毀壞案被告亦明白其所為不當她望法庭採納社會福利官報告判兒童保護令讓被告與祖母同住根據香港法例第章保護兒童及少年條例\\xa0第條\\xa0少年法庭可向任何被帶往法庭並需要受保護及照顧的兒童或少年付託予任何願意負責照顧他的人士法庭也可命令該兒童或少年的父母或監護人辦理擔保手續保證對他對該兒童作出適當的照顧及監護並可就監管期定下期限為期但不得超過年案件編號：'], 'input_ids': tensor([[ 101, 3641,  704,  753, 4511, 4495, 3176, 3299, 1159, 1762, 3200, 6235,\n",
            "         6356, 5392, 1469, 1922, 2094, 4991, 1912, 4274, 1695,  677, 6802, 5393,\n",
            "         2099, 1368, 6901,  912, 6132, 6356, 1519, 4680, 4726,  699, 2227, 7401,\n",
            "         5635,  857, 2792, 2208, 2399, 5422, 3189, 1139, 7271, 3229, 6158, 2936,\n",
            "          800, 3193, 1184, 2824, 6291, 1060, 7517, 1152,  752, 3672, 1889, 5389,\n",
            "         3221, 1353,  934,  891, 6880, 1240, 5635,  791, 3297, 2399, 6738, 6158,\n",
            "         1440,  722,  671, 6800, 3175,  791, 8020, 3189, 8021, 3176, 6205,  736,\n",
            "         7983, 6161, 1161, 3791, 7368, 2208, 2399, 2431, 3724, 2658, 3229, 2900,\n",
            "         6158, 1440, 2347, 3209, 4635, 1071, 6134, 6888, 3175, 2466,  679, 4534,\n",
            "         4412, 2347, 2533, 1168, 3136, 6246, 2510, 2135,  738, 2990,  800,  679,\n",
            "         6206, 1358,  782, 2512, 7513, 3297, 2527, 2967, 5152, 1841, 1440, 2456,\n",
            "         6359, 1161, 1051, 4997,  924, 6362,  808,  943, 3299, 3309, 7279, 6158,\n",
            "         1440,  769, 4507, 4862, 3678, 4212, 7547, 4511, 4997, 7519, 2127, 2156,\n",
            "         4881,  808, 1071, 2971, 5389,  771, 6158, 3059, 7077,  679, 4522, 3428,\n",
            "         2419, 3641, 4638, 6158, 1440, 1762, 6205,  736, 7983, 3791, 7368, 2208,\n",
            "         2399, 2431, 1850, 3738, 3200, 6235, 6356, 5392, 1912, 4274, 6158, 1161,\n",
            "         1051, 4997,  924, 6362,  808, 2399, 6536, 3160, 1756, 4275, 6291, 4158,\n",
            "         4511, 4997, 3221,  782,  976, 2218, 6656,  857,  976, 2510, 2135, 2431,\n",
            "          677, 6851, 7463, 1841, 1440, 1058, 2159, 2900, 4511, 4997, 5645, 1762,\n",
            "         1842,  782, 1894,  679, 4685, 6352, 6291, 4158, 4511, 4997, 3221,  782,\n",
            "         1508,  976, 2218, 6656,  857,  976,  800, 1762, 1161, 1152, 1184, 4294,\n",
            "         1162, 1086, 1558, 4511, 4997, 3221, 1415, 4761, 6887, 4500,  749, 7097,\n",
            "         6299, 4638, 6134, 6888, 3175, 2466, 1086, 5100,  800,  679, 6206, 1358,\n",
            "          782, 2512, 7513, 5445, 4511, 4997, 1762, 2970, 1358, 1051, 4997,  924,\n",
            "         6362,  808, 3309, 7279, 7519, 4507, 4862, 3678, 4212, 7547,  699, 7519,\n",
            "         2127, 3241,  677, 3229, 5635, 3926, 3247, 3229, 4638, 2156, 4881,  808,\n",
            "         5735, 3300, 2157,  782, 7373, 1398, 2772,  752, 1044, 4363, 4675, 6362,\n",
            "          712,  818, 2821, 1114, 1179, 1377, 6485, 1048, 4511, 4997,  771, 7519,\n",
            "         5481, 2537, 2900, 4850,  769, 1351, 1350, 1347, 5645, 3833, 1240, 4511,\n",
            "         4997,  771, 7519, 2902, 1841, 1440, 2456, 6359, 3176, 1288, 2399, 2527,\n",
            "          677, 2431, 6366, 6161, 1161, 2135,  749, 6237, 1071, 6868, 2428, 1841,\n",
            "         1440, 4511, 4997, 2200,  679, 4522, 3428, 2419, 3641, 4511, 4997,  791,\n",
            "         4507, 4862, 4266, 3678, 4266, 6217, 1995, 1995, 5645, 2007, 2007, 7373,\n",
            "         1398, 1071, 2119, 3413, 4852, 2339,  771, 3300, 1168, 2431, 3178, 5481,\n",
            "          800, 3193, 1184, 2824, 6291, 3176, 3299, 3189, 3672, 1889, 3200, 6235,\n",
            "         6356, 5392, 1469, 1922, 2094, 4991, 1139, 1366, 1912, 4274, 6161, 1161,\n",
            "         2135,  791, 1161, 5993, 1051, 4997,  924, 6362,  808, 2527, 6800, 3175,\n",
            "         4509, 6313, 3059, 7077, 2971, 5389, 4363, 2821, 1315, 4511, 4997,  679,\n",
            "         3298, 4522, 3300, 3428, 2419, 3200, 6235, 6356, 5392, 1350, 1922, 2094,\n",
            "         4991, 1912, 1695, 2099, 1368, 3428, 2658, 2900,  912, 6132, 6356, 1519,\n",
            "         3241,  677, 3229, 1288, 4680, 4726, 5885, 7481, 4638, 6158, 1440, 1762,\n",
            "         3200, 6235, 6356, 5392, 1695,  677, 3647, 7946, 6356, 1059, 2157, 3683,\n",
            "         4318, 1071, 2527, 1348, 3176, 1922, 2094,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['大選進入倒數計時不少網紅也相繼拍攝影片呼籲民眾出門投票但仍有不少民眾表示當日因為要上班無法趕回戶籍地投票對此勞動部近日說為保障勞工的投票權已將選舉投票日列勞動基準法所定假日因此在總統大選投票日即年月日雇主應依法讓勞工休假工資照付但本身就休假的的勞工則不另外給假勞動部說明若勞工在投票日工作有兩種不同薪資計算方式第一種是當天原本就是勞工工作日則在工資之外還須發放加班費若勞工因投票佔用小時工時但實際上班有小時投票的小時仍有正常薪資工作的小時則有正常薪資與加班費；第二種若月日原屬勞工休息日但卻被要求工作那雇主須依照勞工出勤的總時數來計算前小時給又後小時給又工資勞動部條件司司長謝倩蒨舉例一名勞工月薪元換算日薪為元時薪元如在週六為工作日投票日當天出勤小時上班則當日加班費應給予元；若當日是休息日雇主經徵得勞工同意後出勤小時加班費應給予元至於部分工時工作者則應給予倍的時薪勞動部表示投票日放假天指的是月日時起至時止由於投票日與一般國定假日不同因此該日不得與其他工作日對調勞動部提醒若雇主未依法給予假期或工資將處萬元以上最高萬元罰鍰並應補給工資'], 'input_ids': tensor([[ 101, 1920, 6908, 6868, 1057,  948, 3149, 6243, 3229,  679, 2208, 5206,\n",
            "         5148,  738, 4685, 5262, 2864, 3109, 2512, 4275, 1461, 5100, 3696, 4707,\n",
            "         1139, 7271, 2832, 4873,  852,  793, 3300,  679, 2208, 3696, 4707, 6134,\n",
            "         4850, 4534, 3189, 1728, 4158, 6206,  677, 4408, 4192, 3791, 6634, 1726,\n",
            "         2786, 5093, 1765, 2832, 4873, 2205, 3634, 1246, 1240, 6956, 6818, 3189,\n",
            "         6303, 4158,  924, 7397, 1246, 2339, 4638, 2832, 4873, 3609, 2347, 2200,\n",
            "         6908, 5647, 2832, 4873, 3189, 1154, 1246, 1240, 1825, 3976, 3791, 2792,\n",
            "         2137,  969, 3189, 1728, 3634, 1762, 5244, 5186, 1920, 6908, 2832, 4873,\n",
            "         3189, 1315, 2399, 3299, 3189, 7416,  712, 2746,  898, 3791, 6366, 1246,\n",
            "         2339,  828,  969, 2339, 6536, 4212,  802,  852, 3315, 6716, 2218,  828,\n",
            "          969, 4638, 4638, 1246, 2339, 1179,  679, 1369, 1912, 5183,  969, 1246,\n",
            "         1240, 6956, 6303, 3209, 5735, 1246, 2339, 1762, 2832, 4873, 3189, 2339,\n",
            "          868, 3300, 1060, 4934,  679, 1398, 5959, 6536, 6243, 5050, 3175, 2466,\n",
            "         5018,  671, 4934, 3221, 4534, 1921, 1333, 3315, 2218, 3221, 1246, 2339,\n",
            "         2339,  868, 3189, 1179, 1762, 2339, 6536,  722, 1912, 6917, 7519, 4634,\n",
            "         3123, 1217, 4408, 6527, 5735, 1246, 2339, 1728, 2832, 4873,  861, 4500,\n",
            "         2207, 3229, 2339, 3229,  852, 2179, 7396,  677, 4408, 3300, 2207, 3229,\n",
            "         2832, 4873, 4638, 2207, 3229,  793, 3300, 3633, 2382, 5959, 6536, 2339,\n",
            "          868, 4638, 2207, 3229, 1179, 3300, 3633, 2382, 5959, 6536, 5645, 1217,\n",
            "         4408, 6527, 8039, 5018,  753, 4934, 5735, 3299, 3189, 1333, 2253, 1246,\n",
            "         2339,  828, 2622, 3189,  852, 1320, 6158, 6206, 3724, 2339,  868, 6929,\n",
            "         7416,  712, 7519,  898, 4212, 1246, 2339, 1139, 1249, 4638, 5244, 3229,\n",
            "         3149,  889, 6243, 5050, 1184, 2207, 3229, 5183, 1348, 2527, 2207, 3229,\n",
            "         5183, 1348, 2339, 6536, 1246, 1240, 6956, 3454,  816, 1385, 1385, 7269,\n",
            "         6342,  959, 5890, 5647,  891,  671, 1399, 1246, 2339, 3299, 5959, 1039,\n",
            "         2994, 5050, 3189, 5959, 4158, 1039, 3229, 5959, 1039, 1963, 1762, 6867,\n",
            "         1063, 4158, 2339,  868, 3189, 2832, 4873, 3189, 4534, 1921, 1139, 1249,\n",
            "         2207, 3229,  677, 4408, 1179, 4534, 3189, 1217, 4408, 6527, 2746, 5183,\n",
            "          750, 1039, 8039, 5735, 4534, 3189, 3221,  828, 2622, 3189, 7416,  712,\n",
            "         5195, 2547, 2533, 1246, 2339, 1398, 2692, 2527, 1139, 1249, 2207, 3229,\n",
            "         1217, 4408, 6527, 2746, 5183,  750, 1039, 5635, 3176, 6956, 1146, 2339,\n",
            "         3229, 2339,  868, 5442, 1179, 2746, 5183,  750,  945, 4638, 3229, 5959,\n",
            "         1246, 1240, 6956, 6134, 4850, 2832, 4873, 3189, 3123,  969, 1921, 2900,\n",
            "         4638, 3221, 3299, 3189, 3229, 6629, 5635, 3229, 3632, 4507, 3176, 2832,\n",
            "         4873, 3189, 5645,  671, 5663, 1751, 2137,  969, 3189,  679, 1398, 1728,\n",
            "         3634, 6283, 3189,  679, 2533, 5645, 1071,  800, 2339,  868, 3189, 2205,\n",
            "         6310, 1246, 1240, 6956, 2990, 7008, 5735, 7416,  712, 3313,  898, 3791,\n",
            "         5183,  750,  969, 3309, 2772, 2339, 6536, 2200, 5993, 5857, 1039,  809,\n",
            "          677, 3297, 7770, 5857, 1039, 5391, 7106,  699, 2746, 6171, 5183, 2339,\n",
            "         6536,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['玩具巨頭美泰公司  週四  日 晚間披露該公司本週稍早收到一封匿名爆料信件目前正在調查此事這項消息令其週五  日 股價下挫 美泰在向美國證券交易委員會  提交的一份簡明文件中表示它取消了計劃於週四結束的債券發行以讓公司有機會調查信中所陳述的事項該公司沒有提供有關信中所討論內容的詳細訊息即指控的本質或何時發生任何可能的不法行為該公司過去幾年經歷過三任   於  年辭職由   接替後者是美泰從谷歌  延聘而來以幫助美泰更加關注高科技互動玩具但  一年後就宣布她將離職接掌家譜網站 前電視工作室製片人   成為現任美泰 今年美泰股價在  領導下強勢回歸在週四披露這項消息之前該股  年以來飆升近 由於芭比娃娃  和風火輪小汽車   等核心系列產品的成功 年假期購物季的銷售情況優於預期今年稍早時美泰公司還宣布與   系列所有者三麗鷗  達成協議開發以   角色及其眾多朋友為主的玩具和遊戲美泰希望在好萊塢善用其知名品牌它計劃製作一部由   主演的真人芭比電影以及一部真人版的風火輪小汽車電影兩者都將由華納兄弟公司製作但去年對美泰及其最大競爭對手孩之寶   來說是艱難的一年玩具反斗城  的破產讓它們最大的合作夥伴之一從市場上消失兩家公司現在都非常依賴沃爾瑪   和亞馬遜  進行銷售擁有  娃娃和驚喜寶貝蛋  的玩具公司  娛樂曾經多次主動向美泰提出收購要約但都遭拒絕美泰股價走勢'], 'input_ids': tensor([[ 101, 4381, 1072, 2342, 7531, 5401, 3805, 1062, 1385, 6867, 1724, 3189,\n",
            "         3241, 7279, 2847, 7463, 6283, 1062, 1385, 3315, 6867, 4924, 3193, 3119,\n",
            "         1168,  671, 2196, 1280, 1399, 4255, 3160,  928,  816, 4680, 1184, 3633,\n",
            "         1762, 6310, 3389, 3634,  752, 6857, 7517, 3867, 2622,  808, 1071, 6867,\n",
            "          758, 3189, 5500, 1019,  678, 2919, 5401, 3805, 1762, 1403, 5401, 1751,\n",
            "         6349, 1171,  769, 3211, 1999, 1519, 3298, 2990,  769, 4638,  671,  819,\n",
            "         5080, 3209, 3152,  816,  704, 6134, 4850, 2124, 1357, 3867,  749, 6243,\n",
            "         1205, 3176, 6867, 1724, 5178, 3338, 4638, 1002, 1171, 4634, 6121,  809,\n",
            "         6366, 1062, 1385, 3300, 3582, 3298, 6310, 3389,  928,  704, 2792, 7376,\n",
            "         6835, 4638,  752, 7517, 6283, 1062, 1385, 3760, 3300, 2990,  897, 3300,\n",
            "         7302,  928,  704, 2792, 6245, 6316, 1058, 2159, 4638, 6284, 5169, 6244,\n",
            "         2622, 1315, 2900, 2971, 4638, 3315, 6549, 2772,  862, 3229, 4634, 4495,\n",
            "          818,  862, 1377, 5543, 4638,  679, 3791, 6121, 4158, 6283, 1062, 1385,\n",
            "         6882, 1343, 2407, 2399, 5195, 3644, 6882,  676,  818, 3176, 2399, 6798,\n",
            "         5480, 4507, 2970, 3296, 2527, 5442, 3221, 5401, 3805, 2537, 6484, 3625,\n",
            "         2454, 5470, 5445,  889,  809, 2396, 1221, 5401, 3805, 3291, 1217, 7302,\n",
            "         3800, 7770, 4906, 2825,  757, 1240, 4381, 1072,  852,  671, 2399, 2527,\n",
            "         2218, 2146, 2357, 1961, 2200, 7431, 5480, 2970, 2958, 2157, 6355, 5206,\n",
            "         4991, 1184, 7442, 6213, 2339,  868, 2147, 6182, 4275,  782, 2768, 4158,\n",
            "         4412,  818, 5401, 3805,  791, 2399, 5401, 3805, 5500, 1019, 1762, 7526,\n",
            "         2206,  678, 2485, 1248, 1726, 3645, 1762, 6867, 1724, 2847, 7463, 6857,\n",
            "         7517, 3867, 2622,  722, 1184, 6283, 5500, 2399,  809,  889, 7598, 1285,\n",
            "         6818, 4507, 3176, 5706, 3683, 2015, 2015, 1469, 7591, 4125, 6743, 2207,\n",
            "         3749, 6722, 5023, 3417, 2552, 5143, 1154, 4496, 1501, 4638, 2768, 1216,\n",
            "         2399,  969, 3309, 6554, 4289, 2108, 4638, 7077, 1545, 2658, 3785, 1032,\n",
            "         3176, 7521, 3309,  791, 2399, 4924, 3193, 3229, 5401, 3805, 1062, 1385,\n",
            "         6917, 2146, 2357, 5645, 5143, 1154, 2792, 3300, 5442,  676, 7927, 7875,\n",
            "         6888, 2768, 1295, 6359, 7274, 4634,  809, 6235, 5682, 1350, 1071, 4707,\n",
            "         1914, 3301, 1351, 4158,  712, 4638, 4381, 1072, 1469, 6879, 2783, 5401,\n",
            "         3805, 2361, 3307, 1762, 1962, 5844, 1854, 1587, 4500, 1071, 4761, 1399,\n",
            "         1501, 4277, 2124, 6243, 1205, 6182,  868,  671, 6956, 4507,  712, 4028,\n",
            "         4638, 4696,  782, 5706, 3683, 7442, 2512,  809, 1350,  671, 6956, 4696,\n",
            "          782, 4276, 4638, 7591, 4125, 6743, 2207, 3749, 6722, 7442, 2512, 1060,\n",
            "         5442, 6963, 2200, 4507, 5836, 5152, 1040, 2475, 1062, 1385, 6182,  868,\n",
            "          852, 1343, 2399, 2205, 5401, 3805, 1350, 1071, 3297, 1920, 5000, 4261,\n",
            "         2205, 2797, 2111,  722, 2188,  889, 6303, 3221, 5681, 7432, 4638,  671,\n",
            "         2399, 4381, 1072, 1353, 3159, 1814, 4638, 4788, 4496, 6366, 2124,  947,\n",
            "         3297, 1920, 4638, 1394,  868, 1919,  845,  722,  671, 2537, 2356, 1842,\n",
            "          677, 3867, 1927, 1060, 2157, 1062, 1385, 4412, 1762, 6963, 7478, 2382,\n",
            "          898, 6552, 3753, 4273, 4454, 1469,  765, 7679, 6893, 6868, 6121, 7077,\n",
            "         1545, 3075, 3300, 2015, 2015, 1469, 7711, 1599, 2188, 6509, 6028, 4638,\n",
            "         4381, 1072, 1062, 1385, 2024, 3556, 3295, 5195, 1914, 3613,  712, 1240,\n",
            "         1403, 5401, 3805, 2990, 1139, 3119, 6554,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['台商林偉琳被吸收擔任共諜他得知同學彭男在台擔任調查官去年竟以萬元現金及將來大陸會有個一官半職為賄賂要求彭男欲刺探調查局機密文件但遭拒一審將林男依違反國家情報工作法判刑年高院改依貪汙及國安法未遂輕判年半全案可上訴歲的林男在年前往大陸蘇州地區經商並擔任蘇州台青會會長台商投資協會副會長青年聯合會委員等職他在年被南京市國安局人員吳主任吸收來台刺探並蒐集機密及發展組織他多次藉由國中同學身分利誘彭姓調查官為他打探消息被拒年月日林男約彭男到桃園市快炒店餐敘席間從餐桌下遞交裝有萬元現金牛皮紙袋給彭男並表示希望彭男將調查局內部機密文件拍攝供帶回大陸有什麼困難萬或萬不是問題在大陸會有一官半職彭男拒絕並舉發林男桃園地院依違反國家情報工作重判年但高院認為林男並未成功取得機密給大陸情報人員不構成違反國家情報法林男的犯行觸犯違反國安法未遂罪及行賄公務員罪從一重依行賄罪將他判刑年月全案可上訴中時'], 'input_ids': tensor([[ 101, 1378, 1555, 3360,  971, 4432, 6158, 1429, 3119, 3085,  818, 1066,\n",
            "         6318,  800, 2533, 4761, 1398, 2119, 2510, 4511, 1762, 1378, 3085,  818,\n",
            "         6310, 3389, 2135, 1343, 2399, 4994,  809, 5857, 1039, 4412, 7032, 1350,\n",
            "         2200,  889, 1920, 7380, 3298, 3300,  943,  671, 2135, 1288, 5480, 4158,\n",
            "         6535, 6533, 6206, 3724, 2510, 4511, 3617, 1173, 2968, 6310, 3389, 2229,\n",
            "         3582, 2166, 3152,  816,  852, 6901, 2867,  671, 2182, 2200, 3360, 4511,\n",
            "          898, 6889, 1353, 1751, 2157, 2658, 1841, 2339,  868, 3791, 1161, 1152,\n",
            "         2399, 7770, 7368, 3121,  898, 6517, 3732, 1350, 1751, 2128, 3791, 3313,\n",
            "         6876, 6738, 1161, 2399, 1288, 1059, 3428, 1377,  677, 6260, 3641, 4638,\n",
            "         3360, 4511, 1762, 2399, 1184, 2518, 1920, 7380, 5979, 2336, 1765, 1281,\n",
            "         5195, 1555,  699, 3085,  818, 5979, 2336, 1378, 7471, 3298, 3298, 7269,\n",
            "         1378, 1555, 2832, 6536, 1295, 3298, 1199, 3298, 7269, 7471, 2399, 5474,\n",
            "         1394, 3298, 1999, 1519, 5023, 5480,  800, 1762, 2399, 6158, 1298,  776,\n",
            "         2356, 1751, 2128, 2229,  782, 1519, 1425,  712,  818, 1429, 3119,  889,\n",
            "         1378, 1173, 2968,  699, 5883, 7415, 3582, 2166, 1350, 4634, 2245, 5175,\n",
            "         5251,  800, 1914, 3613, 5964, 4507, 1751,  704, 1398, 2119, 6716, 1146,\n",
            "         1164, 6294, 2510, 1998, 6310, 3389, 2135, 4158,  800, 2802, 2968, 3867,\n",
            "         2622, 6158, 2867, 2399, 3299, 3189, 3360, 4511, 5147, 2510, 4511, 1168,\n",
            "         3425, 1754, 2356, 2571, 4143, 2421, 7623, 3135, 2375, 7279, 2537, 7623,\n",
            "         3430,  678, 6894,  769, 6172, 3300, 5857, 1039, 4412, 7032, 4281, 4649,\n",
            "         5158, 6150, 5183, 2510, 4511,  699, 6134, 4850, 2361, 3307, 2510, 4511,\n",
            "         2200, 6310, 3389, 2229, 1058, 6956, 3582, 2166, 3152,  816, 2864, 3109,\n",
            "          897, 2380, 1726, 1920, 7380, 3300,  784, 7938, 1737, 7432, 5857, 2772,\n",
            "         5857,  679, 3221, 1558, 7539, 1762, 1920, 7380, 3298, 3300,  671, 2135,\n",
            "         1288, 5480, 2510, 4511, 2867, 5179,  699, 5647, 4634, 3360, 4511, 3425,\n",
            "         1754, 1765, 7368,  898, 6889, 1353, 1751, 2157, 2658, 1841, 2339,  868,\n",
            "         7028, 1161, 2399,  852, 7770, 7368, 6291, 4158, 3360, 4511,  699, 3313,\n",
            "         2768, 1216, 1357, 2533, 3582, 2166, 5183, 1920, 7380, 2658, 1841,  782,\n",
            "         1519,  679, 3539, 2768, 6889, 1353, 1751, 2157, 2658, 1841, 3791, 3360,\n",
            "         4511, 4638, 4306, 6121, 6240, 4306, 6889, 1353, 1751, 2128, 3791, 3313,\n",
            "         6876, 5389, 1350, 6121, 6535, 1062, 1243, 1519, 5389, 2537,  671, 7028,\n",
            "          898, 6121, 6535, 5389, 2200,  800, 1161, 1152, 2399, 3299, 1059, 3428,\n",
            "         1377,  677, 6260,  704, 3229,  102,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([1])}\n",
            "tensor([1], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n",
            "{'review_text': ['近日國民黨立委前進外交部喊話要為外交官討公道金門立委陳玉珍的手被同黨立委黃昭順放進兩個門板中間而遭到夾擊後來被送至台大醫院重症室並戴上呼吸器接受治療大批國民黨立委和總統候選人韓國瑜也到場關心同志引起外界疑慮是否占用病床律師呂秋遠昨（日）深夜在臉書發文出國父孫文病榻前的圖畫感嘆如果去年地方選舉國民黨大勝後能提出郭台銘朱立倫當候選人而韓國瑜在高雄認真做事是不是就不會淪落到今天左支右絀的局面呂秋遠隨後接著寫下不能因為這是天生的他們無法適應民主國家的環境只能不斷的吃老本過活呂秋遠舉藍委衝外交部多人涉嫌辱警為例表示其實按照國民黨不分區立委排名第一的葉毓蘭之前力挺港警的標準這些立委應該用催淚彈與塑膠子彈處理一旦肢體接觸到警察執法人員就應該用警棍與盾牌集體圍毆而且這些人不應該反抗 呂秋遠最後呼籲民眾月日一定要出來投票除了總統票立委和不分區立委的選票也至關重要如果不希望再看到黃昭順陳宜民陳玉珍在外交部在台大醫院濫用立委職權請審慎思考自己的這一票'], 'input_ids': tensor([[ 101, 6818, 3189, 1751, 3696, 7955, 4989, 1999, 1184, 6868, 1912,  769,\n",
            "         6956, 1591, 6282, 6206, 4158, 1912,  769, 2135, 6245, 1062, 6887, 7032,\n",
            "         7271, 4989, 1999, 7376, 4373, 4397, 4638, 2797, 6158, 1398, 7955, 4989,\n",
            "         1999, 7941, 3220, 7518, 3123, 6868, 1060,  943, 7271, 3352,  704, 7279,\n",
            "         5445, 6901, 1168, 1933, 3080, 2527,  889, 6158, 6843, 5635, 1378, 1920,\n",
            "         7015, 7368, 7028, 4568, 2147,  699, 2785,  677, 1461, 1429, 1690, 2970,\n",
            "         1358, 3780, 4615, 1920, 2821, 1751, 3696, 7955, 4989, 1999, 1469, 5244,\n",
            "         5186,  952, 6908,  782, 7502, 1751, 4447,  738, 1168, 1842, 7302, 2552,\n",
            "         1398, 2562, 2471, 6629, 1912, 4518, 4542, 2719, 3221, 1415, 1304, 4500,\n",
            "         4567, 2414, 2526, 2374, 1436, 4904, 6895, 3219, 8020, 3189, 8021, 3918,\n",
            "         1915, 1762, 5622, 3292, 4634, 3152, 1139, 1751, 4266, 2113, 3152, 4567,\n",
            "         3536, 1184, 4638, 1756, 4529, 2697, 1647, 1963, 3362, 1343, 2399, 1765,\n",
            "         3175, 6908, 5647, 1751, 3696, 7955, 1920, 1245, 2527, 5543, 2990, 1139,\n",
            "         6958, 1378, 7071, 3319, 4989,  961, 4534,  952, 6908,  782, 5445, 7502,\n",
            "         1751, 4447, 1762, 7770, 7413, 6291, 4696,  976,  752, 3221,  679, 3221,\n",
            "         2218,  679, 3298, 3914, 5862, 1168,  791, 1921, 2340, 3118, 1381,  100,\n",
            "         4638, 2229, 7481, 1436, 4904, 6895, 7401, 2527, 2970, 5865, 2183,  678,\n",
            "          679, 5543, 1728, 4158, 6857, 3221, 1921, 4495, 4638,  800,  947, 4192,\n",
            "         3791, 6900, 2746, 3696,  712, 1751, 2157, 4638, 4472, 1862, 1372, 5543,\n",
            "          679, 3174, 4638, 1391, 5439, 3315, 6882, 3833, 1436, 4904, 6895, 5647,\n",
            "         5965, 1999, 6128, 1912,  769, 6956, 1914,  782, 3868, 2066, 6802, 6356,\n",
            "         4158,  891, 6134, 4850, 1071, 2179, 2902, 4212, 1751, 3696, 7955,  679,\n",
            "         1146, 1281, 4989, 1999, 2961, 1399, 5018,  671, 4638, 5864, 3682, 5984,\n",
            "          722, 1184, 1213, 2923, 3949, 6356, 4638, 3560, 3976, 6857,  763, 4989,\n",
            "         1999, 2746, 6283, 4500,  998, 3907, 2492, 5645, 1848, 5608, 2094, 2492,\n",
            "         5993, 4415,  671, 3190, 5501, 7768, 2970, 6240, 1168, 6356, 2175, 1822,\n",
            "         3791,  782, 1519, 2218, 2746, 6283, 4500, 6356, 3471, 5645, 4688, 4277,\n",
            "         7415, 7768, 1752, 3676, 5445,  684, 6857,  763,  782,  679, 2746, 6283,\n",
            "         1353, 2834, 1436, 4904, 6895, 3297, 2527, 1461, 5100, 3696, 4707, 3299,\n",
            "         3189,  671, 2137, 6206, 1139,  889, 2832, 4873, 7370,  749, 5244, 5186,\n",
            "         4873, 4989, 1999, 1469,  679, 1146, 1281, 4989, 1999, 4638, 6908, 4873,\n",
            "          738, 5635, 7302, 7028, 6206, 1963, 3362,  679, 2361, 3307, 1086, 4692,\n",
            "         1168, 7941, 3220, 7518, 7376, 2139, 3696, 7376, 4373, 4397, 1762, 1912,\n",
            "          769, 6956, 1762, 1378, 1920, 7015, 7368, 4093, 4500, 4989, 1999, 5480,\n",
            "         3609, 6313, 2182, 2708, 2590, 5440, 5632, 2346, 4638, 6857,  671, 4873,\n",
            "          102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['記者王冠仁台北報導歲慣竊鄭姓男子鎖定酒醉落單醉倒街頭酒客趁其失去反抗能力洗劫財物被害人清醒後一度以為自己亂發小費或付帳釐清後才知遇到乾洗大盜報案鄭男個月內在北市至少犯案多起得手金額數十萬元警方日前趁他物色目標時逮人依竊盜罪嫌送辦今年月底至月底台北市中山區發生多起酒醉民眾遭洗劫財物案件被害人大多是酒醉倒臥在路邊公園甚至還有人是酒醉被朋友開車載回家途中當朋友下車購物犯嫌竟趁車子沒上鎖到車邊洗劫行徑誇張請繼續往下閱讀這名犯嫌至少在中山區犯案多起得手金額數十萬還曾單次得手超過萬元許多被害人隔天酒醒後發現財物短少一度以為自己亂發小費或付帳詢問友人釐清後才發現自己遇上乾洗大盜並報警警方鎖定鄭男涉案分析犯案行蹤與犯案區域日前趁他在長安東路一家便利商店尋找下手目標時逮人警方調查鄭男是名慣竊他發現酒醉民眾常落單甚至爛醉如泥倒在路旁於深夜與凌晨時段鎖定夜店酒店熱炒攤等場所尾隨這些酒醉失去抵抗力的民眾洗劫皮包手錶手機等財物常常偷到天亮才回家警方還發現這名乾洗大盜十分謹慎犯案前會先輕聲叫喚被害人若發現沒反應就直接搜刮財物若仍有反應就立刻落跑警方呼籲民眾喝酒前最好相約親友接送店家除可幫忙叫車若發現有外人靠近也應幫忙照看'], 'input_ids': tensor([[ 101, 6250, 5442, 4374, 1094,  785, 1378, 1266, 1841, 2206, 3641, 2715,\n",
            "         4988, 6972, 1998, 4511, 2094, 7115, 2137, 6983, 7004, 5862, 1606, 7004,\n",
            "          948, 6125, 7531, 6983, 2145, 6630, 1071, 1927, 1343, 1353, 2834, 5543,\n",
            "         1213, 3819, 1223, 6512, 4289, 6158, 2154,  782, 3926, 7008, 2527,  671,\n",
            "         2428,  809, 4158, 5632, 2346,  748, 4634, 2207, 6527, 2772,  802, 2379,\n",
            "         7031, 3926, 2527, 2798, 4761, 6878, 1168,  746, 3819, 1920, 4671, 1841,\n",
            "         3428, 6972, 4511,  943, 3299, 1058, 1762, 1266, 2356, 5635, 2208, 4306,\n",
            "         3428, 1914, 6629, 2533, 2797, 7032, 7540, 3149, 1282, 5857, 1039, 6356,\n",
            "         3175, 3189, 1184, 6630,  800, 4289, 5682, 4680, 3560, 3229, 6866,  782,\n",
            "          898, 4988, 4671, 5389, 2066, 6843, 6794,  791, 2399, 3299, 2419, 5635,\n",
            "         3299, 2419, 1378, 1266, 2356,  704, 2255, 1281, 4634, 4495, 1914, 6629,\n",
            "         6983, 7004, 3696, 4707, 6901, 3819, 1223, 6512, 4289, 3428,  816, 6158,\n",
            "         2154,  782, 1920, 1914, 3221, 6983, 7004,  948, 5629, 1762, 6662, 6920,\n",
            "         1062, 1754, 4493, 5635, 6917, 3300,  782, 3221, 6983, 7004, 6158, 3301,\n",
            "         1351, 7274, 6722, 6734, 1726, 2157, 6854,  704, 4534, 3301, 1351,  678,\n",
            "         6722, 6554, 4289, 4306, 2066, 4994, 6630, 6722, 2094, 3760,  677, 7115,\n",
            "         1168, 6722, 6920, 3819, 1223, 6121, 2529, 6288, 2484, 6313, 5262, 5265,\n",
            "         2518,  678, 7288, 6364, 6857, 1399, 4306, 2066, 5635, 2208, 1762,  704,\n",
            "         2255, 1281, 4306, 3428, 1914, 6629, 2533, 2797, 7032, 7540, 3149, 1282,\n",
            "         5857, 6917, 3295, 1606, 3613, 2533, 2797, 6631, 6882, 5857, 1039, 6258,\n",
            "         1914, 6158, 2154,  782, 7392, 1921, 6983, 7008, 2527, 4634, 4412, 6512,\n",
            "         4289, 4764, 2208,  671, 2428,  809, 4158, 5632, 2346,  748, 4634, 2207,\n",
            "         6527, 2772,  802, 2379, 6273, 1558, 1351,  782, 7031, 3926, 2527, 2798,\n",
            "         4634, 4412, 5632, 2346, 6878,  677,  746, 3819, 1920, 4671,  699, 1841,\n",
            "         6356, 6356, 3175, 7115, 2137, 6972, 4511, 3868, 3428, 1146, 3358, 4306,\n",
            "         3428, 6121, 6697, 5645, 4306, 3428, 1281, 1818, 3189, 1184, 6630,  800,\n",
            "         1762, 7269, 2128, 3346, 6662,  671, 2157,  912, 1164, 1555, 2421, 2204,\n",
            "         2823,  678, 2797, 4680, 3560, 3229, 6866,  782, 6356, 3175, 6310, 3389,\n",
            "         6972, 4511, 3221, 1399, 2715, 4988,  800, 4634, 4412, 6983, 7004, 3696,\n",
            "         4707, 2382, 5862, 1606, 4493, 5635, 4258, 7004, 1963, 3799,  948, 1762,\n",
            "         6662, 3178, 3176, 3918, 1915, 5645, 1119, 3247, 3229, 3667, 7115, 2137,\n",
            "         1915, 2421, 6983, 2421, 4229, 4143, 3113, 5023, 1842, 2792, 2227, 7401,\n",
            "         6857,  763, 6983, 7004, 1927, 1343, 2850, 2834, 1213, 4638, 3696, 4707,\n",
            "         3819, 1223, 4649, 1259, 2797, 7100, 2797, 3582, 5023, 6512, 4289, 2382,\n",
            "         2382,  982, 1168, 1921,  778, 2798, 1726, 2157, 6356, 3175, 6917, 4634,\n",
            "         4412, 6857, 1399,  746, 3819, 1920, 4671, 1282, 1146, 6346, 2708, 4306,\n",
            "         3428, 1184, 3298, 1044, 6738, 5476, 1373, 1598, 6158, 2154,  782, 5735,\n",
            "         4634, 4412, 3760, 1353, 2746, 2218, 4684, 2970, 3017, 1167, 6512, 4289,\n",
            "         5735,  793, 3300, 1353, 2746, 2218, 4989, 1174, 5862, 6651, 6356, 3175,\n",
            "         1461, 5100, 3696, 4707, 1600, 6983, 1184, 3297, 1962, 4685, 5147, 6217,\n",
            "         1351, 2970, 6843, 2421, 2157, 7370, 1377, 2396, 2564, 1373, 6722, 5735,\n",
            "         4634, 4412, 3300, 1912,  782, 7479, 6818,  738, 2746, 2396, 2564, 4212,\n",
            "         4692,  102,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['盤勢分析這幾天外資其實一再的賣超台股但是非常神奇的是台股再怎麼樣就是不跌不免讓人懷疑背後是不是有人刻意護盤才導致這樣子的怪現象其實上週我們就已經推論本週會有更為恰當的買點原本也是認為外資不斷賣超台股應該會有拉回的機會待拉回之後便可再勇於介入只是沒想到這個盤真的強到連拉回都不拉回實在讓人訝異但無損於我們看多做多的意念本來大盤在  之間就有支撐我們只是想等低點進場並沒有放空因此就算盤勢的發展與我們的期待不符我們也沒有受到任何傷害這就是筆者常說的盤並不是非多即空每一段都想做這只是讓自己陷入萬劫不復的危機之中之前我們一再的提供一檔股票那就是  鈺太今天又在盤中攻上漲停了這檔股票筆者最早是在今年  於本專欄中跟大家判紹並點出該公司生產的微機電系統（）麥克風是台灣第一大其中筆電用的  麥克風在全球筆電市場處於第三大供應商目前該公司的產品主要可以廣泛用在耳機手機筆電醫療級助聽器智慧音箱甚至網通與車用領域鈺太在筆記型電腦市場主要是供貨給 華碩宏碁及聯想等品牌廠同時也打入  智慧手機供應鏈去年出貨量約落在  萬至  萬套是可以留意的標的今年  月中之後回檔但家族成員仍不為所動手中持股也仍然還有未來還有多大空間我們會再追蹤雖然盤勢短線看起來還算樂觀但畢竟美元仍然偏強長久下去畢竟會影響到國際資金流入新興市場包括台灣的意願這一波的整理之後的上漲時間上要先保守看待大概再持續二至三週之後就要開始注意是不是又有異常的現象 例如  指數上升外資突然賣超 等這麼說並不是說之後一定要翻空不要緊張而是先設定好操作的策略跟節奏並且做好妥適的資金分配屆時就不會受到影響祝大家操作順利 豐銀投顧 李世新 分析師'], 'input_ids': tensor([[ 101, 4676, 1248, 1146, 3358, 6857, 2407, 1921, 1912, 6536, 1071, 2179,\n",
            "          671, 1086, 4638, 6546, 6631, 1378, 5500,  852, 3221, 7478, 2382, 4868,\n",
            "         1936, 4638, 3221, 1378, 5500, 1086, 2582, 7938, 3564, 2218, 3221,  679,\n",
            "         6649,  679, 1048, 6366,  782, 2755, 4542, 5520, 2527, 3221,  679, 3221,\n",
            "         3300,  782, 1174, 2692, 6362, 4676, 2798, 2206, 5636, 6857, 3564, 2094,\n",
            "         4638, 2597, 4412, 6496, 1071, 2179,  677, 6867, 2769,  947, 2218, 2347,\n",
            "         5195, 2972, 6316, 3315, 6867, 3298, 3300, 3291, 4158, 2623, 4534, 4638,\n",
            "         6525, 7953, 1333, 3315,  738, 3221, 6291, 4158, 1912, 6536,  679, 3174,\n",
            "         6546, 6631, 1378, 5500, 2746, 6283, 3298, 3300, 2861, 1726, 4638, 3582,\n",
            "         3298, 2521, 2861, 1726,  722, 2527,  912, 1377, 1086, 1235, 3176,  792,\n",
            "         1057, 1372, 3221, 3760, 2682, 1168, 6857,  943, 4676, 4696, 4638, 2485,\n",
            "         1168, 6865, 2861, 1726, 6963,  679, 2861, 1726, 2179, 1762, 6366,  782,\n",
            "         6252, 4530,  852, 4192, 3010, 3176, 2769,  947, 4692, 1914,  976, 1914,\n",
            "         4638, 2692, 2573, 3315,  889, 1920, 4676, 1762,  722, 7279, 2218, 3300,\n",
            "         3118, 3052, 2769,  947, 1372, 3221, 2682, 5023,  856, 7953, 6868, 1842,\n",
            "          699, 3760, 3300, 3123, 4958, 1728, 3634, 2218, 5050, 4676, 1248, 4638,\n",
            "         4634, 2245, 5645, 2769,  947, 4638, 3309, 2521,  679, 5016, 2769,  947,\n",
            "          738, 3760, 3300, 1358, 1168,  818,  862, 1003, 2154, 6857, 2218, 3221,\n",
            "         5022, 5442, 2382, 6303, 4638, 4676,  699,  679, 3221, 7478, 1914, 1315,\n",
            "         4958, 3680,  671, 3667, 6963, 2682,  976, 6857, 1372, 3221, 6366, 5632,\n",
            "         2346, 7379, 1057, 5857, 1223,  679, 2541, 4638, 1314, 3582,  722,  704,\n",
            "          722, 1184, 2769,  947,  671, 1086, 4638, 2990,  897,  671, 3593, 5500,\n",
            "         4873, 6929, 2218, 3221, 7052, 1922,  791, 1921, 1348, 1762, 4676,  704,\n",
            "         3122,  677, 4039,  977,  749, 6857, 3593, 5500, 4873, 5022, 5442, 3297,\n",
            "         3193, 3221, 1762,  791, 2399, 3176, 3315, 2201, 3608,  704, 6656, 1920,\n",
            "         2157, 1161, 5171,  699, 7953, 1139, 6283, 1062, 1385, 4495, 4496, 4638,\n",
            "         2544, 3582, 7442, 5143, 5186, 8020, 8021, 7930, 1046, 7591, 3221, 1378,\n",
            "         4124, 5018,  671, 1920, 1071,  704, 5022, 7442, 4500, 4638, 7930, 1046,\n",
            "         7591, 1762, 1059, 4413, 5022, 7442, 2356, 1842, 5993, 3176, 5018,  676,\n",
            "         1920,  897, 2746, 1555, 4680, 1184, 6283, 1062, 1385, 4638, 4496, 1501,\n",
            "          712, 6206, 1377,  809, 2451, 3793, 4500, 1762, 5455, 3582, 2797, 3582,\n",
            "         5022, 7442, 7015, 4615, 5159, 1221, 5481, 1690, 3255, 2716, 7509, 5056,\n",
            "         4493, 5635, 5206, 6858, 5645, 6722, 4500, 7526, 1818, 7052, 1922, 1762,\n",
            "         5022, 6250, 1798, 7442, 5582, 2356, 1842,  712, 6206, 3221,  897, 6515,\n",
            "         5183, 5836, 4820, 2131, 4805, 1350, 5474, 2682, 5023, 1501, 4277, 2449,\n",
            "         1398, 3229,  738, 2802, 1057, 3255, 2716, 2797, 3582,  897, 2746, 7122,\n",
            "         1343, 2399, 1139, 6515, 7030, 5147, 5862, 1762, 5857, 5635, 5857, 1947,\n",
            "         3221, 1377,  809, 4522, 2692, 4638, 3560, 4638,  791, 2399, 3299,  704,\n",
            "          722, 2527, 1726, 3593,  852, 2157, 3184, 2768, 1519,  793,  679, 4158,\n",
            "         2792, 1240, 2797,  704, 2898, 5500,  738,  793, 4197, 6917, 3300, 3313,\n",
            "          889, 6917, 3300, 1914, 1920, 4958, 7279, 2769,  947, 3298, 1086, 6841,\n",
            "         6697, 7426, 4197, 4676, 1248, 4764, 5221, 4692, 6629,  889, 6917, 5050,\n",
            "         3556, 6223,  852, 4525, 4994, 5401, 1039,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['昨  日中國晶圓代工廠華虹公布第三季業績營收純益毛利率產能利用率均較去年同期下滑但與公司第二季預估值相當集團總裁唐均君指出市場變化使產品面臨價格下跌的壓力再加上矽晶圓成本上漲衝擊營運表現但與第二季相比已有所好轉他指出  將為半導體產業帶來新的機遇電子零件的需求將相應激增包括 射頻電源管理和記憶體等財報關鍵數據第三季營收  億美元年減 公司自估  億美元第三季歸屬母公司純益  萬美元年減 第三季   美元去年同期為  美元第三季毛利率 年減三個百分點公司自估  產能利用率 去年同期為 資料來源 公司財報公司觀點由於美國地區的  和快閃記憶體產品的需求減少導致該區營收下滑 而亞洲地區邏輯相關產品需求也呈現下滑抵消  和  的需求增加該區營收減少 中國市場則在  產品需求的帶動下營收成長 而中國市場占總營收比重升至 此外第三季取得政府大量補貼抵消部分折舊成本而華虹無錫  晶圓廠 七廠 第四季開始投產公司團隊已經在七廠產線上通過數個客戶產品認證其中有兩項產品良率已達 華虹自估第四季營收約  億美元毛利率將降至 ～ 間市場觀點野村指出隨著  吋晶圓的產能提升計劃結束預估華虹在  年的產能將較  年增加 ～雖說中國對半導體的需求正在增加但華虹新開的產能未必能迅速接到訂單加上目前中國中低階晶圓代工供應過剩也不利於產品價格發展不過野村認為華虹提升  吋晶圓產品的功率是一個新的契機且改變方向合理野材表示華虹的毛利率從今年第四季開始至明年第二季都會有壓力但在政府補貼支持下對於獲利影響仍在控制範圍內華虹第三季季報下載'], 'input_ids': tensor([[ 101, 3219, 3189,  704, 1751, 3253, 1755,  807, 2339, 2449, 5836, 6004,\n",
            "         1062, 2357, 5018,  676, 2108, 3511, 5245, 4245, 3119, 5155, 4660, 3688,\n",
            "         1164, 4372, 4496, 5543, 1164, 4500, 4372, 1772, 6733, 1343, 2399, 1398,\n",
            "         3309,  678, 3998,  852, 5645, 1062, 1385, 5018,  753, 2108, 7521,  844,\n",
            "          966, 4685, 4534, 7415, 1757, 5244, 6161, 1538, 1772, 1409, 2900, 1139,\n",
            "         2356, 1842, 6365, 1265,  886, 4496, 1501, 7481, 5631, 1019, 3419,  678,\n",
            "         6649, 4638, 1886, 1213, 1086, 1217,  677, 4769, 3253, 1755, 2768, 3315,\n",
            "          677, 4039, 6128, 3080, 4245, 6880, 6134, 4412,  852, 5645, 5018,  753,\n",
            "         2108, 4685, 3683, 2347, 3300, 2792, 1962, 6752,  800, 2900, 1139, 2200,\n",
            "         4158, 1288, 2206, 7768, 4496, 3511, 2380,  889, 3173, 4638, 3582, 6878,\n",
            "         7442, 2094, 7439,  816, 4638, 7444, 3724, 2200, 4685, 2746, 4080, 1872,\n",
            "         1259, 2886, 2198, 7536, 7442, 3975, 5052, 4415, 1469, 6250, 2741, 7768,\n",
            "         5023, 6512, 1841, 7302, 7107, 3149, 3087, 5018,  676, 2108, 4245, 3119,\n",
            "         1023, 5401, 1039, 2399, 3938, 1062, 1385, 5632,  844, 1023, 5401, 1039,\n",
            "         5018,  676, 2108, 3645, 2253, 3678, 1062, 1385, 5155, 4660, 5857, 5401,\n",
            "         1039, 2399, 3938, 5018,  676, 2108, 5401, 1039, 1343, 2399, 1398, 3309,\n",
            "         4158, 5401, 1039, 5018,  676, 2108, 3688, 1164, 4372, 2399, 3938,  676,\n",
            "          943, 4636, 1146, 7953, 1062, 1385, 5632,  844, 4496, 5543, 1164, 4500,\n",
            "         4372, 1343, 2399, 1398, 3309, 4158, 6536, 3160,  889, 3975, 1062, 1385,\n",
            "         6512, 1841, 1062, 1385, 6223, 7953, 4507, 3176, 5401, 1751, 1765, 1281,\n",
            "         4638, 1469, 2571, 7272, 6250, 2741, 7768, 4496, 1501, 4638, 7444, 3724,\n",
            "         3938, 2208, 2206, 5636, 6283, 1281, 4245, 3119,  678, 3998, 5445,  765,\n",
            "         3828, 1765, 1281, 6922, 6744, 4685, 7302, 4496, 1501, 7444, 3724,  738,\n",
            "         1439, 4412,  678, 3998, 2850, 3867, 1469, 4638, 7444, 3724, 1872, 1217,\n",
            "         6283, 1281, 4245, 3119, 3938, 2208,  704, 1751, 2356, 1842, 1179, 1762,\n",
            "         4496, 1501, 7444, 3724, 4638, 2380, 1240,  678, 4245, 3119, 2768, 7269,\n",
            "         5445,  704, 1751, 2356, 1842, 1304, 5244, 4245, 3119, 3683, 7028, 1285,\n",
            "         5635, 3634, 1912, 5018,  676, 2108, 1357, 2533, 3124, 2424, 1920, 7030,\n",
            "         6171, 6528, 2850, 3867, 6956, 1146, 2835, 5648, 2768, 3315, 5445, 5836,\n",
            "         6004, 4192, 7095, 3253, 1755, 2449,  673, 2449, 5018, 1724, 2108, 7274,\n",
            "         1993, 2832, 4496, 1062, 1385, 1757, 7386, 2347, 5195, 1762,  673, 2449,\n",
            "         4496, 5221,  677, 6858, 6882, 3149,  943, 2145, 2786, 4496, 1501, 6291,\n",
            "         6349, 1071,  704, 3300, 1060, 7517, 4496, 1501, 5679, 4372, 2347, 6888,\n",
            "         5836, 6004, 5632,  844, 5018, 1724, 2108, 4245, 3119, 5147, 1023, 5401,\n",
            "         1039, 3688, 1164, 4372, 2200, 7360, 5635, 8080, 7279, 2356, 1842, 6223,\n",
            "         7953, 7029, 3333, 2900, 1139, 7401, 5865, 1397, 3253, 1755, 4638, 4496,\n",
            "         5543, 2990, 1285, 6243, 1205, 5178, 3338, 7521,  844, 5836, 6004, 1762,\n",
            "         2399, 4638, 4496, 5543, 2200, 6733, 2399, 1872, 1217, 8080, 7426, 6303,\n",
            "          704, 1751, 2205, 1288, 2206, 7768, 4638, 7444, 3724, 3633, 1762, 1872,\n",
            "         1217,  852, 5836, 6004, 3173, 7274, 4638, 4496, 5543, 3313, 2553, 5543,\n",
            "         6813, 6862, 2970, 1168, 6242, 1606, 1217,  677, 4680, 1184,  704, 1751,\n",
            "          704,  856, 7389, 3253, 1755,  807, 2339,  897, 2746, 6882, 1197,  738,\n",
            "          679, 1164, 3176, 4496, 1501, 1019, 3419,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['記者黃捷台北報導專營煤炭批發的勇實貿易有限公司涉嫌竄改美化公司訂單向銀行詐貸約億元台北地檢署歷經個月調查今偵結依違反銀行法起訴負責人陳建飛及其員工共人檢調調查勇實公司經營煤炭批發多年因需要資金運轉涉嫌自年起竄改訂單採購單等再持不實單據向銀行貸款透過貸這間還那間的以債養債方式周轉資金直至近年還不出錢造成兆豐銀行板信商銀逾億元呆帳全案才曝光請繼續往下閱讀北檢今年月指揮台北市調查處兵分路搜索並約談負責人陳建飛等多名員工訊後諭令名張姓女財務各萬元交保林姓女會計主管萬元交保邱姓女行政人員萬元交保陳建飛則遭聲押禁見全案並於今天偵結起訴勇實公司主要客戶包括發電業汽電共生業水泥業造紙業紡織業石化業磚瓦業等等年間曾多次違反空氣污染防制法遭台北市環保局等主管機關裁罰罰鍰總額至少萬元'], 'input_ids': tensor([[ 101, 6250, 5442, 7941, 2949, 1378, 1266, 1841, 2206, 2201, 4245, 4209,\n",
            "         4151, 2821, 4634, 4638, 1235, 2179, 6530, 3211, 3300, 7361, 1062, 1385,\n",
            "         3868, 2066, 4985, 3121, 5401, 1265, 1062, 1385, 6242, 1606, 1403, 7065,\n",
            "         6121, 6266, 6526, 5147, 1023, 1039, 1378, 1266, 1765, 3596, 5392, 3644,\n",
            "         5195,  943, 3299, 6310, 3389,  791,  980, 5178,  898, 6889, 1353, 7065,\n",
            "         6121, 3791, 6629, 6260, 6511, 6519,  782, 7376, 2456, 7606, 1350, 1071,\n",
            "         1519, 2339, 1066,  782, 3596, 6310, 6310, 3389, 1235, 2179, 1062, 1385,\n",
            "         5195, 4245, 4209, 4151, 2821, 4634, 1914, 2399, 1728, 7444, 6206, 6536,\n",
            "         7032, 6880, 6752, 3868, 2066, 5632, 2399, 6629, 4985, 3121, 6242, 1606,\n",
            "         2967, 6554, 1606, 5023, 1086, 2898,  679, 2179, 1606, 3087, 1403, 7065,\n",
            "         6121, 6526, 3621, 6851, 6882, 6526, 6857, 7279, 6917, 6929, 7279, 4638,\n",
            "          809, 1002, 7621, 1002, 3175, 2466, 1453, 6752, 6536, 7032, 4684, 5635,\n",
            "         6818, 2399, 6917,  679, 1139, 7092, 6863, 2768, 1042, 6493, 7065, 6121,\n",
            "         3352,  928, 1555, 7065, 6874, 1023, 1039, 1438, 2379, 1059, 3428, 2798,\n",
            "         3284, 1045, 6313, 5262, 5265, 2518,  678, 7288, 6364, 1266, 3596,  791,\n",
            "         2399, 3299, 2900, 3000, 1378, 1266, 2356, 6310, 3389, 5993, 1070, 1146,\n",
            "         6662, 3017, 5164,  699, 5147, 6312, 6511, 6519,  782, 7376, 2456, 7606,\n",
            "         5023, 1914, 1399, 1519, 2339, 6244, 2527, 6323,  808, 1399, 2484, 1998,\n",
            "         1957, 6512, 1243, 1392, 5857, 1039,  769,  924, 3360, 1998, 1957, 3298,\n",
            "         6243,  712, 5052, 5857, 1039,  769,  924, 6937, 1998, 1957, 6121, 3124,\n",
            "          782, 1519, 5857, 1039,  769,  924, 7376, 2456, 7606, 1179, 6901, 5476,\n",
            "         2852, 4881, 6210, 1059, 3428,  699, 3176,  791, 1921,  980, 5178, 6629,\n",
            "         6260, 1235, 2179, 1062, 1385,  712, 6206, 2145, 2786, 1259, 2886, 4634,\n",
            "         7442, 3511, 3749, 7442, 1066, 4495, 3511, 3717, 3799, 3511, 6863, 5158,\n",
            "         3511, 5163, 5251, 3511, 4767, 1265, 3511, 4834, 4482, 3511, 5023, 5023,\n",
            "         2399, 7279, 3295, 1914, 3613, 6889, 1353, 4958, 3706, 3738, 3381, 7344,\n",
            "         1169, 3791, 6901, 1378, 1266, 2356, 4472,  924, 2229, 5023,  712, 5052,\n",
            "         3582, 7302, 6161, 5391, 5391, 7106, 5244, 7540, 5635, 2208, 5857, 1039,\n",
            "          102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([1])}\n",
            "tensor([1], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n",
            "{'review_text': ['盤勢分析技術面分析其實  點並無特別線型壓力主要是投資人心中的無形共識因此我認為  點並不是主要壓力點只是當指數來到這個位置時投資人情緒較為謹慎會導致追價意願減弱從產業趨勢發展來看半導體以 台積大聯盟 最有利基主軸在矽智財其次是設備封測等另外則是庫存調整暫告一段落的  族群雖然大盤呈現開高走低格局然因成交量維持在  億元以上的適度熱絡狀態反而是個股表現相當搶眼；不過從盤面上發現市場 族群性 並不強只有單一個股沒有整個族群顯示投資人心態較為保守還在糾結萬一整體來看因為個股點火的力度夠強說明市場派做多意願濃厚故台股可望在人氣輪動節奏下保持以時間換取空間的整理姿態即以盤代跌楊天迪 分析師 此研究報告著作權屬倫元證券投資顧問 股 公司切勿盜用或翻印否則追究責任決不寬貸 所有資料僅供參考本公司不負盈虧責任'], 'input_ids': tensor([[ 101, 4676, 1248, 1146, 3358, 2825, 6123, 7481, 1146, 3358, 1071, 2179,\n",
            "         7953,  699, 4192, 4294, 1162, 5221, 1798, 1886, 1213,  712, 6206, 3221,\n",
            "         2832, 6536,  782, 2552,  704, 4638, 4192, 2501, 1066, 6352, 1728, 3634,\n",
            "         2769, 6291, 4158, 7953,  699,  679, 3221,  712, 6206, 1886, 1213, 7953,\n",
            "         1372, 3221, 4534, 2900, 3149,  889, 1168, 6857,  943,  855, 5390, 3229,\n",
            "         2832, 6536,  782, 2658, 5219, 6733, 4158, 6346, 2708, 3298, 2206, 5636,\n",
            "         6841, 1019, 2692, 7544, 3938, 2483, 2537, 4496, 3511, 6638, 1248, 4634,\n",
            "         2245,  889, 4692, 1288, 2206, 7768,  809, 1378, 4948, 1920, 5474, 4673,\n",
            "         3297, 3300, 1164, 1825,  712, 6729, 1762, 4769, 3255, 6512, 1071, 3613,\n",
            "         3221, 6257,  991, 2196, 3947, 5023, 1369, 1912, 1179, 3221, 2430, 2100,\n",
            "         6310, 3146, 3271, 1440,  671, 3667, 5862, 4638, 3184, 5408, 7426, 4197,\n",
            "         1920, 4676, 1439, 4412, 7274, 7770, 6624,  856, 3419, 2229, 4197, 1728,\n",
            "         2768,  769, 7030, 5204, 2898, 1762, 1023, 1039,  809,  677, 4638, 6900,\n",
            "         2428, 4229, 5181, 4311, 2706, 1353, 5445, 3221,  943, 5500, 6134, 4412,\n",
            "         4685, 4534, 3024, 4706, 8039,  679, 6882, 2537, 4676, 7481,  677, 4634,\n",
            "         4412, 2356, 1842, 3184, 5408, 2595,  699,  679, 2485, 1372, 3300, 1606,\n",
            "          671,  943, 5500, 3760, 3300, 3146,  943, 3184, 5408, 7549, 4850, 2832,\n",
            "         6536,  782, 2552, 2706, 6733, 4158,  924, 2127, 6917, 1762, 5144, 5178,\n",
            "         5857,  671, 3146, 7768,  889, 4692, 1728, 4158,  943, 5500, 7953, 4125,\n",
            "         4638, 1213, 2428, 1917, 2485, 6303, 3209, 2356, 1842, 3836,  976, 1914,\n",
            "         2692, 7544, 4083, 1331, 3125, 1378, 5500, 1377, 3307, 1762,  782, 3706,\n",
            "         6743, 1240, 5059, 1941,  678,  924, 2898,  809, 3229, 7279, 2994, 1357,\n",
            "         4958, 7279, 4638, 3146, 4415, 2013, 2706, 1315,  809, 4676,  807, 6649,\n",
            "         3501, 1921, 6832, 1146, 3358, 2374, 3634, 4777, 4955, 1841, 1440, 5865,\n",
            "          868, 3609, 2253,  961, 1039, 6349, 1171, 2832, 6536, 7547, 1558, 5500,\n",
            "         1062, 1385, 1147, 1257, 4671, 4500, 2772, 5436, 1313, 1415, 1179, 6841,\n",
            "         4955, 6519,  818, 3748,  679, 2184, 6526, 2792, 3300, 6536, 3160, 1006,\n",
            "          897, 1347, 5440, 3315, 1062, 1385,  679, 6511, 4659, 6000, 6519,  818,\n",
            "          102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['記者陳冠備彰化報導歲李姓男子才跟前妻再婚個月就搭上小歲的白女搞曖昧兩人還一同開車到一處農舍旁空地進行車震正以女上男下姿勢時被李妻當場抓姦白女推稱她昨日剛開完痔瘡結紮手術傷口未癒無法進行激烈的性交姿勢但白女說詞不被法官採信仍依相姦罪判刑月可易科罰金判決書指出年月日李男與前妻復合再婚同年月日李男載著白女到一處偏僻農舍進行車震殊不知李妻與友人已跟車尾隨兩人在車內進行女上男下動作時白女察覺車外有人偷拍急忙跳開衝下車跟李妻理論拉扯間還把李妻手機摔落地面導致面板毀損李妻氣得報警提告相姦與毀損請繼續往下閱讀白女於審理庭時否認有相姦毀損犯行辯稱當天車子還沒停穩李妻就來了也說李男糖尿病很嚴重不知道有沒有性功能當晚沒有發生性行為等語還表示直到去年底出庭時才知李男再婚；其辯護律師也出示醫院診斷書證明白女於前一天月日才到醫院進行痔瘡手術怎麼可能像李妻所說在車內以女上男下激烈性交姿勢而不擔心傷口破裂影響術後癒合不過李男在偵查時就坦承兩人確實有車震表示當時還在做愛時突然發現燈光亮起然後我們就嚇到了庭訊時證稱我跟白女在農舍那裏就是在搞而已她在上面我在下面搞到一半她說怎麼會有燈光我才起來看是我太太進來那晚我們確實有性交在後座椅子當天沒有射精法官審理問李男糖尿病是否影響性功能李男稱服藥年屬輕微李妻也證稱李男還是有性能力等語法官也認為白女痔瘡是長在肛門痔瘡手術後並非不能以陰莖插入陰道方式進行性行為不足以作為有效認定法官審酌白女介入他人婚姻實屬不當又於遭發現相姦行為現場毀損告訴人手機因此依刑法相姦罪判處個月有期徒刑另外依毀損他人物品罪處拘役日皆可易科罰金全案仍可上訴'], 'input_ids': tensor([[ 101, 6250, 5442, 7376, 1094,  991, 2511, 1265, 1841, 2206, 3641, 3330,\n",
            "         1998, 4511, 2094, 2798, 6656, 1184, 1988, 1086, 2042,  943, 3299, 2218,\n",
            "         3022,  677, 2207, 3641, 4638, 4635, 1957, 3018, 3281, 3218, 1060,  782,\n",
            "         6917,  671, 1398, 7274, 6722, 1168,  671, 5993, 6803, 5650, 3178, 4958,\n",
            "         1765, 6868, 6121, 6722, 7448, 3633,  809, 1957,  677, 4511,  678, 2013,\n",
            "         1248, 3229, 6158, 3330, 1988, 4534, 1842, 2831, 2006, 4635, 1957, 2972,\n",
            "         4935, 1961, 3219, 3189, 1190, 7274, 2130, 4574, 4604, 5178, 5167, 2797,\n",
            "         6123, 1003, 1366, 3313, 4618, 4192, 3791, 6868, 6121, 4080, 4164, 4638,\n",
            "         2595,  769, 2013, 1248,  852, 4635, 1957, 6303, 6270,  679, 6158, 3791,\n",
            "         2135, 2967,  928,  793,  898, 4685, 2006, 5389, 1161, 1152, 3299, 1377,\n",
            "         3211, 4906, 5391, 7032, 1161, 3748, 3292, 2900, 1139, 2399, 3299, 3189,\n",
            "         3330, 4511, 5645, 1184, 1988, 2541, 1394, 1086, 2042, 1398, 2399, 3299,\n",
            "         3189, 3330, 4511, 6734, 5865, 4635, 1957, 1168,  671, 5993,  974, 1020,\n",
            "         6803, 5650, 6868, 6121, 6722, 7448, 3654,  679, 4761, 3330, 1988, 5645,\n",
            "         1351,  782, 2347, 6656, 6722, 2227, 7401, 1060,  782, 1762, 6722, 1058,\n",
            "         6868, 6121, 1957,  677, 4511,  678, 1240,  868, 3229, 4635, 1957, 2175,\n",
            "         6221, 6722, 1912, 3300,  782,  982, 2864, 2593, 2564, 6663, 7274, 6128,\n",
            "          678, 6722, 6656, 3330, 1988, 4415, 6316, 2861, 2816, 7279, 6917, 2828,\n",
            "         3330, 1988, 2797, 3582, 3035, 5862, 1765, 7481, 2206, 5636, 7481, 3352,\n",
            "         3672, 3010, 3330, 1988, 3706, 2533, 1841, 6356, 2990, 1440, 4685, 2006,\n",
            "         5645, 3672, 3010, 6313, 5262, 5265, 2518,  678, 7288, 6364, 4635, 1957,\n",
            "         3176, 2182, 4415, 2431, 3229, 1415, 6291, 3300, 4685, 2006, 3672, 3010,\n",
            "         4306, 6121, 6800, 4935, 4534, 1921, 6722, 2094, 6917, 3760,  977, 4952,\n",
            "         3330, 1988, 2218,  889,  749,  738, 6303, 3330, 4511, 5131, 2228, 4567,\n",
            "         2523, 1713, 7028,  679, 4761, 6887, 3300, 3760, 3300, 2595, 1216, 5543,\n",
            "         4534, 3241, 3760, 3300, 4634, 4495, 2595, 6121, 4158, 5023, 6295, 6917,\n",
            "         6134, 4850, 4684, 1168, 1343, 2399, 2419, 1139, 2431, 3229, 2798, 4761,\n",
            "         3330, 4511, 1086, 2042, 8039, 1071, 6800, 6362, 2526, 2374,  738, 1139,\n",
            "         4850, 7015, 7368, 6262, 3174, 3292, 6349, 3209, 4635, 1957, 3176, 1184,\n",
            "          671, 1921, 3299, 3189, 2798, 1168, 7015, 7368, 6868, 6121, 4574, 4604,\n",
            "         2797, 6123, 2582, 7938, 1377, 5543, 1008, 3330, 1988, 2792, 6303, 1762,\n",
            "         6722, 1058,  809, 1957,  677, 4511,  678, 4080, 4164, 2595,  769, 2013,\n",
            "         1248, 5445,  679, 3085, 2552, 1003, 1366, 4788, 6162, 2512, 7513, 6123,\n",
            "         2527, 4618, 1394,  679, 6882, 3330, 4511, 1762,  980, 3389, 3229, 2218,\n",
            "         1788, 2824, 1060,  782, 4825, 2179, 3300, 6722, 7448, 6134, 4850, 4534,\n",
            "         3229, 6917, 1762,  976, 2695, 3229, 4960, 4197, 4634, 4412, 4236, 1045,\n",
            "          778, 6629, 4197, 2527, 2769,  947, 2218, 1702, 1168,  749, 2431, 6244,\n",
            "         3229, 6349, 4935, 2769, 6656, 4635, 1957, 1762, 6803, 5650, 6929, 6166,\n",
            "         2218, 3221, 1762, 3018, 5445, 2347, 1961, 1762,  677, 7481, 2769, 1762,\n",
            "          678, 7481, 3018, 1168,  671, 1288, 1961, 6303, 2582, 7938, 3298, 3300,\n",
            "         4236, 1045, 2769, 2798, 6629,  889, 4692, 3221, 2769, 1922, 1922, 6868,\n",
            "          889, 6929, 3241, 2769,  947, 4825, 2179, 3300, 2595,  769, 1762, 2527,\n",
            "         2429, 3488, 2094, 4534, 1921, 3760, 3300,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['記者楊國文台北報導前總統馬英九涉洩密案高院更一審今判無罪定讞法官認為前檢察總長黃世銘雖被判刑但黃是主動求見馬馬並非主動取得黃交付的資料故馬和黃並非共犯判馬英九無罪備受矚目的前總統馬英九涉洩密等案一審獲判無罪高院改判月徒刑經最高法院撤銷發回更審高院更一審僅開兩次庭即審結相當罕見雖然馬庭訊堅稱清白但檢方指控馬涉案事證明確應判有罪高院更一審今判無罪定讞馬英九未到庭聆判請繼續往下閱讀特別的是馬被控洩密罪等罪原本都是年徒刑以下之罪高院判決後即定讞因大法官前年做出釋字號解釋針對一審無罪而二審判有罪的被告應給予被告一次救濟機會促成立院修法改為得上訴最高法院而馬案被撤銷發回更一審判決後就定讞即為一例更一審時因無證據有待調查或傳訊證人僅在月召開準備庭月召開審理庭並立即言詞辯論馬英九主張只以口頭簡要方式向時任行政院長江宜樺副秘書長羅智強說明司法關說案報告內容目的是為穩定政局一切合憲合法高檢署檢察官周士榆論告批評馬英九洩密等事證明確也違背曾宣誓保障通訊監察的承諾竟將原本只能做為偵查犯罪的通訊監察資料挪為政治目的使用此為通訊監察不可碰觸的紅線和底線此案源於年月日晚時任檢察總長黃世銘向馬英九報告所謂司法關說案的專案報告後馬將相關偵查秘密洩漏給江宜樺羅智強；此外馬還教唆黃於月日向江洩密遭北檢依刑法洩密等罪起訴黃已被判刑年月徒刑定讞台北地院獨任法官唐玥雖認定馬有洩密行為但馬是行使憲法第條的院際調解權是依法令之行為可阻卻違法判馬無罪但高院合議庭審判長江振義受命法官許文章陪席法官潘翠雪認定此案並無院與院之間的爭執馬也未召集院際調解馬罪行明確改判月徒刑最高法院今年月撤銷發回高院更一審但更一審認為一審認定有誤並無法證明馬的犯行此外黃世銘雖被判刑但馬和黃並非共犯黃是主動求見馬馬並非主動取得黃交付的資料；再者馬被訴通保法是否有失職不能以刑法追究刑責檢方也未舉證馬有犯罪事證因此判馬無罪定讞纏訟年多 馬英九洩密案大事紀 馬英九洩密無罪 還有更大條三中案等著出庭'], 'input_ids': tensor([[ 101, 6250, 5442, 3501, 1751, 3152, 1378, 1266, 1841, 2206, 1184, 5244,\n",
            "         5186, 7679, 5739,  736, 3868, 3824, 2166, 3428, 7770, 7368, 3291,  671,\n",
            "         2182,  791, 1161, 4192, 5389, 2137, 6368, 3791, 2135, 6291, 4158, 1184,\n",
            "         3596, 2175, 5244, 7269, 7941,  686, 7071, 7426, 6158, 1161, 1152,  852,\n",
            "         7941, 3221,  712, 1240, 3724, 6210, 7679, 7679,  699, 7478,  712, 1240,\n",
            "         1357, 2533, 7941,  769,  802, 4638, 6536, 3160, 3125, 7679, 1469, 7941,\n",
            "          699, 7478, 1066, 4306, 1161, 7679, 5739,  736, 4192, 5389,  991, 1358,\n",
            "         4756, 4680, 4638, 1184, 5244, 5186, 7679, 5739,  736, 3868, 3824, 2166,\n",
            "         5023, 3428,  671, 2182, 4363, 1161, 4192, 5389, 7770, 7368, 3121, 1161,\n",
            "         3299, 2530, 1152, 5195, 3297, 7770, 3791, 7368, 3059, 7077, 4634, 1726,\n",
            "         3291, 2182, 7770, 7368, 3291,  671, 2182, 1006, 7274, 1060, 3613, 2431,\n",
            "         1315, 2182, 5178, 4685, 4534, 5383, 6210, 7426, 4197, 7679, 2431, 6244,\n",
            "         1830, 4935, 3926, 4635,  852, 3596, 3175, 2900, 2971, 7679, 3868, 3428,\n",
            "          752, 6349, 3209, 4825, 2746, 1161, 3300, 5389, 7770, 7368, 3291,  671,\n",
            "         2182,  791, 1161, 4192, 5389, 2137, 6368, 7679, 5739,  736, 3313, 1168,\n",
            "         2431, 5463, 1161, 6313, 5262, 5265, 2518,  678, 7288, 6364, 4294, 1162,\n",
            "         4638, 3221, 7679, 6158, 2971, 3824, 2166, 5389, 5023, 5389, 1333, 3315,\n",
            "         6963, 3221, 2399, 2530, 1152,  809,  678,  722, 5389, 7770, 7368, 1161,\n",
            "         3748, 2527, 1315, 2137, 6368, 1728, 1920, 3791, 2135, 1184, 2399,  976,\n",
            "         1139, 7026, 2099, 5998, 6237, 7026, 7036, 2205,  671, 2182, 4192, 5389,\n",
            "         5445,  753, 2182, 1161, 3300, 5389, 4638, 6158, 1440, 2746, 5183,  750,\n",
            "         6158, 1440,  671, 3613, 3131, 4089, 3582, 3298,  914, 2768, 4989, 7368,\n",
            "          934, 3791, 3121, 4158, 2533,  677, 6260, 3297, 7770, 3791, 7368, 5445,\n",
            "         7679, 3428, 6158, 3059, 7077, 4634, 1726, 3291,  671, 2182, 1161, 3748,\n",
            "         2527, 2218, 2137, 6368, 1315, 4158,  671,  891, 3291,  671, 2182, 3229,\n",
            "         1728, 4192, 6349, 3087, 3300, 2521, 6310, 3389, 2772, 1001, 6244, 6349,\n",
            "          782, 1006, 1762, 3299, 1374, 7274, 3976,  991, 2431, 3299, 1374, 7274,\n",
            "         2182, 4415, 2431,  699, 4989, 1315, 6241, 6270, 6800, 6316, 7679, 5739,\n",
            "          736,  712, 2484, 1372,  809, 1366, 7531, 5080, 6206, 3175, 2466, 1403,\n",
            "         3229,  818, 6121, 3124, 7368, 7269, 3736, 2139, 3573, 1199, 4908, 3292,\n",
            "         7269, 5397, 3255, 2485, 6303, 3209, 1385, 3791, 7302, 6303, 3428, 1841,\n",
            "         1440, 1058, 2159, 4680, 4638, 3221, 4158, 4952, 2137, 3124, 2229,  671,\n",
            "         1147, 1394, 2740, 1394, 3791, 7770, 3596, 5392, 3596, 2175, 2135, 1453,\n",
            "         1894, 3521, 6316, 1440, 2821, 6268, 7679, 5739,  736, 3824, 2166, 5023,\n",
            "          752, 6349, 3209, 4825,  738, 6889, 5520, 3295, 2146, 6292,  924, 7397,\n",
            "         6858, 6244, 4675, 2175, 4638, 2824, 6330, 4994, 2200, 1333, 3315, 1372,\n",
            "         5543,  976, 4158,  980, 3389, 4306, 5389, 4638, 6858, 6244, 4675, 2175,\n",
            "         6536, 3160, 2918, 4158, 3124, 3780, 4680, 4638,  886, 4500, 3634, 4158,\n",
            "         6858, 6244, 4675, 2175,  679, 1377, 4821, 6240, 4638, 5148, 5221, 1469,\n",
            "         2419, 5221, 3634, 3428, 3975, 3176, 2399, 3299, 3189, 3241, 3229,  818,\n",
            "         3596, 2175, 5244, 7269, 7941,  686, 7071, 1403, 7679, 5739,  736, 1841,\n",
            "         1440, 2792, 6333, 1385, 3791, 7302, 6303, 3428, 4638, 2201, 3428, 1841,\n",
            "         1440, 2527, 7679, 2200, 4685, 7302,  980,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['小燈泡媽媽王婉諭被列在時代力量不分區立委第位後近日她也勤跑基層助選昨（）日更南下新竹參加座談與同黨區域立委候選人高鈺婷聊到親子議題時人都忍不住紅了眼眶身為媽媽為了孩子我們一定會用盡全力地保護我們的下一代沒想到今（）日高鈺婷揭露藍綠新竹林鄭買地團後卻遭到地方人士留言騷擾甚至威脅高位女兒的生命安全直呼何苦當洪仲丘與小燈泡的家人稍早王婉諭於臉書文回應此事強調看到這種留言相當難過憤怒請不要將我的孩子所發生的不幸用來製造其他爸爸媽媽的恐懼害怕這不僅是對我們再一次的傷害更是所有的父母都無法容忍的事王婉諭也強悍表示沒有人應為了揭發不公義的事受到威脅支持高鈺婷提告身為媽媽這種威脅小孩的行為絕對不該再有對於高鈺婷不向威脅低頭依然勇敢出來開記者會揭露此事王婉諭坦言自己又忍不住哭了最後她更不忘加油喊話我們雖然會害怕但一定會一起勇敢保護下一代的未來我們一起勇敢照亮孩子的未來'], 'input_ids': tensor([[ 101, 2207, 4236, 3796, 2061, 2061, 4374, 2039, 6323, 6158, 1154, 1762,\n",
            "         3229,  807, 1213, 7030,  679, 1146, 1281, 4989, 1999, 5018,  855, 2527,\n",
            "         6818, 3189, 1961,  738, 1249, 6651, 1825, 2251, 1221, 6908, 3219, 8020,\n",
            "         8021, 3189, 3291, 1298,  678, 3173, 5001, 1347, 1217, 2429, 6312, 5645,\n",
            "         1398, 7955, 1281, 1818, 4989, 1999,  952, 6908,  782, 7770, 7052, 2051,\n",
            "         5464, 1168, 6217, 2094, 6359, 7539, 3229,  782, 6963, 2556,  679,  857,\n",
            "         5148,  749, 4706, 4702, 6716, 4158, 2061, 2061, 4158,  749, 2111, 2094,\n",
            "         2769,  947,  671, 2137, 3298, 4500, 4674, 1059, 1213, 1765,  924, 6362,\n",
            "         2769,  947, 4638,  678,  671,  807, 3760, 2682, 1168,  791, 8020, 8021,\n",
            "         3189, 7770, 7052, 2051, 2999, 7463, 5965, 5199, 3173, 5001, 3360, 6972,\n",
            "         6525, 1765, 1757, 2527, 1320, 6901, 1168, 1765, 3175,  782, 1894, 4522,\n",
            "         6241, 7703, 3101, 4493, 5635, 2014, 5545, 7770,  855, 1957, 1051, 4638,\n",
            "         4495, 1462, 2128, 1059, 4684, 1461,  862, 5736, 4534, 3825,  815,  687,\n",
            "         5645, 2207, 4236, 3796, 4638, 2157,  782, 4924, 3193, 4374, 2039, 6323,\n",
            "         3176, 5622, 3292, 3152, 1726, 2746, 3634,  752, 2485, 6310, 4692, 1168,\n",
            "         6857, 4934, 4522, 6241, 4685, 4534, 7432, 6882, 2734, 2584, 6313,  679,\n",
            "         6206, 2200, 2769, 4638, 2111, 2094, 2792, 4634, 4495, 4638,  679, 2401,\n",
            "         4500,  889, 6182, 6863, 1071,  800, 4268, 4268, 2061, 2061, 4638, 2607,\n",
            "         2758, 2154, 2586, 6857,  679, 1006, 3221, 2205, 2769,  947, 1086,  671,\n",
            "         3613, 4638, 1003, 2154, 3291, 3221, 2792, 3300, 4638, 4266, 3678, 6963,\n",
            "         4192, 3791, 2159, 2556, 4638,  752, 4374, 2039, 6323,  738, 2485, 2636,\n",
            "         6134, 4850, 3760, 3300,  782, 2746, 4158,  749, 2999, 4634,  679, 1062,\n",
            "         5412, 4638,  752, 1358, 1168, 2014, 5545, 3118, 2898, 7770, 7052, 2051,\n",
            "         2990, 1440, 6716, 4158, 2061, 2061, 6857, 4934, 2014, 5545, 2207, 2111,\n",
            "         4638, 6121, 4158, 5179, 2205,  679, 6283, 1086, 3300, 2205, 3176, 7770,\n",
            "         7052, 2051,  679, 1403, 2014, 5545,  856, 7531,  898, 4197, 1235, 3140,\n",
            "         1139,  889, 7274, 6250, 5442, 3298, 2999, 7463, 3634,  752, 4374, 2039,\n",
            "         6323, 1788, 6241, 5632, 2346, 1348, 2556,  679,  857, 1526,  749, 3297,\n",
            "         2527, 1961, 3291,  679, 2563, 1217, 3779, 1591, 6282, 2769,  947, 7426,\n",
            "         4197, 3298, 2154, 2586,  852,  671, 2137, 3298,  671, 6629, 1235, 3140,\n",
            "          924, 6362,  678,  671,  807, 4638, 3313,  889, 2769,  947,  671, 6629,\n",
            "         1235, 3140, 4212,  778, 2111, 2094, 4638, 3313,  889,  102,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['這裡是我的戰情指揮中心走進股市中實戶林適中在北市中山區的寓所落地窗就能遠眺台北平日他就窩在書房一隅大量閱讀資訊偶爾抬頭看看電視牆上跳動的股價指數書房裡還有一台滑步機腦力激盪之餘林適中不忘運動健身運動時會分泌腦內啡是平衡情緒維持理性的重要賀爾蒙投資時才能保持客觀身材精實做過研究員的林適中投資績效以倍數計縱橫股市逾年累積出上億元雄厚資本曾有買下中菲行成股權的實力看好的公司也會重押萬張以上期間台股跌到千點大家都慘兮兮他卻一派輕鬆投資同好與林適中相識年的牙醫林一夫指出幫林適中治療牙齒他總是問東問西想弄清楚為何這樣治療談投資他一樣追根究底但弄清楚是為了心裡踏實   \\u3000嚴謹的執念展現在他對產業趨勢的掌握及對公司營運的徹底了解但他掌握趨勢的方法並不複雜看書報雜誌從新聞中抓住蛛絲馬跡雖然每個時期的趨勢產業不同但只要投注在風口上的產業資本變大的速度一定遠比其他成熟產業快確立趨勢之後林適中關注的是占到穩當份額成長性高的公司因為第一名的優勢就是第一名他會挑出年可望翻倍的成長股觀察重點包括：公司營收年複合成長率達以上毛利率有機會大幅提升至以上（每股稅後純益）年成長率可達～然後從中找出本益比仍低的公司這個世界變化太大了只能看到～年的趨勢但必須確保年以後這家公司還是會活得比現在好而他偏愛股價盤整多年籌碼乾淨的公司在市場尚未聚焦前逢低布局\\u3000年林適中發現中國成為世界工廠的趨勢成形貨運承攬龍頭中菲行受惠最大但一直被市場忽略於是他以均價約元持續買進萬張股票年金融海嘯前因本益比過高出脫持股期間股價最高漲到逾元年多獲利近倍曾面試林適中當研究員的萬寶投顧董事長朱成志發現林適中看中的股票通常觀察半年甚至年才會出手他會多面向檢視並與專家討論確認後重押長期持有能夠這般篤定重押全然是因為他有一套評估股價和計算獲利的方法千檔台股中我真正能算得出未來獲利與成長性的可能不超過檔但看這檔就夠了以中菲行為例年約元他預估中國收成股的中菲行未來～年營收複合成長率可達將提升到近元以此回推當時股價元的中菲行本益比僅倍中國成為世界工廠中菲行的物流必將受惠而且趨勢至少～年不變林適中估算隨著獲利成長中菲行的本益比可望拉升到倍股價可望達到元後來中菲行股價漲到超乎預估的多元\\u3000只要算清楚未來價值就不用害怕歷經至少次重大股災的林適中即使手上股票淨值下跌成也老神在在不做融資所以耐得住留在市場股災過後有競爭力的公司仍會創新高其實年輕時林適中也融資買股我拿父親給的萬元本金玩股票年滾到多萬元但年景氣反轉加上過度融資資產大幅蒸發賠到剩萬元他痛下決心停掉融資戶沉潛年從頭開始改以研究產業趨勢和公司基本面重押具爆發力的成長股得以賺取大波段行情學做股票的頭年我看的書比小學到大學加起來還要多原來念書時林適中是個讓父母頭痛的小孩考上師大附中後耽溺於玩樂高二還因無照騎機車出車禍骨折無法上課最後跟不上學業決定休學後來在家自修以高中同等學力報考大學輾轉念了個科系卻還是沒畢業結果我只有國中文憑林適中忍不住自謔退伍後年他賣過保險房子還跟人合夥開過便當店我業務做得很好但年少氣盛個人意識較強與人合作常理念不合孤鳥性格加上職涯不順母親擔心他無所事事建議他跟著公務員退休的父親學做投資我每天跟父親到號子幫忙跑腿遞單子觀摩父親怎麼做為了磨練基本功他選擇進入台灣首家券商華昌投顧當研究員也曾在股市大戶賈文中的證券公司上班\\u3000選對趨勢產業重點在必須辨別出它是實現性很高的新趨勢而不是雷聲大雨點小的題材年林適中從新聞訊息發現政府積極發展替代能源產業其中以離岸風電最具競爭力年政黨輪替後大力推動替代能源並舉辦離岸風電招標眼看趨勢成形他從元附近開始布局鋼結構廠世紀鋼平均成本約元年世紀鋼搭上風電題材股價暴漲倍雖然之後大跌但林適中不但沒賣出任一張股票跌破元時還加碼因為這不僅是未來年的趨勢產業也是台灣第一次有了自主性的能源產業鏈即使身價上億林適中仍然紀律作息每天閱讀大量資訊我只做十拿九穩的投資而做足功課下好離手等待大行情收割則是他歷經年股海浮沉仍立於不敗的武器\\u3000 步驟從新聞訊息找趨勢向上具爆發力的產業：年前從新聞台灣離岸風電規畫場址公告注意到政府積極發展替代能源產業；年政黨輪替後舉辦離岸風電招標因此鎖定風電股步驟挑選龍頭或具競爭優勢的公司評估獲利成長性：眼看趨勢成形從本土供應鏈中發現即使近年鋼構業不景氣世紀鋼也沒賠錢林適中估算傳統鋼構業毛利約而風機的鋼構因規格及製程嚴謹毛利達成加上世紀鋼股本小有機會達到至元當時股價不到元回推本益比僅約倍步驟拜訪公司與經營層討論多方確認：勤勞蒐集公司相關報導並檢視月營收變化甚至親訪公司年月德國達德能源與世紀鋼鐵子公司世紀風電簽訂備忘錄是第一件通過環評的離岸風力發電案實際操作近年帳面獲利逾倍：年月林適中在股價元附近持續買進世紀鋼平均成本約元隔年月間盤中最高價來到元帳面獲利逾倍月底風電股漲多修正世紀鋼單月跌但林適中不僅未賣還在股價跌破元時加碼目前股價回升至元以上迄今帳面獲利逾倍'], 'input_ids': tensor([[ 101, 6857, 6174, 3221, 2769, 4638, 2782, 2658, 2900, 3000,  704, 2552,\n",
            "         6624, 6868, 5500, 2356,  704, 2179, 2786, 3360, 6900,  704, 1762, 1266,\n",
            "         2356,  704, 2255, 1281, 4638, 2171, 2792, 5862, 1765, 4970, 2218, 5543,\n",
            "         6895, 4705, 1378, 1266, 2398, 3189,  800, 2218, 4979, 1762, 3292, 2791,\n",
            "          671, 7383, 1920, 7030, 7288, 6364, 6536, 6244,  981, 4273, 2848, 7531,\n",
            "         4692, 4692, 7442, 6213, 4274,  677, 6663, 1240, 4638, 5500, 1019, 2900,\n",
            "         3149, 3292, 2791, 6174, 6917, 3300,  671, 1378, 3998, 3635, 3582, 5582,\n",
            "         1213, 4080, 4679,  722, 7626, 3360, 6900,  704,  679, 2563, 6880, 1240,\n",
            "          978, 6716, 6880, 1240, 3229, 3298, 1146, 3789, 5582, 1058, 1565, 3221,\n",
            "         2398, 6130, 2658, 5219, 5204, 2898, 4415, 2595, 4638, 7028, 6206, 6531,\n",
            "         4273, 5885, 2832, 6536, 3229, 2798, 5543,  924, 2898, 2145, 6223, 6716,\n",
            "         3332, 5125, 2179,  976, 6882, 4777, 4955, 1519, 4638, 3360, 6900,  704,\n",
            "         2832, 6536, 5245, 3126,  809,  945, 3149, 6243, 5241, 3585, 5500, 2356,\n",
            "         6874, 2399, 5168, 4948, 1139,  677, 1023, 1039, 7413, 1331, 6536, 3315,\n",
            "         3295, 3300, 6525,  678,  704, 5838, 6121, 2768, 5500, 3609, 4638, 2179,\n",
            "         1213, 4692, 1962, 4638, 1062, 1385,  738, 3298, 7028, 2852, 5857, 2484,\n",
            "          809,  677, 3309, 7279, 1378, 5500, 6649, 1168, 1283, 7953, 1920, 2157,\n",
            "         6963, 2711, 1064, 1064,  800, 1320,  671, 3836, 6738, 7777, 2832, 6536,\n",
            "         1398, 1962, 5645, 3360, 6900,  704, 4685, 6352, 2399, 4638, 4280, 7015,\n",
            "         3360,  671, 1923, 2900, 1139, 2396, 3360, 6900,  704, 3780, 4615, 4280,\n",
            "         7971,  800, 5244, 3221, 1558, 3346, 1558, 6205, 2682, 2462, 3926, 3504,\n",
            "         4158,  862, 6857, 3564, 3780, 4615, 6312, 2832, 6536,  800,  671, 3564,\n",
            "         6841, 3418, 4955, 2419,  852, 2462, 3926, 3504, 3221, 4158,  749, 2552,\n",
            "         6174, 6672, 2179, 1713, 6346, 4638, 1822, 2573, 2245, 4412, 1762,  800,\n",
            "         2205, 4496, 3511, 6638, 1248, 4638, 2958, 2995, 1350, 2205, 1062, 1385,\n",
            "         4245, 6880, 4638, 2549, 2419,  749, 6237,  852,  800, 2958, 2995, 6638,\n",
            "         1248, 4638, 3175, 3791,  699,  679, 6185, 7429, 4692, 3292, 1841, 7429,\n",
            "         6290, 2537, 3173, 5472,  704, 2831,  857, 6033, 5187, 7679, 6657, 7426,\n",
            "         4197, 3680,  943, 3229, 3309, 4638, 6638, 1248, 4496, 3511,  679, 1398,\n",
            "          852, 1372, 6206, 2832, 3800, 1762, 7591, 1366,  677, 4638, 4496, 3511,\n",
            "         6536, 3315, 6365, 1920, 4638, 6862, 2428,  671, 2137, 6895, 3683, 1071,\n",
            "          800, 2768, 4225, 4496, 3511, 2571, 4825, 4989, 6638, 1248,  722, 2527,\n",
            "         3360, 6900,  704, 7302, 3800, 4638, 3221, 1304, 1168, 4952, 4534,  819,\n",
            "         7540, 2768, 7269, 2595, 7770, 4638, 1062, 1385, 1728, 4158, 5018,  671,\n",
            "         1399, 4638, 1032, 1248, 2218, 3221, 5018,  671, 1399,  800, 3298, 2904,\n",
            "         1139, 2399, 1377, 3307, 5436,  945, 4638, 2768, 7269, 5500, 6223, 2175,\n",
            "         7028, 7953, 1259, 2886, 8038, 1062, 1385, 4245, 3119, 2399, 6185, 1394,\n",
            "         2768, 7269, 4372, 6888,  809,  677, 3688, 1164, 4372, 3300, 3582, 3298,\n",
            "         1920, 2388, 2990, 1285, 5635,  809,  677, 8020, 3680, 5500, 4922, 2527,\n",
            "         5155, 4660, 8021, 2399, 2768, 7269, 4372, 1377, 6888, 8080, 4197, 2527,\n",
            "         2537,  704, 2823, 1139, 3315, 4660, 3683,  793,  856, 4638, 1062, 1385,\n",
            "         6857,  943,  686, 4518, 6365, 1265, 1922, 1920,  749, 1372, 5543, 4692,\n",
            "         1168, 8080, 2399, 4638, 6638, 1248,  852,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['中美大打貿易戰抑制美國農產品出口在玉米小麥和黃豆等農產品價格大跌之際美國農業帶（ ）的農民發現種電比農作物更有利可圖中美互徵關稅衝擊市場對美國農產品的需求玉米小麥和黃豆期貨價跌至年以來新低水準農業帶入不敷出的農民開始在田裡裝設太陽能板供自用或是出售以彌補短少的收入尼爾森夫婦在明尼蘇達州英畝的土地種植玉米和黃豆過去年來收入減少約他們打算將部分土地拿來種電當地一家電力公司同意支付每年萬美元在未來年向尼爾森夫婦承租英畝土地種電想要種電的農民現在有兩種選擇把土地出租給能源公司農地太陽能板的電力將輸送至網格尼爾森夫婦就是採用這種方法另一種方式是裝設自有的太陽能板電力供自家使用以降低電費支出根據農民和再生能源倡議人士表示兩種方法皆能創造每個月超過美元的利潤明尼蘇達州非營利組織 的主管戴維斯（ ）表示農民對種電改善收入的興趣逐漸濃厚該組織協助美國個州的數百位農民在田地裝設太陽能板不過種電需要與電力公司簽定長期合約讓部分農民裏足不前農民表示如果穀物價格反彈種電的收入將不如農產品美國農民正經歷嚴重的商品跌價促使農民決定冒險賭一把根據美國農業事務聯合會的數據顯示年上半年聲請破產的農場大增創下年以來最高水準農民亞當斯（ ）年將威斯康辛州英畝的土地全部出租種電一年可獲得每英畝美元的收入他表示：種電成為豐富收入來源的好辦法'], 'input_ids': tensor([[ 101,  704, 5401, 1920, 2802, 6530, 3211, 2782, 2829, 1169, 5401, 1751,\n",
            "         6803, 4496, 1501, 1139, 1366, 1762, 4373, 5101, 2207, 7930, 1469, 7941,\n",
            "         6486, 5023, 6803, 4496, 1501, 1019, 3419, 1920, 6649,  722, 7396, 5401,\n",
            "         1751, 6803, 3511, 2380, 8020, 8021, 4638, 6803, 3696, 4634, 4412, 4934,\n",
            "         7442, 3683, 6803,  868, 4289, 3291, 3300, 1164, 1377, 1756,  704, 5401,\n",
            "          757, 2547, 7302, 4922, 6128, 3080, 2356, 1842, 2205, 5401, 1751, 6803,\n",
            "         4496, 1501, 4638, 7444, 3724, 4373, 5101, 2207, 7930, 1469, 7941, 6486,\n",
            "         3309, 6515, 1019, 6649, 5635, 2399,  809,  889, 3173,  856, 3717, 3976,\n",
            "         6803, 3511, 2380, 1057,  679, 3148, 1139, 4638, 6803, 3696, 7274, 1993,\n",
            "         1762, 4506, 6174, 6172, 6257, 1922, 7382, 5543, 3352,  897, 5632, 4500,\n",
            "         2772, 3221, 1139, 1545,  809, 2493, 6171, 4764, 2208, 4638, 3119, 1057,\n",
            "         2225, 4273, 3481, 1923, 2044, 1762, 3209, 2225, 5979, 6888, 2336, 5739,\n",
            "         4524, 4638, 1759, 1765, 4934, 3490, 4373, 5101, 1469, 7941, 6486, 6882,\n",
            "         1343, 2399,  889, 3119, 1057, 3938, 2208, 5147,  800,  947, 2802, 5050,\n",
            "         2200, 6956, 1146, 1759, 1765, 2897,  889, 4934, 7442, 4534, 1765,  671,\n",
            "         2157, 7442, 1213, 1062, 1385, 1398, 2692, 3118,  802, 3680, 2399, 5857,\n",
            "         5401, 1039, 1762, 3313,  889, 2399, 1403, 2225, 4273, 3481, 1923, 2044,\n",
            "         2824, 4909, 5739, 4524, 1759, 1765, 4934, 7442, 2682, 6206, 4934, 7442,\n",
            "         4638, 6803, 3696, 4412, 1762, 3300, 1060, 4934, 6908, 3079, 2828, 1759,\n",
            "         1765, 1139, 4909, 5183, 5543, 3975, 1062, 1385, 6803, 1765, 1922, 7382,\n",
            "         5543, 3352, 4638, 7442, 1213, 2200, 6745, 6843, 5635, 5206, 3419, 2225,\n",
            "         4273, 3481, 1923, 2044, 2218, 3221, 2967, 4500, 6857, 4934, 3175, 3791,\n",
            "         1369,  671, 4934, 3175, 2466, 3221, 6172, 6257, 5632, 3300, 4638, 1922,\n",
            "         7382, 5543, 3352, 7442, 1213,  897, 5632, 2157,  886, 4500,  809, 7360,\n",
            "          856, 7442, 6527, 3118, 1139, 3418, 3087, 6803, 3696, 1469, 1086, 4495,\n",
            "         5543, 3975,  956, 6359,  782, 1894, 6134, 4850, 1060, 4934, 3175, 3791,\n",
            "         4639, 5543, 1201, 6863, 3680,  943, 3299, 6631, 6882, 5401, 1039, 4638,\n",
            "         1164, 4056, 3209, 2225, 5979, 6888, 2336, 7478, 4245, 1164, 5175, 5251,\n",
            "         4638,  712, 5052, 2785, 5204, 3172, 8020, 8021, 6134, 4850, 6803, 3696,\n",
            "         2205, 4934, 7442, 3121, 1587, 3119, 1057, 4638, 5646, 6637, 6852, 4041,\n",
            "         4083, 1331, 6283, 5175, 5251, 1295, 1221, 5401, 1751,  943, 2336, 4638,\n",
            "         3149, 4636,  855, 6803, 3696, 1762, 4506, 1765, 6172, 6257, 1922, 7382,\n",
            "         5543, 3352,  679, 6882, 4934, 7442, 7444, 6206, 5645, 7442, 1213, 1062,\n",
            "         1385, 5087, 2137, 7269, 3309, 1394, 5147, 6366, 6956, 1146, 6803, 3696,\n",
            "         6166, 6639,  679, 1184, 6803, 3696, 6134, 4850, 1963, 3362, 4944, 4289,\n",
            "         1019, 3419, 1353, 2492, 4934, 7442, 4638, 3119, 1057, 2200,  679, 1963,\n",
            "         6803, 4496, 1501, 5401, 1751, 6803, 3696, 3633, 5195, 3644, 1713, 7028,\n",
            "         4638, 1555, 1501, 6649, 1019,  914,  886, 6803, 3696, 3748, 2137, 1088,\n",
            "         7402, 6551,  671, 2828, 3418, 3087, 5401, 1751, 6803, 3511,  752, 1243,\n",
            "         5474, 1394, 3298, 4638, 3149, 3087, 7549, 4850, 2399,  677, 1288, 2399,\n",
            "         5476, 6313, 4788, 4496, 4638, 6803, 1842, 1920, 1872, 1201,  678, 2399,\n",
            "          809,  889, 3297, 7770, 3717, 3976, 6803, 3696,  765, 4534, 3172, 8020,\n",
            "         8021, 2399, 2200, 2014, 3172, 2434, 6789,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['在停擺兩個月後美中貿易談判本周終於再度重啟為市場重燃希望不過法人認為貿易戰尚未完全落幕投資人應留意接下來的會談過程可能讓市場再起漣漪因此建議下半年投資可採取軟硬兼施的策略避開美中兩國角力帶來的直接衝擊所謂軟指的是軟實力產業如： 人工智慧金融科技等透過 大數據雲端網路平台等創新技術為企業帶來貢獻屬於無實體商品在貿易戰課稅範圍之外；硬指的是剛性需求包括：水電瓦斯等民生必需品及醫療服務等無論市場景氣如何變化需求永遠存在第一金全球  人工智慧基金經理人陳世杰表示全球企業發展和運用  的腳步未受貿易戰的影響 在近期最新報告中指出今年企業對  系統的投資金額預估為  億美元較去年大幅增長 且未來  年將持續高速增長到  年投資額將擴大到  億美元年複合成長率 陳世杰表示 技術自  年開始被亞馬遜谷歌等大型企業採用不僅強化獲利品牌價值也跟著水漲船高引發各產業關注美中在內的主要國家都傾政策力量協助企業發展  軟實力根據  資料預估從  年到  年 相關企業的獲利年複合成長率為 遠高於那斯達克指數成份企業的   企業的 代表儘管全球政經環境不穩企業獲利成長放緩 仍舊是投資市場的明燈剛性需求部分第一金全球水電瓦斯及基礎建設收益基金經理人葉菀婷表示去年  月貿易戰開打後考驗各產業的耐震度而幾乎所有類股波動度都大幅竄升惟公用事業不增反減截至今年  月中為止波動度只有 低於工業金融原物料能源等動輒  成以上的幅度顯示抗震效果佳葉菀婷分析公用事業中以水電瓦斯為主大多為內需市場各國都獨立發展股價表現與其他區域關聯性低不因事件而相互牽連除此之外隨著城市化程度越來越高對水電瓦斯等民生必須品的需求量同步增加讓經營這類民生用品輸配送的企業獲利穩健成長支撐股價表現第一金投信獨立經營管理本基金經金管會核准或同意生效惟不表示絕無風險基金經理公司以往之經理績效不保證基金之最低投資收益；基金經理公司除盡善良管理人之注意義務外不負責基金之盈虧亦不保證最低之收益投資人申購前應詳閱基金公開說明書有關基金應負擔之費用（境外基金含分銷費用反稀釋費用）及基金之相關投資風險已揭露於基金之公開說明書或投資人須知中本公司及各銷售機構備有公開說明書歡迎索取或自行至本公司官網（）公開資訊觀測站（）或境外基金資訊觀測站（）下載投資人應注意基金投資之風險包括匯率風險利率風險債券交易市場流動性不足之風險及投資無擔保公司債之風險；基金或有因利率變動債券交易市場流動性不足及定期存單提前解約而影響基金淨值下跌之風險同時或有受益人大量贖回時致延遲給付贖回價款之可能基金高收益債券之投資占顯著比重者適合能承受較高風險之非保守型之投資人由於高收益債券之信用評等未達投資等級或未經信用評等且對利率變動的敏感度甚高故本基金可能會因利率上升市場流動性下降或債券發行機構違約不支付本金利息或破產而蒙受虧損投資人應審慎評估本基金不適合無法承擔相關風險之投資人投資人投資以高收益債券為訴求之基金不宜占其投資組合過高之比重投資高收益債券之基金可能投資美國   債券（境內基金投資比例最高可達基金總資產 ）該債券屬私募性質易發生流動性不足財務訊息揭露不完整或價格不透明導致高波動性之風險部分可配息基金配息前未先扣除應負擔之相關費用且基金的配息可能由基金的收益或本金中支付任何涉及由本金支出的部份可能導致原始投資金額以同等比例減損基金配息率不代表基金報酬率且過去配息率不代表未來配息率；基金淨值可能因市場因素而上下波動投資人可至本公司官網查詢最近  個月內由本金支付之配息組成項目基金配息之年化配息率為估算值計算公式為每單位配息金額  除息日前一日之淨值 × 一年配息次數 × 各期間報酬率 含息 是假設收益分配均滾入再投資於本基金之期間累積報酬率內容涉及新興市場部分因其波動性與風險程度較高且政治與經濟情勢穩定度可能低於已開發國家可能使資產價值受不同程度之影響現階段法令限制投資於中國證券市場僅限掛牌上市之有價證券且境外基金總金額不得超過基金淨資產價值 中國大陸為外匯管制市場投資相關有價證券可能有資金無法即時匯回之風險或可能因特殊情事致延遲給付買回價款投資人另須留意中國巿場特定政治經濟法規與巿場等投資風險匯率走勢可能影響所投資之海外資產而使資產價值變動本資料提及之經濟走勢預測不必然代表該基金之績效基金投資風險請詳閱基金公開說明書投資人因不同時間進場將有不同之投資績效過去之績效亦不代表未來績效之保證以過去績效進行模擬投資組合之報酬率僅為歷史資料模擬投資組合之結果不代表任何基金或相關投資組合之實際報酬率及未來績效保證；不同時間進行模擬操作結果可能不同本資料提及之企業指數或投資標的僅為舉例說明之用不代表任何投資之推薦有關未成立之基金初期資產配置僅為暫訂之規劃實際投資配置可能依市場狀況而改變基金風險報酬等級依投信投顧公會分類標準由低至高分為  等五個等級此分類係基於一般市況反映市場價格波動風險無法涵蓋所有風險不宜作為投資唯一依據投資人仍應注意所投資基金之個別風險並考量個人風險承擔能力資金可運用期間等始為投資判斷本基金之風險可能含有產業景氣循環變動流動性不足外匯管制投資地區政經社會變動或其他投資風險遞延手續費  級別持有未滿  年手續費率分別為 於買回時以申購金額贖回金額孰低計收滿  年者免付本新聞稿內容僅供參考若將新聞稿再編製者應以本公司所公開資料為主不得為誇大不實之報導'], 'input_ids': tensor([[ 101, 1762,  977, 3099, 1060,  943, 3299, 2527, 5401,  704, 6530, 3211,\n",
            "         6312, 1161, 3315, 1453, 5173, 3176, 1086, 2428, 7028, 1564, 4158, 2356,\n",
            "         1842, 7028, 4234, 2361, 3307,  679, 6882, 3791,  782, 6291, 4158, 6530,\n",
            "         3211, 2782, 2213, 3313, 2130, 1059, 5862, 2391, 2832, 6536,  782, 2746,\n",
            "         4522, 2692, 2970,  678,  889, 4638, 3298, 6312, 6882, 4923, 1377, 5543,\n",
            "         6366, 2356, 1842, 1086, 6629, 4032, 4034, 1728, 3634, 2456, 6359,  678,\n",
            "         1288, 2399, 2832, 6536, 1377, 2967, 1357, 6727, 4801, 1076, 3177, 4638,\n",
            "         5032, 4526, 6912, 7274, 5401,  704, 1060, 1751, 6235, 1213, 2380,  889,\n",
            "         4638, 4684, 2970, 6128, 3080, 2792, 6333, 6727, 2900, 4638, 3221, 6727,\n",
            "         2179, 1213, 4496, 3511, 1963, 8038,  782, 2339, 3255, 2716, 7032, 6084,\n",
            "         4906, 2825, 5023, 6851, 6882, 1920, 3149, 3087, 7437, 4999, 5206, 6662,\n",
            "         2398, 1378, 5023, 1201, 3173, 2825, 6123, 4158,  821, 3511, 2380,  889,\n",
            "         6513, 4368, 2253, 3176, 4192, 2179, 7768, 1555, 1501, 1762, 6530, 3211,\n",
            "         2782, 6307, 4922, 5061, 1752,  722, 1912, 8039, 4801, 2900, 4638, 3221,\n",
            "         1190, 2595, 7444, 3724, 1259, 2886, 8038, 3717, 7442, 4482, 3172, 5023,\n",
            "         3696, 4495, 2553, 7444, 1501, 1350, 7015, 4615, 3302, 1243, 5023, 4192,\n",
            "         6316, 2356, 1842, 3250, 3706, 1963,  862, 6365, 1265, 7444, 3724, 3719,\n",
            "         6895, 2100, 1762, 5018,  671, 7032, 1059, 4413,  782, 2339, 3255, 2716,\n",
            "         1825, 7032, 5195, 4415,  782, 7376,  686, 3345, 6134, 4850, 1059, 4413,\n",
            "          821, 3511, 4634, 2245, 1469, 6880, 4500, 4638, 5589, 3635, 3313, 1358,\n",
            "         6530, 3211, 2782, 4638, 2512, 7513, 1762, 6818, 3309, 3297, 3173, 1841,\n",
            "         1440,  704, 2900, 1139,  791, 2399,  821, 3511, 2205, 5143, 5186, 4638,\n",
            "         2832, 6536, 7032, 7540, 7521,  844, 4158, 1023, 5401, 1039, 6733, 1343,\n",
            "         2399, 1920, 2388, 1872, 7269,  684, 3313,  889, 2399, 2200, 2898, 5265,\n",
            "         7770, 6862, 1872, 7269, 1168, 2399, 2832, 6536, 7540, 2200, 3097, 1920,\n",
            "         1168, 1023, 5401, 1039, 2399, 6185, 1394, 2768, 7269, 4372, 7376,  686,\n",
            "         3345, 6134, 4850, 2825, 6123, 5632, 2399, 7274, 1993, 6158,  765, 7679,\n",
            "         6893, 6484, 3625, 5023, 1920, 1798,  821, 3511, 2967, 4500,  679, 1006,\n",
            "         2485, 1265, 4363, 1164, 1501, 4277, 1019,  966,  738, 6656, 5865, 3717,\n",
            "         4039, 5670, 7770, 2471, 4634, 1392, 4496, 3511, 7302, 3800, 5401,  704,\n",
            "         1762, 1058, 4638,  712, 6206, 1751, 2157, 6963, 1005, 3124, 5032, 1213,\n",
            "         7030, 1295, 1221,  821, 3511, 4634, 2245, 6727, 2179, 1213, 3418, 3087,\n",
            "         6536, 3160, 7521,  844, 2537, 2399, 1168, 2399, 4685, 7302,  821, 3511,\n",
            "         4638, 4363, 1164, 2399, 6185, 1394, 2768, 7269, 4372, 4158, 6895, 7770,\n",
            "         3176, 6929, 3172, 6888, 1046, 2900, 3149, 2768,  819,  821, 3511, 4638,\n",
            "          821, 3511, 4638,  807, 6134, 1029, 5052, 1059, 4413, 3124, 5195, 4472,\n",
            "         1862,  679, 4952,  821, 3511, 4363, 1164, 2768, 7269, 3123, 5227,  793,\n",
            "         5648, 3221, 2832, 6536, 2356, 1842, 4638, 3209, 4236, 1190, 2595, 7444,\n",
            "         3724, 6956, 1146, 5018,  671, 7032, 1059, 4413, 3717, 7442, 4482, 3172,\n",
            "         1350, 1825, 4843, 2456, 6257, 3119, 4660, 1825, 7032, 5195, 4415,  782,\n",
            "         5864, 5820, 2051, 6134, 4850, 1343, 2399, 3299, 6530, 3211, 2782, 7274,\n",
            "         2802, 2527, 5440, 7710, 1392, 4496, 3511, 4638, 5447, 7448, 2428, 5445,\n",
            "         2407,  725, 2792, 3300, 7546, 5500, 3797,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['大盤趨勢由於美國費城半導體指數拉回影響台積電股價表現加上利空新聞影響股價因而出現空方缺口跌破季線此次的跌破代表台積電股價將會走向區間震盪整理直到季線扣抵再次走入低檔區之後才有機會重回多方趨勢目前美中的科技冷戰持續華爾街投資人在沒有看到商務部明顯動作之前對於半導體類股將會維持觀望的態度預期到第四季之後台股才能更為明朗目前盤勢資金雖受空方力道影響但是個股之間仍相對有機會表現生技類股目前漲勢較為整齊不過多數仍是個股表現依照題材而各自發揮平盤之上的股票不少包括帶量創高的  訊聯買盤不斷的  國光收盤見高的  旭富法人追買的  美時有高點就有後續唯量能不要失控生技仍有機會在  月份表現今天  新鉅科打入跌停不僅僅是增資折價的問題指紋辨識才是下跌的主因而今天另一檔  精材漲停此消彼長代表後續指紋辨識的受惠股將會進入江山換手先前中國團購 是否帶動產業競爭的變革將會是台股下一個矚目的焦點華冠投顧 鍾騏遠分析師華冠證券投資顧問股份有限公司  證管投顧新字第  號本資料僅供參考投資時應審慎評估'], 'input_ids': tensor([[ 101, 1920, 4676, 6638, 1248, 4507, 3176, 5401, 1751, 6527, 1814, 1288,\n",
            "         2206, 7768, 2900, 3149, 2861, 1726, 2512, 7513, 1378, 4948, 7442, 5500,\n",
            "         1019, 6134, 4412, 1217,  677, 1164, 4958, 3173, 5472, 2512, 7513, 5500,\n",
            "         1019, 1728, 5445, 1139, 4412, 4958, 3175, 5375, 1366, 6649, 4788, 2108,\n",
            "         5221, 3634, 3613, 4638, 6649, 4788,  807, 6134, 1378, 4948, 7442, 5500,\n",
            "         1019, 2200, 3298, 6624, 1403, 1281, 7279, 7448, 4679, 3146, 4415, 4684,\n",
            "         1168, 2108, 5221, 2807, 2850, 1086, 3613, 6624, 1057,  856, 3593, 1281,\n",
            "          722, 2527, 2798, 3300, 3582, 3298, 7028, 1726, 1914, 3175, 6638, 1248,\n",
            "         4680, 1184, 5401,  704, 4638, 4906, 2825, 1107, 2782, 2898, 5265, 5836,\n",
            "         4273, 6125, 2832, 6536,  782, 1762, 3760, 3300, 4692, 1168, 1555, 1243,\n",
            "         6956, 3209, 7549, 1240,  868,  722, 1184, 2205, 3176, 1288, 2206, 7768,\n",
            "         7546, 5500, 2200, 3298, 5204, 2898, 6223, 3307, 4638, 2706, 2428, 7521,\n",
            "         3309, 1168, 5018, 1724, 2108,  722, 2527, 1378, 5500, 2798, 5543, 3291,\n",
            "         4158, 3209, 3306, 4680, 1184, 4676, 1248, 6536, 7032, 7426, 1358, 4958,\n",
            "         3175, 1213, 6887, 2512, 7513,  852, 3221,  943, 5500,  722, 7279,  793,\n",
            "         4685, 2205, 3300, 3582, 3298, 6134, 4412, 4495, 2825, 7546, 5500, 4680,\n",
            "         1184, 4039, 1248, 6733, 4158, 3146, 7968,  679, 6882, 1914, 3149,  793,\n",
            "         3221,  943, 5500, 6134, 4412,  898, 4212, 7539, 3332, 5445, 1392, 5632,\n",
            "         4634, 3000, 2398, 4676,  722,  677, 4638, 5500, 4873,  679, 2208, 1259,\n",
            "         2886, 2380, 7030, 1201, 7770, 4638, 6244, 5474, 6525, 4676,  679, 3174,\n",
            "         4638, 1751, 1045, 3119, 4676, 6210, 7770, 4638, 3195, 2168, 3791,  782,\n",
            "         6841, 6525, 4638, 5401, 3229, 3300, 7770, 7953, 2218, 3300, 2527, 5265,\n",
            "         1546, 7030, 5543,  679, 6206, 1927, 2971, 4495, 2825,  793, 3300, 3582,\n",
            "         3298, 1762, 3299,  819, 6134, 4412,  791, 1921, 3173, 7056, 4906, 2802,\n",
            "         1057, 6649,  977,  679, 1006, 1006, 3221, 1872, 6536, 2835, 1019, 4638,\n",
            "         1558, 7539, 2900, 5151, 6795, 6352, 2798, 3221,  678, 6649, 4638,  712,\n",
            "         1728, 5445,  791, 1921, 1369,  671, 3593, 5125, 3332, 4039,  977, 3634,\n",
            "         3867, 2516, 7269,  807, 6134, 2527, 5265, 2900, 5151, 6795, 6352, 4638,\n",
            "         1358, 2669, 5500, 2200, 3298, 6868, 1057, 3736, 2255, 2994, 2797, 1044,\n",
            "         1184,  704, 1751, 1757, 6554, 3221, 1415, 2380, 1240, 4496, 3511, 5000,\n",
            "         4261, 4638, 6365, 7484, 2200, 3298, 3221, 1378, 5500,  678,  671,  943,\n",
            "         4756, 4680, 4638, 4193, 7953, 5836, 1094, 2832, 7547, 7109, 7698, 6895,\n",
            "         1146, 3358, 2374, 5836, 1094, 6349, 1171, 2832, 6536, 7547, 1558, 5500,\n",
            "          819, 3300, 7361, 1062, 1385, 6349, 5052, 2832, 7547, 3173, 2099, 5018,\n",
            "         5998, 3315, 6536, 3160, 1006,  897, 1347, 5440, 2832, 6536, 3229, 2746,\n",
            "         2182, 2708, 6268,  844,  102,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['富少游瀚甯去年開藍寶堅尼跑車炸隧道在北市自強隧道內超速撞上工程車造成死傷慘劇同車女友也殞命此案士林地院排定日再度開庭不過周刊報導傳游瀚甯已和被害人家屬達成和解金額超過萬元創下車禍賠償新高紀錄去年月日凌晨時許游瀚甯與友人相約飆車競速游在飆車前還頭戴錄影設備以手機連線要錄下飆速經過他開著租來的藍寶堅尼超跑載著劉姓女友車子開進自強隧道後狂飆平均時速超過公里甚至最高達到公里高速行駛噪音在隧道發生巨響就是車友所謂的炸隧道當時隧道內有張姓名工人正在施工並停放工程車游因車速過快來不及減速閃避撞上人導致張姓工人死亡另人受傷游男也受傷劉姓女友亦死亡事後畫面曝光車禍發生瞬間游的女友在副駕駛座滑手機連尖叫呼喊都來不及就已殞命場面十分驚悚今年月日檢方依過失致死罪嫌起訴游；然上月日士林地院首度開庭檢察官突然提出要變更起訴法條改以刑度較重的刑法條妨害公眾往來安全致死罪論告刑期至少年最重可判無期徒刑游男當庭表示我認罪但對追加刑法條部分表示要請教律師據鏡週刊報導游男已與被害人家屬達成和解金額超過萬元創下車禍和解金新高紀錄中時電子報'], 'input_ids': tensor([[ 101, 2168, 2208, 3952, 4108, 4505, 1343, 2399, 7274, 5965, 2188, 1830,\n",
            "         2225, 6651, 6722, 4156, 7400, 6887, 1762, 1266, 2356, 5632, 2485, 7400,\n",
            "         6887, 1058, 6631, 6862, 3058,  677, 2339, 4923, 6722, 6863, 2768, 3647,\n",
            "         1003, 2711, 1206, 1398, 6722, 1957, 1351,  738, 3660, 1462, 3634, 3428,\n",
            "         1894, 3360, 1765, 7368, 2961, 2137, 3189, 1086, 2428, 7274, 2431,  679,\n",
            "         6882, 1453, 1149, 1841, 2206, 1001, 3952, 4108, 4505, 2347, 1469, 6158,\n",
            "         2154,  782, 2157, 2253, 6888, 2768, 1469, 6237, 7032, 7540, 6631, 6882,\n",
            "         5857, 1039, 1201,  678, 6722, 4884, 6543, 1030, 3173, 7770, 5145, 7087,\n",
            "         1343, 2399, 3299, 3189, 1119, 3247, 3229, 6258, 3952, 4108, 4505, 5645,\n",
            "         1351,  782, 4685, 5147, 7598, 6722, 5000, 6862, 3952, 1762, 7598, 6722,\n",
            "         1184, 6917, 7531, 2785, 7087, 2512, 6257,  991,  809, 2797, 3582, 6865,\n",
            "         5221, 6206, 7087,  678, 7598, 6862, 5195, 6882,  800, 7274, 5865, 4909,\n",
            "          889, 4638, 5965, 2188, 1830, 2225, 6631, 6651, 6734, 5865, 1208, 1998,\n",
            "         1957, 1351, 6722, 2094, 7274, 6868, 5632, 2485, 7400, 6887, 2527, 4312,\n",
            "         7598, 2398, 1772, 3229, 6862, 6631, 6882, 1062, 7027, 4493, 5635, 3297,\n",
            "         7770, 6888, 1168, 1062, 7027, 7770, 6862, 6121, 7691, 1692, 7509, 1762,\n",
            "         7400, 6887, 4634, 4495, 2342, 7513, 2218, 3221, 6722, 1351, 2792, 6333,\n",
            "         4638, 4156, 7400, 6887, 4534, 3229, 7400, 6887, 1058, 3300, 2484, 1998,\n",
            "         1399, 2339,  782, 3633, 1762, 3177, 2339,  699,  977, 3123, 2339, 4923,\n",
            "         6722, 3952, 1728, 6722, 6862, 6882, 2571,  889,  679, 1350, 3938, 6862,\n",
            "         7272, 6912, 3058,  677,  782, 2206, 5636, 2484, 1998, 2339,  782, 3647,\n",
            "          767, 1369,  782, 1358, 1003, 3952, 4511,  738, 1358, 1003, 1208, 1998,\n",
            "         1957, 1351,  771, 3647,  767,  752, 2527, 4529, 7481, 3284, 1045, 6722,\n",
            "         4884, 4634, 4495, 4746, 7279, 3952, 4638, 1957, 1351, 1762, 1199, 7690,\n",
            "         7691, 2429, 3998, 2797, 3582, 6865, 2211, 1373, 1461, 1591, 6963,  889,\n",
            "          679, 1350, 2218, 2347, 3660, 1462, 1842, 7481, 1282, 1146, 7711, 2639,\n",
            "          791, 2399, 3299, 3189, 3596, 3175,  898, 6882, 1927, 5636, 3647, 5389,\n",
            "         2066, 6629, 6260, 3952, 8039, 4197,  677, 3299, 3189, 1894, 3360, 1765,\n",
            "         7368, 7674, 2428, 7274, 2431, 3596, 2175, 2135, 4960, 4197, 2990, 1139,\n",
            "         6206, 6365, 3291, 6629, 6260, 3791, 3454, 3121,  809, 1152, 2428, 6733,\n",
            "         7028, 4638, 1152, 3791, 3454, 1981, 2154, 1062, 4707, 2518,  889, 2128,\n",
            "         1059, 5636, 3647, 5389, 6316, 1440, 1152, 3309, 5635, 2208, 2399, 3297,\n",
            "         7028, 1377, 1161, 4192, 3309, 2530, 1152, 3952, 4511, 4534, 2431, 6134,\n",
            "         4850, 2769, 6291, 5389,  852, 2205, 6841, 1217, 1152, 3791, 3454, 6956,\n",
            "         1146, 6134, 4850, 6206, 6313, 3136, 2526, 2374, 3087, 7128, 6867, 1149,\n",
            "         1841, 2206, 3952, 4511, 2347, 5645, 6158, 2154,  782, 2157, 2253, 6888,\n",
            "         2768, 1469, 6237, 7032, 7540, 6631, 6882, 5857, 1039, 1201,  678, 6722,\n",
            "         4884, 1469, 6237, 7032, 3173, 7770, 5145, 7087,  704, 3229, 7442, 2094,\n",
            "         1841,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['記者楊國文台北報導台灣第一家有限公司被查出將砷含量超標的工業用碳酸鎂摻入胡椒粉椒鹽粉等產品出售給超市雜貨店並供旗下台灣第一家鹽酥雞店面使用一審依違反食安法的食品添加物有毒而加工罪輕判創辦人陳廷智之子總經理陳星佑年徒刑陳廷智長女即副總陳鏡如年僅沒收萬犯罪所得；高等法院則痛斥陳星佑陳鏡如兩人犯罪近兩年無悔意加重分別改判為年半年並將銷售額億萬元均視為犯罪所得須沒收陳廷智仍無罪可上訴判決指出陳廷智年間就已將經營權交給子女未實際管事只將胡椒粉配方傳給兒子陳星佑兒子掌握產品生產業務長女陳鏡如負責財務及會計事務請繼續往下閱讀年間陳星佑得知碳酸鎂可避免胡椒粉受潮一公斤食用碳酸鎂約元工業用碳酸鎂約至元成本有到倍落差於是向純佳公司購買允成化工生產的允成鹽基性碳酸鎂碳酸鎂貨品上明明註明   （僅限工業使用）仍然添加年食安法修法後陳星佑仍以比比例把工業用碳酸鎂加入胡椒粉椒鹽粉等產品出售給超市雜貨店另供旗下台灣第一家鹽酥雞店面使用新北市政府衛生局將查扣的碳酸鎂送驗發現砷含量達超過標準屬有毒食品添加物新北檢方起訴認定台灣第一家不法所得達億多元但新北地院認定有落差從食安法年修法後算起共萬餘元高等法院則認定陳星佑陳鏡如犯罪時間近兩年所販售椒盬粉等項食品總售額高達億萬多元都是犯罪所得因此均須沒收或追徵消基會指出長期食用工業用碳酸鎂恐會傷肝腎'], 'input_ids': tensor([[ 101, 6250, 5442, 3501, 1751, 3152, 1378, 1266, 1841, 2206, 1378, 4124,\n",
            "         5018,  671, 2157, 3300, 7361, 1062, 1385, 6158, 3389, 1139, 2200, 4789,\n",
            "         1419, 7030, 6631, 3560, 4638, 2339, 3511, 4500, 4823, 7000, 7110, 3046,\n",
            "         1057, 5529, 3492, 5106, 3492, 7921, 5106, 5023, 4496, 1501, 1139, 1545,\n",
            "         5183, 6631, 2356, 7429, 6515, 2421,  699,  897, 3186,  678, 1378, 4124,\n",
            "         5018,  671, 2157, 7921, 6989, 7430, 2421, 7481,  886, 4500,  671, 2182,\n",
            "          898, 6889, 1353, 7608, 2128, 3791, 4638, 7608, 1501, 3924, 1217, 4289,\n",
            "         3300, 3681, 5445, 1217, 2339, 5389, 6738, 1161, 1201, 6794,  782, 7376,\n",
            "         2455, 3255,  722, 2094, 5244, 5195, 4415, 7376, 3215,  859, 2399, 2530,\n",
            "         1152, 7376, 2455, 3255, 7269, 1957, 1315, 1199, 5244, 7376, 7128, 1963,\n",
            "         2399, 1006, 3760, 3119, 5857, 4306, 5389, 2792, 2533, 8039, 7770, 5023,\n",
            "         3791, 7368, 1179, 4578, 3166, 7376, 3215,  859, 7376, 7128, 1963, 1060,\n",
            "          782, 4306, 5389, 6818, 1060, 2399, 4192, 2637, 2692, 1217, 7028, 1146,\n",
            "         1162, 3121, 1161, 4158, 2399, 1288, 2399,  699, 2200, 7077, 1545, 7540,\n",
            "         1023, 5857, 1039, 1772, 6213, 4158, 4306, 5389, 2792, 2533, 7519, 3760,\n",
            "         3119, 7376, 2455, 3255,  793, 4192, 5389, 1377,  677, 6260, 1161, 3748,\n",
            "         2900, 1139, 7376, 2455, 3255, 2399, 7279, 2218, 2347, 2200, 5195, 4245,\n",
            "         3609,  769, 5183, 2094, 1957, 3313, 2179, 7396, 5052,  752, 1372, 2200,\n",
            "         5529, 3492, 5106, 6981, 3175, 1001, 5183, 1051, 2094, 7376, 3215,  859,\n",
            "         1051, 2094, 2958, 2995, 4496, 1501, 4495, 4496, 3511, 1243, 7269, 1957,\n",
            "         7376, 7128, 1963, 6511, 6519, 6512, 1243, 1350, 3298, 6243,  752, 1243,\n",
            "         6313, 5262, 5265, 2518,  678, 7288, 6364, 2399, 7279, 7376, 3215,  859,\n",
            "         2533, 4761, 4823, 7000, 7110, 1377, 6912, 1048, 5529, 3492, 5106, 1358,\n",
            "         4060,  671, 1062, 3165, 7608, 4500, 4823, 7000, 7110, 5147, 1039, 2339,\n",
            "         3511, 4500, 4823, 7000, 7110, 5147, 5635, 1039, 2768, 3315, 3300, 1168,\n",
            "          945, 5862, 2345, 3176, 3221, 1403, 5155,  881, 1062, 1385, 6554, 6525,\n",
            "         1038, 2768, 1265, 2339, 4495, 4496, 4638, 1038, 2768, 7921, 1825, 2595,\n",
            "         4823, 7000, 7110, 4823, 7000, 7110, 6515, 1501,  677, 3209, 3209, 6263,\n",
            "         3209, 8020, 1006, 7361, 2339, 3511,  886, 4500, 8021,  793, 4197, 3924,\n",
            "         1217, 2399, 7608, 2128, 3791,  934, 3791, 2527, 7376, 3215,  859,  793,\n",
            "          809, 3683, 3683,  891, 2828, 2339, 3511, 4500, 4823, 7000, 7110, 1217,\n",
            "         1057, 5529, 3492, 5106, 3492, 7921, 5106, 5023, 4496, 1501, 1139, 1545,\n",
            "         5183, 6631, 2356, 7429, 6515, 2421, 1369,  897, 3186,  678, 1378, 4124,\n",
            "         5018,  671, 2157, 7921, 6989, 7430, 2421, 7481,  886, 4500, 3173, 1266,\n",
            "         2356, 3124, 2424, 6127, 4495, 2229, 2200, 3389, 2807, 4638, 4823, 7000,\n",
            "         7110, 6843, 7710, 4634, 4412, 4789, 1419, 7030, 6888, 6631, 6882, 3560,\n",
            "         3976, 2253, 3300, 3681, 7608, 1501, 3924, 1217, 4289, 3173, 1266, 3596,\n",
            "         3175, 6629, 6260, 6291, 2137, 1378, 4124, 5018,  671, 2157,  679, 3791,\n",
            "         2792, 2533, 6888, 1023, 1914, 1039,  852, 3173, 1266, 1765, 7368, 6291,\n",
            "         2137, 3300, 5862, 2345, 2537, 7608, 2128, 3791, 2399,  934, 3791, 2527,\n",
            "         5050, 6629, 1066, 5857, 7626, 1039, 7770, 5023, 3791, 7368, 1179, 6291,\n",
            "         2137, 7376, 3215,  859, 7376, 7128, 1963, 4306, 5389, 3229, 7279, 6818,\n",
            "         1060, 2399, 2792, 6516, 1545, 3492,  100,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([1])}\n",
            "tensor([1], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n",
            "{'review_text': ['阿根廷總統初選結果爆冷門反對派候選人艾伯托   得票率大幅領先現任總統馬克里  引發阿根廷金融市場重挫阿根廷債指數利差大幅飆升近  點殖利率來到 匯市也挫跌 拖累整體新興債市表現中國信託投信債券  經理人張勝原表示就指數成分來看中信  主權債  分散布局於三大新興市場並未持有阿根廷綜觀拉美市場除了阿根廷及委內瑞拉其他國家通膨率目前均控制得宜水準約在  至  間有助於民眾購買力也提供央行實施寬鬆貨幣政策空間張勝原表示阿根廷大選將於  月正式舉行若最終由反對派取得勝利艾伯托的選舉搭擋費南德茲     的支出承諾恐使阿根廷財政陷入困境也可能使國際貨幣基金  的援助計劃出現變數信評機構惠譽  也暗示債務可能會因選舉結果出現惡化的可能阿根廷真正的大選將於  月舉行然阿根廷匯率出現重貶恐將加重目前已相當嚴重的通膨加上經濟仍陷衰退及政治風險擴大阿根廷債價格恐再大幅震盪好消息是阿根廷債務壓力及政治不確定性應不會向外擴散且昨日阿根廷央行已出手干預匯率後市上可觀察反對派是否有提出更為明確的政策張勝原表示整體而言根據  統計 年新興市場公司債違約率 略高於  至  年水準但由於近年來新興市場公司積極降槓桿因此仍低於  至  年的平均水準展望後市下半年新興市場主權債波動可能加大然而在新興市場多數國家央行相繼降息之下仍有利新興市場債後市表現此外短年期債券受到市場波動的影響相對較小在美國債券殖利率來到  年  月以來新低的情況下持有新興市場短天期債券 或可為投資人提供相對誘人的收益同時降低資產波動中國信託投信獨立經營管理本公司經理之基金皆經金管會核准或同意生效在國內募集及銷售惟並不表示絕無風險本公司除盡善良管理人之注意義務外不負責投資之盈虧基金經理公司以往之經理績效不保證基金之最低投資收益亦不必然為未來績效表現投資人申購前應詳閱基金公開說明書基金應負擔之費用（含分銷費用）已揭露於基金之公開說明書中投資人可前往本公司網站及公開資訊觀測站中查詢各銷售機構均備有基金公開說明書歡迎索取匯率走勢亦可能影響所投資之海外資產而使資產價值變動本資料僅供參考請勿將其視為買賣基金或其他任何投資之建議或邀約以上所作任何投資意見與市場分析結果係依據資料製作當時情況進行判斷本公司已力求資訊之正確與完整惟文中之數據預測或意見仍可能有脫漏或錯誤之處本公司不保證本資料內容及來源資料之正確及完整性；或因市場環境變化已有變更投資標的之價格與收益亦將隨時變動投資人因不同時間進場將有不同之投資績效過去的績效亦不代表未來績效之保證投資人應自行判斷投資標的投資風險或尋求專業之投資建議不應將本資料內容引為投資之唯一依據若有投資損益或因使用本資料所生之直接或間接損失應由投資人自行負責本文提及之經濟走勢預測不必然代表基金之績效基金投資風險請詳閱基金公開說明書本基金並無受存款保險保險安定基金或其他相關保障機制之保障故投資本基金可能發生部分或全部本金之損失最大可能損失則為全部投資金額金融消費爭議處理及申訴管道：就本公司所提供之金融商品或服務所生紛爭投資人應先向本公司提出申訴若三十日內未獲回覆或投資人不滿意處理結果得於六十日內向金融消費評議中心申請評議本公開說明書之內容如有虛偽或隱匿之情事者應由本經理公司及負責人與其他曾在公開說明書上簽章者依法負責中國信託新興亞洲 不含中國 美元精選綜合債券  基金 本基金有一定比重投資於非投資等級之高風險債券及中國信託新興市場  年期美元政府債券  基金本基金有一定比重投資於非投資等級之高風險債券等子基金投資涉及新興市場部份因其波動性及風險程度可能較高且其政治經濟情勢穩定度可能低於已開發國家基金淨資產價值可能承受不同程度的影響及基金資產有一定比重投資於非投資等級之高風險債券由於高收益債券之信用評等由於未達投資等級且對利率變動的敏感度甚高故部份基金可能會因利率上升市場流動性下降或債券發行機構違約不支付本金利息或破產而蒙受虧損該等基金不適合無法承擔相關風險之投資人且不宜占投資人投資組合過高之比重各子基金之操作目標在追蹤與標的指數相關之報酬中國信託中國國債及政策性金融債  至  年期債券  基金之標的指數為彭博巴克萊中國國債及政策性金融債  至  年期債券指數中國信託新興亞洲不含中國 美元精選綜合債券  證券投資信託基金之標的指數為彭博巴克萊新興亞洲 不含中國 美元精選綜合債券指數及 中國信託新興市場  年期美元政府債券  基金之標的指數為  新興市場  年期美元政府債券指數而標的成分債券價格波動包括但不限於受利多利空債券交易市場流動性不足交易對手之信用風險利率風險等因素影響 將影響基金標的指數的走勢然基金追求標的指數報酬之目標不因標的指數劇烈波動而改變交易大陸地區境內債券風險包含：信用評等風險流動性風險及法令變動風險等另外境內債券可循債券通方式投資大陸地區債券其相關投資相關風險：包括交易機制不確定性之風險額度限制風險交易產生之營運及操作風險交易對手風險匯率風險價格與債券流動性風險跨境交易風險及法規遵循風險等各子基金可能面臨之風險包含但不限於債券流動性風險匯率風險投資地區政治或經濟變動之風險交易對手信用風險等而基金所投資之債券可能隱含發行人無法償付本息之違約風險各子基金所投資標的發生上開風險時基金之淨資產價值可能因此產生波動其他有關投資風險之揭露請詳閱各子基金公開說明書本基金雖以追蹤標的指數報酬為目標然下列因素仍可能使基金報酬偏離標的指數報酬且偏離方向無法預估：  基金可能因應申贖或維持所需曝險比例等因素而需每日進行基金曝險調整故基金淨值將受到每日所交易之有價證券或期貨成交價格交易費用基金其他必要之費用如：經理費保管費上櫃費等投資組合成分價格波動或基金整體曝險比例等因素的影響而使基金報酬與投資目標產生偏離  基金投資組合與標的指數相關性將受到基金持有之有價證券或期貨與標的指數之相關性等因素影響此外基金投資組合中持有的期貨部位因期貨的價格發現功能使其對市場信息多空走勢之價格反應可能不同於債券因此當市場出現特定信息時基金淨值將同時承受期貨及債券對市場信息反應不一所產生的價格波動影響可能使基金報酬將與投資目標產生偏離 基金以新臺幣計價而基金所投資的有價證券或期貨標的可能為新臺幣以外之計價貨幣由於各子基金暫不從事匯率避險因此各子基金承受相關匯率波動風險可能使基金報酬與投資目標產生偏離各子基金可能面臨之風險包含但不限於債券流動性風險匯率風險投資地區政治或經濟變動之風險交易對手信用風險等而基金所投資之債券可能隱含發行人無法償付本息之違約風險各子基金所投資標的發生上開風險時基金之淨資產價值可能因此產生波動基金自成立日起即運用基金資產進行投資組合佈局基金投資組合成分價格波動會影響基金淨值表現投資人於基金成立日 不含當日 前參與申購所買入的基金每受益權單位之發行價格不等於基金掛牌上櫃之價格參與申購投資人需自行承擔基金成立日起自上櫃掛牌日止期間之基金淨資產價格波動所產生之折  溢價的風險本基金上櫃日前 不含當日經理公司不接受基金受益權單位數之買回基金受益憑證上櫃後之買賣成交價格無升降幅度限制並應依財團法人中華民國證券櫃檯買賣中心以下簡稱證券櫃檯買賣中心 所有關規定辦理各子基金於上櫃日後將依證券櫃檯買賣中心所規定於臺灣證券交易時間內提供盤中估計淨值供投資人參考基金淨值以新臺幣計價而基金主要投資標的為外幣計價之債券或期貨因此匯率波動會影響基金淨值之計算而計算盤中估計淨值所使用的盤中即時匯率因評價時點及資訊來源不同與實際基金淨值計算之匯率或有差異因此計算盤中估計淨值與實際基金淨值計算之基金投組或有差異投資人應注意盤中估計淨值與實際淨值可能有誤差值之風險經理公司於臺灣證券交易時間內提供的盤中估計淨值僅供投資人參考實際淨值應以本公司最終公告之每日淨值為準各子基金配息率不代表基金報酬率且過去配息率不代表未來配息率基金淨值可能因市場因素而上下波動於獲配息時須一併注意基金淨值之變動'], 'input_ids': tensor([[ 101, 7350, 3418, 2455, 5244, 5186, 1159, 6908, 5178, 3362, 4255, 1107,\n",
            "         7271, 1353, 2205, 3836,  952, 6908,  782, 5687,  843, 2805, 2533, 4873,\n",
            "         4372, 1920, 2388, 7526, 1044, 4412,  818, 5244, 5186, 7679, 1046, 7027,\n",
            "         2471, 4634, 7350, 3418, 2455, 7032, 6084, 2356, 1842, 7028, 2919, 7350,\n",
            "         3418, 2455, 1002, 2900, 3149, 1164, 2345, 1920, 2388, 7598, 1285, 6818,\n",
            "         7953, 3658, 1164, 4372,  889, 1168, 1274, 2356,  738, 2919, 6649, 2870,\n",
            "         5168, 3146, 7768, 3173, 5646, 1002, 2356, 6134, 4412,  704, 1751,  928,\n",
            "         6249, 2832,  928, 1002, 1171, 5195, 4415,  782, 2484, 1245, 1333, 6134,\n",
            "         4850, 2218, 2900, 3149, 2768, 1146,  889, 4692,  704,  928,  712, 3609,\n",
            "         1002, 1146, 3141, 2357, 2229, 3176,  676, 1920, 3173, 5646, 2356, 1842,\n",
            "          699, 3313, 2898, 3300, 7350, 3418, 2455, 5198, 6223, 2861, 5401, 2356,\n",
            "         1842, 7370,  749, 7350, 3418, 2455, 1350, 1999, 1058, 4448, 2861, 1071,\n",
            "          800, 1751, 2157, 6858, 5610, 4372, 4680, 1184, 1772, 2971, 1169, 2533,\n",
            "         2139, 3717, 3976, 5147, 1762, 5635, 7279, 3300, 1221, 3176, 3696, 4707,\n",
            "         6554, 6525, 1213,  738, 2990,  897, 1925, 6121, 2179, 3177, 2184, 7777,\n",
            "         6515, 2395, 3124, 5032, 4958, 7279, 2484, 1245, 1333, 6134, 4850, 7350,\n",
            "         3418, 2455, 1920, 6908, 2200, 3176, 3299, 3633, 2466, 5647, 6121, 5735,\n",
            "         3297, 5173, 4507, 1353, 2205, 3836, 1357, 2533, 1245, 1164, 5687,  843,\n",
            "         2805, 4638, 6908, 5647, 3022, 3081, 6527, 1298, 2548, 5760, 4638, 3118,\n",
            "         1139, 2824, 6330, 2607,  886, 7350, 3418, 2455, 6512, 3124, 7379, 1057,\n",
            "         1737, 1862,  738, 1377, 5543,  886, 1751, 7396, 6515, 2395, 1825, 7032,\n",
            "         4638, 3001, 1221, 6243, 1205, 1139, 4412, 6365, 3149,  928, 6268, 3582,\n",
            "         3539, 2669, 6363,  738, 3266, 4850, 1002, 1243, 1377, 5543, 3298, 1728,\n",
            "         6908, 5647, 5178, 3362, 1139, 4412, 2670, 1265, 4638, 1377, 5543, 7350,\n",
            "         3418, 2455, 4696, 3633, 4638, 1920, 6908, 2200, 3176, 3299, 5647, 6121,\n",
            "         4197, 7350, 3418, 2455, 1274, 4372, 1139, 4412, 7028, 6524, 2607, 2200,\n",
            "         1217, 7028, 4680, 1184, 2347, 4685, 4534, 1713, 7028, 4638, 6858, 5610,\n",
            "         1217,  677, 5195, 4089,  793, 7379, 6139, 6842, 1350, 3124, 3780, 7591,\n",
            "         7402, 3097, 1920, 7350, 3418, 2455, 1002, 1019, 3419, 2607, 1086, 1920,\n",
            "         2388, 7448, 4679, 1962, 3867, 2622, 3221, 7350, 3418, 2455, 1002, 1243,\n",
            "         1886, 1213, 1350, 3124, 3780,  679, 4825, 2137, 2595, 2746,  679, 3298,\n",
            "         1403, 1912, 3097, 3141,  684, 3219, 3189, 7350, 3418, 2455, 1925, 6121,\n",
            "         2347, 1139, 2797, 2397, 7521, 1274, 4372, 2527, 2356,  677, 1377, 6223,\n",
            "         2175, 1353, 2205, 3836, 3221, 1415, 3300, 2990, 1139, 3291, 4158, 3209,\n",
            "         4825, 4638, 3124, 5032, 2484, 1245, 1333, 6134, 4850, 3146, 7768, 5445,\n",
            "         6241, 3418, 3087, 5186, 6243, 2399, 3173, 5646, 2356, 1842, 1062, 1385,\n",
            "         1002, 6889, 5147, 4372, 4526, 7770, 3176, 5635, 2399, 3717, 3976,  852,\n",
            "         4507, 3176, 6818, 2399,  889, 3173, 5646, 2356, 1842, 1062, 1385, 4948,\n",
            "         3513, 7360, 3544, 3447, 1728, 3634,  793,  856, 3176, 5635, 2399, 4638,\n",
            "         2398, 1772, 3717, 3976, 2245, 3307, 2527, 2356,  678, 1288, 2399, 3173,\n",
            "         5646, 2356, 1842,  712, 3609, 1002, 3797, 1240, 1377, 5543, 1217, 1920,\n",
            "         4197, 5445, 1762, 3173, 5646, 2356, 1842, 1914, 3149, 1751, 2157, 1925,\n",
            "         6121, 4685, 5262, 7360, 2622,  722,  678,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['加藤鷹當年號稱能只靠手指就讓女性在秒內高潮如今手指前端紅腫發黑他自嘲經過洗滌金手指破爛不堪疑似患病的手指也讓網友為他的身體擔憂紛紛要他趕緊去看醫生還有網友戲稱這是工傷加藤鷹入行多年合作過位女優拍攝超過部作品雖然引退已超過年但這段期間仍有不少工作邀約加藤鷹曾在接受訪問時透露雖然很久沒拍但難說哪天會再復出他笑說：為了再用到的一天我每天都有保養我的手指'], 'input_ids': tensor([[ 101, 1217, 5972, 7877, 4534, 2399, 5998, 4935, 5543, 1372, 7479, 2797,\n",
            "         2900, 2218, 6366, 1957, 2595, 1762, 4907, 1058, 7770, 4060, 1963,  791,\n",
            "         2797, 2900, 1184, 4999, 5148, 5584, 4634, 7946,  800, 5632, 1672, 5195,\n",
            "         6882, 3819, 3997, 7032, 2797, 2900, 4788, 4258,  679, 1838, 4542,  849,\n",
            "         2642, 4567, 4638, 2797, 2900,  738, 6366, 5206, 1351, 4158,  800, 4638,\n",
            "         6716, 7768, 3085, 2726, 5160, 5160, 6206,  800, 6634, 5215, 1343, 4692,\n",
            "         7015, 4495, 6917, 3300, 5206, 1351, 2783, 4935, 6857, 3221, 2339, 1003,\n",
            "         1217, 5972, 7877, 1057, 6121, 1914, 2399, 1394,  868, 6882,  855, 1957,\n",
            "         1032, 2864, 3109, 6631, 6882, 6956,  868, 1501, 7426, 4197, 2471, 6842,\n",
            "         2347, 6631, 6882, 2399,  852, 6857, 3667, 3309, 7279,  793, 3300,  679,\n",
            "         2208, 2339,  868, 6913, 5147, 1217, 5972, 7877, 3295, 1762, 2970, 1358,\n",
            "         6256, 1558, 3229, 6851, 7463, 7426, 4197, 2523,  719, 3760, 2864,  852,\n",
            "         7432, 6303, 1525, 1921, 3298, 1086, 2541, 1139,  800, 5010, 6303, 8038,\n",
            "         4158,  749, 1086, 4500, 1168, 4638,  671, 1921, 2769, 3680, 1921, 6963,\n",
            "         3300,  924, 7621, 2769, 4638, 2797, 2900,  102,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['全球寬鬆的貨幣政策將持續支撐市場美國聯準會一如預期於日利率政策會議後宣布聯邦基金利率維持不變介於～的區間根據會議結束後發布的聲明內容顯示勞動市場依然強勁經濟活動一直處於溫和增長但商業投資與出口仍相對疲軟此外會後聲明刪除了月聲明中曾提及的經濟前景的不確定依然存在顯示對經濟與就業信心略有增強的說詞；而聯準會主席鮑爾提到目前經濟和貨幣政策都處於有利地位等的說法亦為市場對於經濟前景挹注更多的信心回顧今年以來可謂是經濟與政策的轉變年全球經濟放緩由聯準會帶頭吹起的降息風加上貿易戰英國硬脫歐等擔憂出現轉圜資產普遍亮眼表現而全球市場在資金流動快速下不同市場和資產輪動表現全球經濟放緩主要受到新興國家歐洲與日本等國家影響美國經濟雖受到川普財政政策刺激與減稅政策影響但亦逐步走向周期後段而由聯準會帶頭的降息政策轉彎也明顯吹向新興市場今年以來已經有逾個國家陸續降息顯示寬鬆政策效應也逐步在新興市場中擴散新興市場央行跟隨成熟市場央行的做法今年已顯著提升貨幣政策的寬鬆程度而且估計將有更多寬鬆措施這無疑為年底的風險胃納提供了技術支撐如果簡單歸納可以發現今年支撐資產有表現的原因第一個是評價面也就是去年跌太多今年因而出現反彈第二個伴隨著貨幣政策的寬鬆再來是財政政策的擴散正因為上述這三大原因讓全球市場呈現差異化表現再觀察資金面年初以來近兆美元的資金流入貨幣市場和債券基金後最近幾周也出現變化全球股票基金開始出現億美元以上的資金流入在此之前年初以來流失逾億美元顯示目前投資人開始對經濟穩定展現信心展望年投資收益美國聯準會保持彈向料將使美國年公債殖利率在至溫和水準徘徊有利整體債市表現也提供新興國家央行進一步寬鬆的空間策略上建議聚焦美元債以及部分當地計價的新興市場債券全球央行採取寬貨幣政策將利率維持在低點市場尋找收益的需求強烈短期多空訊息紛雜且年底前市場將因假期而產生籌碼凌亂的情況策略上可伺機加碼信用債各地區與債種位居不同信用周期表現料也將分歧建議聚焦體質穩健或具改善機會且流動性佳的企業債種上高信評優低信評偏好美歐投資及債及流動性較佳的美高收與部分歐高收但建議避開級與槓桿貸款等體質較差的債種其次縮短存續期宜中性看待主要考量是下半年以來連續兩次降息聯準會將持續觀察降息後的經濟表現短線再大幅降息空間有限加上中美貿易談判達成初步協議風險規避的需求降低另外可增持風險性信用債加大信用風險但相對較為分散以投資級債取代部分公債部位此外隨著全球央行貨幣政策偏向寬鬆市場尋利需求仍在利率相對高的高收益債與新興市場債在市場情緒轉佳下可望相對受惠至於需要留意的地方建議投資人可留意：貨幣政策可能持平以及美國總統川普推特發言可能對市場埋下不確定的影響'], 'input_ids': tensor([[ 101, 1059, 4413, 2184, 7777, 4638, 6515, 2395, 3124, 5032, 2200, 2898,\n",
            "         5265, 3118, 3052, 2356, 1842, 5401, 1751, 5474, 3976, 3298,  671, 1963,\n",
            "         7521, 3309, 3176, 3189, 1164, 4372, 3124, 5032, 3298, 6359, 2527, 2146,\n",
            "         2357, 5474, 6930, 1825, 7032, 1164, 4372, 5204, 2898,  679, 6365,  792,\n",
            "         3176, 8080, 4638, 1281, 7279, 3418, 3087, 3298, 6359, 5178, 3338, 2527,\n",
            "         4634, 2357, 4638, 5476, 3209, 1058, 2159, 7549, 4850, 1246, 1240, 2356,\n",
            "         1842,  898, 4197, 2485, 1233, 5195, 4089, 3833, 1240,  671, 4684, 5993,\n",
            "         3176, 3984, 1469, 1872, 7269,  852, 1555, 3511, 2832, 6536, 5645, 1139,\n",
            "         1366,  793, 4685, 2205, 4558, 6727, 3634, 1912, 3298, 2527, 5476, 3209,\n",
            "         1165, 7370,  749, 3299, 5476, 3209,  704, 3295, 2990, 1350, 4638, 5195,\n",
            "         4089, 1184, 3250, 4638,  679, 4825, 2137,  898, 4197, 2100, 1762, 7549,\n",
            "         4850, 2205, 5195, 4089, 5645, 2218, 3511,  928, 2552, 4526, 3300, 1872,\n",
            "         2485, 4638, 6303, 6270, 8039, 5445, 5474, 3976, 3298,  712, 2375, 7800,\n",
            "         4273, 2990, 1168, 4680, 1184, 5195, 4089, 1469, 6515, 2395, 3124, 5032,\n",
            "         6963, 5993, 3176, 3300, 1164, 1765,  855, 5023, 4638, 6303, 3791,  771,\n",
            "         4158, 2356, 1842, 2205, 3176, 5195, 4089, 1184, 3250, 2922, 3800, 3291,\n",
            "         1914, 4638,  928, 2552, 1726, 7547,  791, 2399,  809,  889, 1377, 6333,\n",
            "         3221, 5195, 4089, 5645, 3124, 5032, 4638, 6752, 6365, 2399, 1059, 4413,\n",
            "         5195, 4089, 3123, 5227, 4507, 5474, 3976, 3298, 2380, 7531, 1430, 6629,\n",
            "         4638, 7360, 2622, 7591, 1217,  677, 6530, 3211, 2782, 5739, 1751, 4801,\n",
            "         5562, 3627, 5023, 3085, 2726, 1139, 4412, 6752, 1758, 6536, 4496, 3249,\n",
            "         6881,  778, 4706, 6134, 4412, 5445, 1059, 4413, 2356, 1842, 1762, 6536,\n",
            "         7032, 3837, 1240, 2571, 6862,  678,  679, 1398, 2356, 1842, 1469, 6536,\n",
            "         4496, 6743, 1240, 6134, 4412, 1059, 4413, 5195, 4089, 3123, 5227,  712,\n",
            "         6206, 1358, 1168, 3173, 5646, 1751, 2157, 3627, 3828, 5645, 3189, 3315,\n",
            "         5023, 1751, 2157, 2512, 7513, 5401, 1751, 5195, 4089, 7426, 1358, 1168,\n",
            "         2335, 3249, 6512, 3124, 3124, 5032, 1173, 4080, 5645, 3938, 4922, 3124,\n",
            "         5032, 2512, 7513,  852,  771, 6852, 3635, 6624, 1403, 1453, 3309, 2527,\n",
            "         3667, 5445, 4507, 5474, 3976, 3298, 2380, 7531, 4638, 7360, 2622, 3124,\n",
            "         5032, 6752, 2494,  738, 3209, 7549, 1430, 1403, 3173, 5646, 2356, 1842,\n",
            "          791, 2399,  809,  889, 2347, 5195, 3300, 6874,  943, 1751, 2157, 7380,\n",
            "         5265, 7360, 2622, 7549, 4850, 2184, 7777, 3124, 5032, 3126, 2746,  738,\n",
            "         6852, 3635, 1762, 3173, 5646, 2356, 1842,  704, 3097, 3141, 3173, 5646,\n",
            "         2356, 1842, 1925, 6121, 6656, 7401, 2768, 4225, 2356, 1842, 1925, 6121,\n",
            "         4638,  976, 3791,  791, 2399, 2347, 7549, 5865, 2990, 1285, 6515, 2395,\n",
            "         3124, 5032, 4638, 2184, 7777, 4923, 2428, 5445,  684,  844, 6243, 2200,\n",
            "         3300, 3291, 1914, 2184, 7777, 2974, 3177, 6857, 4192, 4542, 4158, 2399,\n",
            "         2419, 4638, 7591, 7402, 5517, 5152, 2990,  897,  749, 2825, 6123, 3118,\n",
            "         3052, 1963, 3362, 5080, 1606, 3645, 5152, 1377,  809, 4634, 4412,  791,\n",
            "         2399, 3118, 3052, 6536, 4496, 3300, 6134, 4412, 4638, 1333, 1728, 5018,\n",
            "          671,  943, 3221, 6268, 1019, 7481,  738, 2218, 3221, 1343, 2399, 6649,\n",
            "         1922, 1914,  791, 2399, 1728, 5445, 1139, 4412, 1353, 2492, 5018,  753,\n",
            "          943,  845, 7401, 5865, 6515, 2395, 3124,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['年初至月全球主要商品價格曾有一波漲幅但下半年處於整理階段富蘭克林華美天然資源組合基金經理人蕭若梅指出原物料和貴金屬市場主要受到供需面和貿易戰等因素影響表現不如股票和債券市場過去一年商品市場以貴金屬漲幅最大其次是石油最弱是基本金屬而表現最讓市場意外的商品是鈀金鈀金漲得比黃金還要誇張年大漲近成原物料投資達人盧冠安指出近多年股市多頭很多人以為漲最多是美股其實汽車觸媒轉換器主要消耗品具有環保功用加持的鈀金年來足足漲了倍盧冠安指出黃金在年表現也相當亮眼漲幅一度超過道瓊工業及標普指數月金價漲破每盎司美元但隨著月貿易戰再起波瀾美國降息效應顯現等利空影響金價漲幅才收縮展望年黃金漲勢可望延續投資大行包括高盛瑞銀都預期金價上看每盎司美元主要是受惠於避險需求全球更寬鬆的貨幣政策以及央行買盤的支撐；花旗集團則認為年迭創新高的鈀金未來一年可望續漲站上美元關卡黃金有大個性一是商品二是貨幣蕭若梅分析從商品面來看黃金的供給非常價格導向礦商依據現金流及金價來評估是否開新礦因此產量往往落後金價這也是為何金價年漲約但黃金相關股票卻漲逾最高曾達到成的原因雖然年金價上揚但礦商曾在年因大肆擴產而重傷後目前財務規劃仍保守至於黃金需求蕭若梅指出除了的投機資金外飾金市場需求仍低迷而年美元表現強勢未來若美元轉弱會是支撐黃金的另一個小利多黃金作為商品之外蕭若梅認為金價目前轉向貨幣取向原因是在負利率環境中市場追求有配息的標的黃金雖然不配息但具有貨幣特性反而成為各國央行規避債台高築的工具之一我們不看空金價主因是聯準會鷹式降息背後仍可能持續注入市場資金全球長期利率處於下降趨勢黃金仍是資產配置中不可或缺的一環至於油價年表現並不差年初個月曾經大漲但隨即在月打回原形近期則出現反彈西德州原油年漲幅逾原因是目前原油市場呈現供不應求蕭若梅解釋雖然全球製造業走下坡但原油增長幅度放緩包括擴大減產以及美國頁岩油單井生產力增速降低所致不過蕭若梅指出市場預期年石油需求增加供給減少使得年原油市場可能由小幅過剩轉為平衡在需求預估上升原油庫存逐漸消化之下油價在年可望震盪回穩基本金屬方面年製造業景氣疲弱包含銅鋁鋅等價格低迷是表現最差的商品類別不過蕭若梅指出銅的供給越來越少加上全球發展電動車（）帶動需求未來年市場偏多看待在投資策略上蕭若梅建議投資人應配置一部分資產在貴金屬和天然資源部位掌握景氣落底後復甦的機會自金融海嘯後全球經濟進入年長週期的第個中週期製造業景氣有機會在年落底回升而與景氣呈現正循環相關的天然資源市場近期落底盤整投資人可趁早布局'], 'input_ids': tensor([[ 101, 2399, 1159, 5635, 3299, 1059, 4413,  712, 6206, 1555, 1501, 1019,\n",
            "         3419, 3295, 3300,  671, 3797, 4039, 2388,  852,  678, 1288, 2399, 5993,\n",
            "         3176, 3146, 4415, 7389, 3667, 2168, 5984, 1046, 3360, 5836, 5401, 1921,\n",
            "         4197, 6536, 3975, 5175, 1394, 1825, 7032, 5195, 4415,  782, 5941, 5735,\n",
            "         3449, 2900, 1139, 1333, 4289, 3160, 1469, 6523, 7032, 2253, 2356, 1842,\n",
            "          712, 6206, 1358, 1168,  897, 7444, 7481, 1469, 6530, 3211, 2782, 5023,\n",
            "         1728, 5162, 2512, 7513, 6134, 4412,  679, 1963, 5500, 4873, 1469, 1002,\n",
            "         1171, 2356, 1842, 6882, 1343,  671, 2399, 1555, 1501, 2356, 1842,  809,\n",
            "         6523, 7032, 2253, 4039, 2388, 3297, 1920, 1071, 3613, 3221, 4767, 3779,\n",
            "         3297, 2483, 3221, 1825, 3315, 7032, 2253, 5445, 6134, 4412, 3297, 6366,\n",
            "         2356, 1842, 2692, 1912, 4638, 1555, 1501, 3221, 7041, 7032, 7041, 7032,\n",
            "         4039, 2533, 3683, 7941, 7032, 6917, 6206, 6288, 2484, 2399, 1920, 4039,\n",
            "         6818, 2768, 1333, 4289, 3160, 2832, 6536, 6888,  782, 4678, 1094, 2128,\n",
            "         2900, 1139, 6818, 1914, 2399, 5500, 2356, 1914, 7531, 2523, 1914,  782,\n",
            "          809, 4158, 4039, 3297, 1914, 3221, 5401, 5500, 1071, 2179, 3749, 6722,\n",
            "         6240, 2054, 6752, 2994, 1690,  712, 6206, 3867, 5450, 1501, 1072, 3300,\n",
            "         4472,  924, 1216, 4500, 1217, 2898, 4638, 7041, 7032, 2399,  889, 6639,\n",
            "         6639, 4039,  749,  945, 4678, 1094, 2128, 2900, 1139, 7941, 7032, 1762,\n",
            "         2399, 6134, 4412,  738, 4685, 4534,  778, 4706, 4039, 2388,  671, 2428,\n",
            "         6631, 6882, 6887, 4475, 2339, 3511, 1350, 3560, 3249, 2900, 3149, 3299,\n",
            "         7032, 1019, 4039, 4788, 3680, 4661, 1385, 5401, 1039,  852, 7401, 5865,\n",
            "         3299, 6530, 3211, 2782, 1086, 6629, 3797, 4117, 5401, 1751, 7360, 2622,\n",
            "         3126, 2746, 7549, 4412, 5023, 1164, 4958, 2512, 7513, 7032, 1019, 4039,\n",
            "         2388, 2798, 3119, 5240, 2245, 3307, 2399, 7941, 7032, 4039, 1248, 1377,\n",
            "         3307, 2454, 5265, 2832, 6536, 1920, 6121, 1259, 2886, 7770, 4670, 4448,\n",
            "         7065, 6963, 7521, 3309, 7032, 1019,  677, 4692, 3680, 4661, 1385, 5401,\n",
            "         1039,  712, 6206, 3221, 1358, 2669, 3176, 6912, 7402, 7444, 3724, 1059,\n",
            "         4413, 3291, 2184, 7777, 4638, 6515, 2395, 3124, 5032,  809, 1350, 1925,\n",
            "         6121, 6525, 4676, 4638, 3118, 3052, 8039, 5709, 3186, 7415, 1757, 1179,\n",
            "         6291, 4158, 2399, 6834, 1201, 3173, 7770, 4638, 7041, 7032, 3313,  889,\n",
            "          671, 2399, 1377, 3307, 5265, 4039, 4991,  677, 5401, 1039, 7302, 1305,\n",
            "         7941, 7032, 3300, 1920,  943, 2595,  671, 3221, 1555, 1501,  753, 3221,\n",
            "         6515, 2395, 5941, 5735, 3449, 1146, 3358, 2537, 1555, 1501, 7481,  889,\n",
            "         4692, 7941, 7032, 4638,  897, 5183, 7478, 2382, 1019, 3419, 2206, 1403,\n",
            "         4846, 1555,  898, 3087, 4412, 7032, 3837, 1350, 7032, 1019,  889, 6268,\n",
            "          844, 3221, 1415, 7274, 3173, 4846, 1728, 3634, 4496, 7030, 2518, 2518,\n",
            "         5862, 2527, 7032, 1019, 6857,  738, 3221, 4158,  862, 7032, 1019, 2399,\n",
            "         4039, 5147,  852, 7941, 7032, 4685, 7302, 5500, 4873, 1320, 4039, 6874,\n",
            "         3297, 7770, 3295, 6888, 1168, 2768, 4638, 1333, 1728, 7426, 4197, 2399,\n",
            "         7032, 1019,  677, 2993,  852, 4846, 1555, 3295, 1762, 2399, 1728, 1920,\n",
            "         5487, 3097, 4496, 5445, 7028, 1003, 2527, 4680, 1184, 6512, 1243, 6211,\n",
            "         1205,  793,  924, 2127, 5635, 3176, 7941, 7032, 7444, 3724, 5941, 5735,\n",
            "         3449, 2900, 1139, 7370,  749, 4638, 2832,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['因英國倫敦房產投資糾紛亞太國際地產董事長秦啟松資產被投資民眾聲請凍結（記者徐義平攝）記者徐義平台北報導多位財經名人曾推薦海外地產首選的亞太國際地產近年來危機連環爆去年底遭檢調搜索今年月日更驚爆停業；而去年同樣遭檢調搜索的台灣搜房網也傳出已停業房地產業者擔心最壞的情況就是過去透過家業者投資海外房地產的民眾可能淪為海外孤兒請繼續往下閱讀根據經濟部商業司登記資料亞太國際地產於年月底成立正好是海外置產熱潮的時間點至今已超過年最熱時期年可銷售超過百億元的海外房產不過去年月底與另一家經營海外的業者台灣搜房網同樣因以保證獲利等話術推銷英國倫敦房地產吸引投資金額超過億元同時遭到檢調搜索事隔不到年亞太國際地產月日驚爆停業預計停業年亞太國際地產聲明停業原因是部分投資英國房產的客戶因未能收取建商提供的保證租金在今年月針對亞太國際地產董事長秦啟松以及總經理等銀行帳戶與資產向法院聲請查扣與假扣押目前所有資金與資產均遭到凍結因資產凍結已超過個月面臨求助無門的窘境才會決議月日申請停業並確定月日停業除了亞太國際地產另一家遭到檢調搜索的台灣搜房網也在月日確定停業停業時間同樣是年房地產業者指出這波海外置產熱潮起於年中奢侈稅上路後推估年來逾億元資金錢進海外一路從日本馬來西亞買到澳洲倫敦美國等；光是台北市登記專營海外房產投資的經紀業家數截至年底就近家不過好景不常隨著各國房地產被熱錢炒高各國政府陸續祭出防堵政策加上出租率不高甚至面臨脫手獲利不易等問題近幾年海外房產投資逐漸式微    一手掌握經濟脈動    點我訂閱自由財經頻道'], 'input_ids': tensor([[ 101, 1728, 5739, 1751,  961, 3142, 2791, 4496, 2832, 6536, 5144, 5160,\n",
            "          765, 1922, 1751, 7396, 1765, 4496, 5869,  752, 7269, 4912, 1564, 3351,\n",
            "         6536, 4496, 6158, 2832, 6536, 3696, 4707, 5476, 6313, 1120, 5178, 8020,\n",
            "         6250, 5442, 2528, 5412, 2398, 3109, 8021, 6250, 5442, 2528, 5412, 2398,\n",
            "         1378, 1266, 1841, 2206, 1914,  855, 6512, 5195, 1399,  782, 3295, 2972,\n",
            "         5956, 3862, 1912, 1765, 4496, 7674, 6908, 4638,  765, 1922, 1751, 7396,\n",
            "         1765, 4496, 6818, 2399,  889, 1314, 3582, 6865, 4472, 4255, 1343, 2399,\n",
            "         2419, 6901, 3596, 6310, 3017, 5164,  791, 2399, 3299, 3189, 3291, 7711,\n",
            "         4255,  977, 3511, 8039, 5445, 1343, 2399, 1398, 3564, 6901, 3596, 6310,\n",
            "         3017, 5164, 4638, 1378, 4124, 3017, 2791, 5206,  738, 1001, 1139, 2347,\n",
            "          977, 3511, 2791, 1765, 4496, 3511, 5442, 3085, 2552, 3297, 1889, 4638,\n",
            "         2658, 3785, 2218, 3221, 6882, 1343, 6851, 6882, 2157, 3511, 5442, 2832,\n",
            "         6536, 3862, 1912, 2791, 1765, 4496, 4638, 3696, 4707, 1377, 5543, 3914,\n",
            "         4158, 3862, 1912, 2109, 1051, 6313, 5262, 5265, 2518,  678, 7288, 6364,\n",
            "         3418, 3087, 5195, 4089, 6956, 1555, 3511, 1385, 4633, 6250, 6536, 3160,\n",
            "          765, 1922, 1751, 7396, 1765, 4496, 3176, 2399, 3299, 2419, 2768, 4989,\n",
            "         3633, 1962, 3221, 3862, 1912, 5390, 4496, 4229, 4060, 4638, 3229, 7279,\n",
            "         7953, 5635,  791, 2347, 6631, 6882, 2399, 3297, 4229, 3229, 3309, 2399,\n",
            "         1377, 7077, 1545, 6631, 6882, 4636, 1023, 1039, 4638, 3862, 1912, 2791,\n",
            "         4496,  679, 6882, 1343, 2399, 3299, 2419, 5645, 1369,  671, 2157, 5195,\n",
            "         4245, 3862, 1912, 4638, 3511, 5442, 1378, 4124, 3017, 2791, 5206, 1398,\n",
            "         3564, 1728,  809,  924, 6349, 4363, 1164, 5023, 6282, 6123, 2972, 7077,\n",
            "         5739, 1751,  961, 3142, 2791, 1765, 4496, 1429, 2471, 2832, 6536, 7032,\n",
            "         7540, 6631, 6882, 1023, 1039, 1398, 3229, 6901, 1168, 3596, 6310, 3017,\n",
            "         5164,  752, 7392,  679, 1168, 2399,  765, 1922, 1751, 7396, 1765, 4496,\n",
            "         3299, 3189, 7711, 4255,  977, 3511, 7521, 6243,  977, 3511, 2399,  765,\n",
            "         1922, 1751, 7396, 1765, 4496, 5476, 3209,  977, 3511, 1333, 1728, 3221,\n",
            "         6956, 1146, 2832, 6536, 5739, 1751, 2791, 4496, 4638, 2145, 2786, 1728,\n",
            "         3313, 5543, 3119, 1357, 2456, 1555, 2990,  897, 4638,  924, 6349, 4909,\n",
            "         7032, 1762,  791, 2399, 3299, 7036, 2205,  765, 1922, 1751, 7396, 1765,\n",
            "         4496, 5869,  752, 7269, 4912, 1564, 3351,  809, 1350, 5244, 5195, 4415,\n",
            "         5023, 7065, 6121, 2379, 2786, 5645, 6536, 4496, 1403, 3791, 7368, 5476,\n",
            "         6313, 3389, 2807, 5645,  969, 2807, 2852, 4680, 1184, 2792, 3300, 6536,\n",
            "         7032, 5645, 6536, 4496, 1772, 6901, 1168, 1120, 5178, 1728, 6536, 4496,\n",
            "         1120, 5178, 2347, 6631, 6882,  943, 3299, 7481, 5631, 3724, 1221, 4192,\n",
            "         7271, 4638, 4971, 1862, 2798, 3298, 3748, 6359, 3299, 3189, 4509, 6313,\n",
            "          977, 3511,  699, 4825, 2137, 3299, 3189,  977, 3511, 7370,  749,  765,\n",
            "         1922, 1751, 7396, 1765, 4496, 1369,  671, 2157, 6901, 1168, 3596, 6310,\n",
            "         3017, 5164, 4638, 1378, 4124, 3017, 2791, 5206,  738, 1762, 3299, 3189,\n",
            "         4825, 2137,  977, 3511,  977, 3511, 3229, 7279, 1398, 3564, 3221, 2399,\n",
            "         2791, 1765, 4496, 3511, 5442, 2900, 1139, 6857, 3797, 3862, 1912, 5390,\n",
            "         4496, 4229, 4060, 6629, 3176, 2399,  704, 1951,  890, 4922,  677, 6662,\n",
            "         2527, 2972,  844, 2399,  889, 6874, 1023,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([1])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n",
            "{'review_text': ['記者鄭淑婷桃園報導歲張姓男子因酒駕被吊銷駕照昨凌晨又涉嫌酒後開車在國道自撞護欄車子立在草叢間他自行爬出脫困被送到醫院急救時已告昏迷經抽血檢測發現酒精值超標幾達爛醉程度國道警方將待張男傷勢好轉後依公共危險罪嫌送辦警方調查昨凌晨點多張男駕駛白色轎車準備從國道一號北上公里處的機場系統匝道銜接國道二號時突然自撞匝道護欄整輛車失控撞斷多個防撞桶導桿最後撞上國道二號下方涵洞牆壁車子就立在匝道旁草叢與水泥柱旁；張男自行爬出車外脫困眉毛處有明顯傷痕桃園市消防局內壢消防分隊趕抵時發現張男已昏迷倒臥匝道口外側救護人員立即將他送往衛福部桃園醫院經急救後仍在加護病房觀察暫無生命危險請繼續往下閱讀張男經抽血檢驗發現酒精濃度超標幾達爛醉程度國道警方將待他傷勢好轉並完成筆錄後依公共危險罪嫌送辦據了解張男曾有酒駕紀錄且駕照被吊銷卻又因酒駕肇禍確切肇事原因待警方釐清'], 'input_ids': tensor([[ 101, 6250, 5442, 6972, 3902, 2051, 3425, 1754, 1841, 2206, 3641, 2484,\n",
            "         1998, 4511, 2094, 1728, 6983, 7690, 6158, 1396, 7077, 7690, 4212, 3219,\n",
            "         1119, 3247, 1348, 3868, 2066, 6983, 2527, 7274, 6722, 1762, 1751, 6887,\n",
            "         5632, 3058, 6362, 3608, 6722, 2094, 4989, 1762, 5770, 1365, 7279,  800,\n",
            "         5632, 6121, 4260, 1139, 5562, 1737, 6158, 6843, 1168, 7015, 7368, 2593,\n",
            "         3131, 3229, 2347, 1440, 3210, 6837, 5195, 2853, 6117, 3596, 3947, 4634,\n",
            "         4412, 6983, 5125,  966, 6631, 3560, 2407, 6888, 4258, 7004, 4923, 2428,\n",
            "         1751, 6887, 6356, 3175, 2200, 2521, 2484, 4511, 1003, 1248, 1962, 6752,\n",
            "         2527,  898, 1062, 1066, 1314, 7402, 5389, 2066, 6843, 6794, 6356, 3175,\n",
            "         6310, 3389, 3219, 1119, 3247, 7953, 1914, 2484, 4511, 7690, 7691, 4635,\n",
            "         5682, 6754, 6722, 3976,  991, 2537, 1751, 6887,  671, 5998, 1266,  677,\n",
            "         1062, 7027, 5993, 4638, 3582, 1842, 5143, 5186, 1268, 6887, 7072, 2970,\n",
            "         1751, 6887,  753, 5998, 3229, 4960, 4197, 5632, 3058, 1268, 6887, 6362,\n",
            "         3608, 3146, 6739, 6722, 1927, 2971, 3058, 3174, 1914,  943, 7344, 3058,\n",
            "         3446, 2206, 3447, 3297, 2527, 3058,  677, 1751, 6887,  753, 5998,  678,\n",
            "         3175, 3891, 3822, 4274, 1880, 6722, 2094, 2218, 4989, 1762, 1268, 6887,\n",
            "         3178, 5770, 1365, 5645, 3717, 3799, 3393, 3178, 8039, 2484, 4511, 5632,\n",
            "         6121, 4260, 1139, 6722, 1912, 5562, 1737, 4691, 3688, 5993, 3300, 3209,\n",
            "         7549, 1003, 4575, 3425, 1754, 2356, 3867, 7344, 2229, 1058, 1891, 3867,\n",
            "         7344, 1146, 7386, 6634, 2850, 3229, 4634, 4412, 2484, 4511, 2347, 3210,\n",
            "         6837,  948, 5629, 1268, 6887, 1366, 1912,  979, 3131, 6362,  782, 1519,\n",
            "         4989, 1315, 2200,  800, 6843, 2518, 6127, 4886, 6956, 3425, 1754, 7015,\n",
            "         7368, 5195, 2593, 3131, 2527,  793, 1762, 1217, 6362, 4567, 2791, 6223,\n",
            "         2175, 3271, 4192, 4495, 1462, 1314, 7402, 6313, 5262, 5265, 2518,  678,\n",
            "         7288, 6364, 2484, 4511, 5195, 2853, 6117, 3596, 7710, 4634, 4412, 6983,\n",
            "         5125, 4083, 2428, 6631, 3560, 2407, 6888, 4258, 7004, 4923, 2428, 1751,\n",
            "         6887, 6356, 3175, 2200, 2521,  800, 1003, 1248, 1962, 6752,  699, 2130,\n",
            "         2768, 5022, 7087, 2527,  898, 1062, 1066, 1314, 7402, 5389, 2066, 6843,\n",
            "         6794, 3087,  749, 6237, 2484, 4511, 3295, 3300, 6983, 7690, 5145, 7087,\n",
            "          684, 7690, 4212, 6158, 1396, 7077, 1320, 1348, 1728, 6983, 7690, 5488,\n",
            "         4884, 4825, 1147, 5488,  752, 1333, 1728, 2521, 6356, 3175, 7031, 3926,\n",
            "          102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['近來台南地區流傳一張標榜臨時工廠代辦登記無完成全部退費服務處配合地政士代書特由服務處與律師事務所簽約見證的傳單讓數以萬計想就地合法的工廠老闆看了大為心動傳單上更印著台南市議長郭信良辦公室主任黃龍生的名片讓觀者莫不恍然大悟直呼議長夠力為瞭解議長郭信良服務處是否真成為承攬非法工廠納管生意的登記處月日下午記者佯裝佔用農地的違法工廠老闆前往服務處一探究竟一進入服務處記者拿著傳單表明要詢問農地工廠合法化的問題並說是朋友介紹來找服務處主任黃龍生服務處人員毫不避諱地回說：黃主任在忙等一下就來跟您說明沒多久黃龍生拿著傳單與相關法令資料現身詢問記者工廠的實際情形並老練的提出建議表示最好連住家也當管理室變更成為工業用地反正只需繳納公告地價的當回饋金即可相當划算談到敏感的代辦費黃龍生說一般代書辦這種案件收萬元但只是照程序送件；他們服務處與某代書簽約這位代書辦過許多成功案例所以收費萬元黃還將其他議員也拉下水說：別的議員那邊收費到萬議長這邊算是最便宜的了接著黃更拍胸脯保證只要跟服務處簽約合作辦不成就退費而且簽約時有律師見證若代書收了錢辦不成又不退費律師可代為提告最後他請記者留下電話過不到個小時傳單中的郭姓女律師便主動打電話詢問記者何時可以到工廠現勘看得出這夥人相當積極的在招攬業務本刊調查這名自稱律師的郭女曾在年遭人檢舉違反律師法指她根本不是律師如今卻與議長服務處主任包攬行政單位審查案件讓人有不知今夕是何夕之嘆'], 'input_ids': tensor([[ 101, 6818,  889, 1378, 1298, 1765, 1281, 3837, 1001,  671, 2484, 3560,\n",
            "         3528, 5631, 3229, 2339, 2449,  807, 6794, 4633, 6250, 4192, 2130, 2768,\n",
            "         1059, 6956, 6842, 6527, 3302, 1243, 5993, 6981, 1394, 1765, 3124, 1894,\n",
            "          807, 3292, 4294, 4507, 3302, 1243, 5993, 5645, 2526, 2374,  752, 1243,\n",
            "         2792, 5087, 5147, 6210, 6349, 4638, 1001, 1606, 6366, 3149,  809, 5857,\n",
            "         6243, 2682, 2218, 1765, 1394, 3791, 4638, 2339, 2449, 5439, 7293, 4692,\n",
            "          749, 1920, 4158, 2552, 1240, 1001, 1606,  677, 3291, 1313, 5865, 1378,\n",
            "         1298, 2356, 6359, 7269, 6958,  928, 5679, 6794, 1062, 2147,  712,  818,\n",
            "         7941, 7983, 4495, 4638, 1399, 4275, 6366, 6223, 5442, 5811,  679, 2606,\n",
            "         4197, 1920, 2640, 4684, 1461, 6359, 7269, 1917, 1213, 4158, 4747, 6237,\n",
            "         6359, 7269, 6958,  928, 5679, 3302, 1243, 5993, 3221, 1415, 4696, 2768,\n",
            "         4158, 2824, 3117, 7478, 3791, 2339, 2449, 5152, 5052, 4495, 2692, 4638,\n",
            "         4633, 6250, 5993, 3299, 3189,  678, 1286, 6250, 5442,  879, 6172,  861,\n",
            "         4500, 6803, 1765, 4638, 6889, 3791, 2339, 2449, 5439, 7293, 1184, 2518,\n",
            "         3302, 1243, 5993,  671, 2968, 4955, 4994,  671, 6868, 1057, 3302, 1243,\n",
            "         5993, 6250, 5442, 2897, 5865, 1001, 1606, 6134, 3209, 6206, 6273, 1558,\n",
            "         6803, 1765, 2339, 2449, 1394, 3791, 1265, 4638, 1558, 7539,  699, 6303,\n",
            "         3221, 3301, 1351,  792, 5171,  889, 2823, 3302, 1243, 5993,  712,  818,\n",
            "         7941, 7983, 4495, 3302, 1243, 5993,  782, 1519, 3690,  679, 6912, 6325,\n",
            "         1765, 1726, 6303, 8038, 7941,  712,  818, 1762, 2564, 5023,  671,  678,\n",
            "         2218,  889, 6656, 2644, 6303, 3209, 3760, 1914,  719, 7941, 7983, 4495,\n",
            "         2897, 5865, 1001, 1606, 5645, 4685, 7302, 3791,  808, 6536, 3160, 4412,\n",
            "         6716, 6273, 1558, 6250, 5442, 2339, 2449, 4638, 2179, 7396, 2658, 2501,\n",
            "          699, 5439, 5230, 4638, 2990, 1139, 2456, 6359, 6134, 4850, 3297, 1962,\n",
            "         6865,  857, 2157,  738, 4534, 5052, 4415, 2147, 6365, 3291, 2768, 4158,\n",
            "         2339, 3511, 4500, 1765, 1353, 3633, 1372, 7444, 5260, 5152, 1062, 1440,\n",
            "         1765, 1019, 4638, 4534, 1726, 7637, 7032, 1315, 1377, 4685, 4534, 1153,\n",
            "         5050, 6312, 1168, 3130, 2697, 4638,  807, 6794, 6527, 7941, 7983, 4495,\n",
            "         6303,  671, 5663,  807, 3292, 6794, 6857, 4934, 3428,  816, 3119, 5857,\n",
            "         1039,  852, 1372, 3221, 4212, 4923, 2415, 6843,  816, 8039,  800,  947,\n",
            "         3302, 1243, 5993, 5645, 3378,  807, 3292, 5087, 5147, 6857,  855,  807,\n",
            "         3292, 6794, 6882, 6258, 1914, 2768, 1216, 3428,  891, 2792,  809, 3119,\n",
            "         6527, 5857, 1039, 7941, 6917, 2200, 1071,  800, 6359, 1519,  738, 2861,\n",
            "          678, 3717, 6303, 8038, 1162, 4638, 6359, 1519, 6929, 6920, 3119, 6527,\n",
            "         1168, 5857, 6359, 7269, 6857, 6920, 5050, 3221, 3297,  912, 2139, 4638,\n",
            "          749, 2970, 5865, 7941, 3291, 2864, 5541, 5563,  924, 6349, 1372, 6206,\n",
            "         6656, 3302, 1243, 5993, 5087, 5147, 1394,  868, 6794,  679, 2768, 2218,\n",
            "         6842, 6527, 5445,  684, 5087, 5147, 3229, 3300, 2526, 2374, 6210, 6349,\n",
            "         5735,  807, 3292, 3119,  749, 7092, 6794,  679, 2768, 1348,  679, 6842,\n",
            "         6527, 2526, 2374, 1377,  807, 4158, 2990, 1440, 3297, 2527,  800, 6313,\n",
            "         6250, 5442, 4522,  678, 7442, 6282, 6882,  679, 1168,  943, 2207, 3229,\n",
            "         1001, 1606,  704, 4638, 6958, 1998, 1957, 2526, 2374,  912,  712, 1240,\n",
            "         2802, 7442, 6282, 6273, 1558, 6250, 5442,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['據外媒報導谷歌  與美國第二大醫療系統  合作的南丁格爾計畫 涉及秘密收集境內數百萬美國病患的詳細個人健康資訊美國聯邦政府機構已經對此進行調查報導中指出谷歌的這項計畫從去年開始進行並且涉及與在  個州和華盛頓特區擁有超過  個設施例如醫院和療養院的大醫療保健系統 兩者合作包含數據共享像是病患檢查結果診斷資料住院記錄乃至病患個資等隱私內容美國衛生與公共服務部人權辦公室主任   表示已開始針對南丁格爾計畫展開調查將會收集更多相關資訊以確保健康保險便利和責任法  保護能被充分的實施南丁格爾計畫旨在透過人工智慧技術  來改善對患者的治療效果但有專家警告該計畫可能侵害病患隱私 也說道新的技術也許能改善醫療效果但絕不能為此而犧牲患者隱私數據和安全對此谷歌發言人在一份聲明中表示：我們很樂意與有關該項目的任何問題進行合作我們與  的合作會遵守有關患者數據的法規 包括 並且會在數據隱私安全性和使用方面實行嚴格的規範除了谷歌之外其他科技巨頭像是微軟蘋果等也期望在醫療領域中擴展並尋求更多商業機會舉例來說蘋果通過自家的   產品來與醫療體系合作期望藉由智慧設備的數據量測使醫生更容易判斷病患的情況'], 'input_ids': tensor([[ 101, 3087, 1912, 2054, 1841, 2206, 6484, 3625, 5645, 5401, 1751, 5018,\n",
            "          753, 1920, 7015, 4615, 5143, 5186, 1394,  868, 4638, 1298,  672, 3419,\n",
            "         4273, 6243, 4529, 3868, 1350, 4908, 2166, 3119, 7415, 1862, 1058, 3149,\n",
            "         4636, 5857, 5401, 1751, 4567, 2642, 4638, 6284, 5169,  943,  782,  978,\n",
            "         2434, 6536, 6244, 5401, 1751, 5474, 6930, 3124, 2424, 3582, 3539, 2347,\n",
            "         5195, 2205, 3634, 6868, 6121, 6310, 3389, 1841, 2206,  704, 2900, 1139,\n",
            "         6484, 3625, 4638, 6857, 7517, 6243, 4529, 2537, 1343, 2399, 7274, 1993,\n",
            "         6868, 6121,  699,  684, 3868, 1350, 5645, 1762,  943, 2336, 1469, 5836,\n",
            "         4670, 7524, 4294, 1281, 3075, 3300, 6631, 6882,  943, 6257, 3177,  891,\n",
            "         1963, 7015, 7368, 1469, 4615, 7621, 7368, 4638, 1920, 7015, 4615,  924,\n",
            "          978, 5143, 5186, 1060, 5442, 1394,  868, 1259, 1419, 3149, 3087, 1066,\n",
            "          775, 1008, 3221, 4567, 2642, 3596, 3389, 5178, 3362, 6262, 3174, 6536,\n",
            "         3160,  857, 7368, 6250, 7087,  718, 5635, 4567, 2642,  943, 6536, 5023,\n",
            "         7403, 4900, 1058, 2159, 5401, 1751, 6127, 4495, 5645, 1062, 1066, 3302,\n",
            "         1243, 6956,  782, 3609, 6794, 1062, 2147,  712,  818, 6134, 4850, 2347,\n",
            "         7274, 1993, 7036, 2205, 1298,  672, 3419, 4273, 6243, 4529, 2245, 7274,\n",
            "         6310, 3389, 2200, 3298, 3119, 7415, 3291, 1914, 4685, 7302, 6536, 6244,\n",
            "          809, 4825,  924,  978, 2434,  924, 7402,  912, 1164, 1469, 6519,  818,\n",
            "         3791,  924, 6362, 5543, 6158, 1041, 1146, 4638, 2179, 3177, 1298,  672,\n",
            "         3419, 4273, 6243, 4529, 3192, 1762, 6851, 6882,  782, 2339, 3255, 2716,\n",
            "         2825, 6123,  889, 3121, 1587, 2205, 2642, 5442, 4638, 3780, 4615, 3126,\n",
            "         3362,  852, 3300, 2201, 2157, 6356, 1440, 6283, 6243, 4529, 1377, 5543,\n",
            "          909, 2154, 4567, 2642, 7403, 4900,  738, 6303, 6887, 3173, 4638, 2825,\n",
            "         6123,  738, 6258, 5543, 3121, 1587, 7015, 4615, 3126, 3362,  852, 5179,\n",
            "          679, 5543, 4158, 3634, 5445, 4304, 4291, 2642, 5442, 7403, 4900, 3149,\n",
            "         3087, 1469, 2128, 1059, 2205, 3634, 6484, 3625, 4634, 6241,  782, 1762,\n",
            "          671,  819, 5476, 3209,  704, 6134, 4850, 8038, 2769,  947, 2523, 3556,\n",
            "         2692, 5645, 3300, 7302, 6283, 7517, 4680, 4638,  818,  862, 1558, 7539,\n",
            "         6868, 6121, 1394,  868, 2769,  947, 5645, 4638, 1394,  868, 3298, 6905,\n",
            "         2127, 3300, 7302, 2642, 5442, 3149, 3087, 4638, 3791, 6211, 1259, 2886,\n",
            "          699,  684, 3298, 1762, 3149, 3087, 7403, 4900, 2128, 1059, 2595, 1469,\n",
            "          886, 4500, 3175, 7481, 2179, 6121, 1713, 3419, 4638, 6211, 5061, 7370,\n",
            "          749, 6484, 3625,  722, 1912, 1071,  800, 4906, 2825, 2342, 7531, 1008,\n",
            "         3221, 2544, 6727, 5981, 3362, 5023,  738, 3309, 3307, 1762, 7015, 4615,\n",
            "         7526, 1818,  704, 3097, 2245,  699, 2204, 3724, 3291, 1914, 1555, 3511,\n",
            "         3582, 3298, 5647,  891,  889, 6303, 5981, 3362, 6858, 6882, 5632, 2157,\n",
            "         4638, 4496, 1501,  889, 5645, 7015, 4615, 7768, 5143, 1394,  868, 3309,\n",
            "         3307, 5964, 4507, 3255, 2716, 6257,  991, 4638, 3149, 3087, 7030, 3947,\n",
            "          886, 7015, 4495, 3291, 2159, 3211, 1161, 3174, 4567, 2642, 4638, 2658,\n",
            "         3785,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['記者楊佩琪台北報導知名瑞傑國際地產公司標榜投資泰國房產保證獲利被檢舉涉嫌吸金高達餘億元受害人數超過人台北地檢署指揮台北市調處日兵分路搜索並傳喚前後任負責人王際平林西田以及前台東市長陳建閣一共名被告及名證人全案朝違反銀行法偵辦北檢搜索瑞傑國際地產追查投資泰國房產涉吸金億案前台東市長陳建閣也遭傳喚列為被告（圖翻攝自陳建閣臉書粉絲專頁）打開該公司的粉絲專頁不難發現其專營泰國房產建案強調在泰國政府鼓勵下經濟發展前景可期房地產投資更是先搶先贏房產部分瑞傑以標榜有完整的代租代管物業管理系統以及完整的標的物回購機制公司買土地蓋房子幫管理吸引投資人買房棟房產底價至萬保證投資前年獲利一名瑞傑國際的業務員就在自己的臉書上宣傳投資泰國東部經濟走廊可擁有高頭抱租金收益只要萬就可入主泰國房市不過檢調接獲檢舉瑞傑國際自年起透過臉書粉絲專頁說明會等方式招攬投資卻出現有投資人拿不到投資款血本無歸受害者目前初估多人數恐還會增加'], 'input_ids': tensor([[ 101, 6250, 5442, 3501,  877, 4427, 1378, 1266, 1841, 2206, 4761, 1399,\n",
            "         4448,  989, 1751, 7396, 1765, 4496, 1062, 1385, 3560, 3528, 2832, 6536,\n",
            "         3805, 1751, 2791, 4496,  924, 6349, 4363, 1164, 6158, 3596, 5647, 3868,\n",
            "         2066, 1429, 7032, 7770, 6888, 7626, 1023, 1039, 1358, 2154,  782, 3149,\n",
            "         6631, 6882,  782, 1378, 1266, 1765, 3596, 5392, 2900, 3000, 1378, 1266,\n",
            "         2356, 6310, 5993, 3189, 1070, 1146, 6662, 3017, 5164,  699, 1001, 1598,\n",
            "         1184, 2527,  818, 6511, 6519,  782, 4374, 7396, 2398, 3360, 6205, 4506,\n",
            "          809, 1350, 1184, 1378, 3346, 2356, 7269, 7376, 2456, 7284,  671, 1066,\n",
            "         1399, 6158, 1440, 1350, 1399, 6349,  782, 1059, 3428, 3308, 6889, 1353,\n",
            "         7065, 6121, 3791,  980, 6794, 1266, 3596, 3017, 5164, 4448,  989, 1751,\n",
            "         7396, 1765, 4496, 6841, 3389, 2832, 6536, 3805, 1751, 2791, 4496, 3868,\n",
            "         1429, 7032, 1023, 3428, 1184, 1378, 3346, 2356, 7269, 7376, 2456, 7284,\n",
            "          738, 6901, 1001, 1598, 1154, 4158, 6158, 1440, 8020, 1756, 5436, 3109,\n",
            "         5632, 7376, 2456, 7284, 5622, 3292, 5106, 5187, 2201, 7514, 8021, 2802,\n",
            "         7274, 6283, 1062, 1385, 4638, 5106, 5187, 2201, 7514,  679, 7432, 4634,\n",
            "         4412, 1071, 2201, 4245, 3805, 1751, 2791, 4496, 2456, 3428, 2485, 6310,\n",
            "         1762, 3805, 1751, 3124, 2424, 7961, 1252,  678, 5195, 4089, 4634, 2245,\n",
            "         1184, 3250, 1377, 3309, 2791, 1765, 4496, 2832, 6536, 3291, 3221, 1044,\n",
            "         3024, 1044, 6560, 2791, 4496, 6956, 1146, 4448,  989,  809, 3560, 3528,\n",
            "         3300, 2130, 3146, 4638,  807, 4909,  807, 5052, 4289, 3511, 5052, 4415,\n",
            "         5143, 5186,  809, 1350, 2130, 3146, 4638, 3560, 4638, 4289, 1726, 6554,\n",
            "         3582, 1169, 1062, 1385, 6525, 1759, 1765, 5901, 2791, 2094, 2396, 5052,\n",
            "         4415, 1429, 2471, 2832, 6536,  782, 6525, 2791, 3477, 2791, 4496, 2419,\n",
            "         1019, 5635, 5857,  924, 6349, 2832, 6536, 1184, 2399, 4363, 1164,  671,\n",
            "         1399, 4448,  989, 1751, 7396, 4638, 3511, 1243, 1519, 2218, 1762, 5632,\n",
            "         2346, 4638, 5622, 3292,  677, 2146, 1001, 2832, 6536, 3805, 1751, 3346,\n",
            "         6956, 5195, 4089, 6624, 2443, 1377, 3075, 3300, 7770, 7531, 2849, 4909,\n",
            "         7032, 3119, 4660, 1372, 6206, 5857, 2218, 1377, 1057,  712, 3805, 1751,\n",
            "         2791, 2356,  679, 6882, 3596, 6310, 2970, 4363, 3596, 5647, 4448,  989,\n",
            "         1751, 7396, 5632, 2399, 6629, 6851, 6882, 5622, 3292, 5106, 5187, 2201,\n",
            "         7514, 6303, 3209, 3298, 5023, 3175, 2466, 2875, 3117, 2832, 6536, 1320,\n",
            "         1139, 4412, 3300, 2832, 6536,  782, 2897,  679, 1168, 2832, 6536, 3621,\n",
            "         6117, 3315, 4192, 3645, 1358, 2154, 5442, 4680, 1184, 1159,  844, 1914,\n",
            "          782, 3149, 2607, 6917, 3298, 1872, 1217,  102,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([1])}\n",
            "tensor([1], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n",
            "{'review_text': ['族群最新出現主流轉彎跡象：外資基於股價漲多再上空間有限前提一口氣降評兩大高價股健鼎（）與臻鼎（）相較多家研究機構相繼調升華通（）與欣興（）財務預期族群內出現續買低價股出脫高價股操作策略健鼎臻鼎股價近期雙雙攀上高峰瑞銀與匯豐證券此時出手分別降評兩檔高價指標股至中立與賣出均認為毛利擴張等利多已反映在股價上建議旗下客戶獲利了結相較之下族群中低價位的欣興華通股價表現同樣亮麗然內外資研究機構反而看到更多來自獲利提升的契機像野村證券最近才調升欣興財務預期統一投顧里昂等五大研究機構則對華通唱高調法人看中低價位雙雄的最高目標價都來到元潛在上檔空間均在二成左右健鼎最新除遭瑞銀證券降評匯豐證券科技產業分析師洪希民日前已出手調降推測未來個月合理股價是元為外資主要研究機構中最低瑞銀證券指出健鼎在分散產品組合上取得不錯成果毛利率順利擴張但股價今年來經過漲升大行情後諸多利多已反映在股價飆漲之上目前股價位階來到年推估獲利的倍本益比處在過去三年～倍區間上緣；進一步考量相關產品營收可能下滑目前評價已經合理再漲空間有限因而降評不建議客戶再追價洪希民認為健鼎年毛利率可望因成本結構改善而上升但因健鼎產能有限擴產需一段時間才能上線就算啟動擴產意味折舊費用提高對毛利造成負面影響臻鼎近期人氣強強滾天風國際證券更看好臻鼎是年蘋果 的軟板用量增長中最大受惠者之一；惟法說會後匯豐證券認為評價滿足加上供應商議價能力低高階於主流智慧機滲透率提升緩慢等變數啟動降評賣出目標價看元匯豐也是外資圈中少數對臻鼎前景較保守代表'], 'input_ids': tensor([[ 101, 3184, 5408, 3297, 3173, 1139, 4412,  712, 3837, 6752, 2494, 6657,\n",
            "         6496, 8038, 1912, 6536, 1825, 3176, 5500, 1019, 4039, 1914, 1086,  677,\n",
            "         4958, 7279, 3300, 7361, 1184, 2990,  671, 1366, 3706, 7360, 6268, 1060,\n",
            "         1920, 7770, 1019, 5500,  978, 7959, 8020, 8021, 5645, 5638, 7959, 8020,\n",
            "         8021, 4685, 6733, 1914, 2157, 4777, 4955, 3582, 3539, 4685, 5262, 6310,\n",
            "         1285, 5836, 6858, 8020, 8021, 5645, 3615, 5646, 8020, 8021, 6512, 1243,\n",
            "         7521, 3309, 3184, 5408, 1058, 1139, 4412, 5265, 6525,  856, 1019, 5500,\n",
            "         1139, 5562, 7770, 1019, 5500, 3082,  868, 5032, 4526,  978, 7959, 5638,\n",
            "         7959, 5500, 1019, 6818, 3309, 7427, 7427, 3102,  677, 7770, 2292, 4448,\n",
            "         7065, 5645, 1274, 6493, 6349, 1171, 3634, 3229, 1139, 2797, 1146, 1162,\n",
            "         7360, 6268, 1060, 3593, 7770, 1019, 2900, 3560, 5500, 5635,  704, 4989,\n",
            "         5645, 6546, 1139, 1772, 6291, 4158, 3688, 1164, 3097, 2484, 5023, 1164,\n",
            "         1914, 2347, 1353, 3216, 1762, 5500, 1019,  677, 2456, 6359, 3186,  678,\n",
            "         2145, 2786, 4363, 1164,  749, 5178, 4685, 6733,  722,  678, 3184, 5408,\n",
            "          704,  856, 1019,  855, 4638, 3615, 5646, 5836, 6858, 5500, 1019, 6134,\n",
            "         4412, 1398, 3564,  778, 7927, 4197, 1058, 1912, 6536, 4777, 4955, 3582,\n",
            "         3539, 1353, 5445, 4692, 1168, 3291, 1914,  889, 5632, 4363, 1164, 2990,\n",
            "         1285, 4638, 1943, 3582, 1008, 7029, 3333, 6349, 1171, 3297, 6818, 2798,\n",
            "         6310, 1285, 3615, 5646, 6512, 1243, 7521, 3309, 5186,  671, 2832, 7547,\n",
            "         7027, 3203, 5023,  758, 1920, 4777, 4955, 3582, 3539, 1179, 2205, 5836,\n",
            "         6858, 1548, 7770, 6310, 3791,  782, 4692,  704,  856, 1019,  855, 7427,\n",
            "         7413, 4638, 3297, 7770, 4680, 3560, 1019, 6963,  889, 1168, 1039, 4051,\n",
            "         1762,  677, 3593, 4958, 7279, 1772, 1762,  753, 2768, 2340, 1381,  978,\n",
            "         7959, 3297, 3173, 7370, 6901, 4448, 7065, 6349, 1171, 7360, 6268, 1274,\n",
            "         6493, 6349, 1171, 4906, 2825, 4496, 3511, 1146, 3358, 2374, 3825, 2361,\n",
            "         3696, 3189, 1184, 2347, 1139, 2797, 6310, 7360, 2972, 3947, 3313,  889,\n",
            "          943, 3299, 1394, 4415, 5500, 1019, 3221, 1039, 4158, 1912, 6536,  712,\n",
            "         6206, 4777, 4955, 3582, 3539,  704, 3297,  856, 4448, 7065, 6349, 1171,\n",
            "         2900, 1139,  978, 7959, 1762, 1146, 3141, 4496, 1501, 5175, 1394,  677,\n",
            "         1357, 2533,  679, 7097, 2768, 3362, 3688, 1164, 4372, 7518, 1164, 3097,\n",
            "         2484,  852, 5500, 1019,  791, 2399,  889, 5195, 6882, 4039, 1285, 1920,\n",
            "         6121, 2658, 2527, 6328, 1914, 1164, 1914, 2347, 1353, 3216, 1762, 5500,\n",
            "         1019, 7598, 4039,  722,  677, 4680, 1184, 5500, 1019,  855, 7389,  889,\n",
            "         1168, 2399, 2972,  844, 4363, 1164, 4638,  945, 3315, 4660, 3683, 5993,\n",
            "         1762, 6882, 1343,  676, 2399, 8080,  945, 1281, 7279,  677, 5225, 8039,\n",
            "         6868,  671, 3635, 5440, 7030, 4685, 7302, 4496, 1501, 4245, 3119, 1377,\n",
            "         5543,  678, 3998, 4680, 1184, 6268, 1019, 2347, 5195, 1394, 4415, 1086,\n",
            "         4039, 4958, 7279, 3300, 7361, 1728, 5445, 7360, 6268,  679, 2456, 6359,\n",
            "         2145, 2786, 1086, 6841, 1019, 3825, 2361, 3696, 6291, 4158,  978, 7959,\n",
            "         2399, 3688, 1164, 4372, 1377, 3307, 1728, 2768, 3315, 5178, 3539, 3121,\n",
            "         1587, 5445,  677, 1285,  852, 1728,  978, 7959, 4496, 5543, 3300, 7361,\n",
            "         3097, 4496, 7444,  671, 3667, 3229, 7279, 2798, 5543,  677, 5221, 2218,\n",
            "         5050, 1564, 1240, 3097, 4496, 2692, 1456,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['主演：呂雪鳳張曉雄李夢蘇俊忠李英銓導演張作驥的電影都以他個人的生活為取材靈感來源加上長期對於底層社會陰暗面的觀察在看似平淡無奇的眾生相裡頭提煉出他最生猛有力的轉折這個家的兩個女人不約而同都在感受到其實周遭的人對自己非常陌生女兒小夢是替男友頂罪入獄終於得到假釋回家可是她對兒子阿全而言卻是一個陌生人母親玉鳳勞心勞力支撐整個家但父親張軍雄老年失智什麼都忘記了讓玉鳳心裡有說不出的恨整個家的變化阿全都默默看在眼裡大人的紛擾對他來說只是這個夏天的記憶張作驥的電影裡頭總有一個失能的家庭以及為了這個家庭始終在忙碌的女性如果把他之前的當愛來的時候醉生夢死放在一起看這是一個母親三部曲的結束 主演：張家輝張翰秦沛金燕玲谷祖琳張兆輝鄭則仕走驚悚燒腦路線的催眠裁決是少見的法庭電影但又透過各種橋段營造緊張氣氛文戲爾虞我詐武戲動作飛車整個就是讓觀眾大呼過癮曾經是國際知名的催眠專家許立生成為審查香港兇殺案的陪審團成員之一但在審判最後一天陪審團就要退席做出最後裁決之際他收到不名人士的消息他的女兒被綁架了如果在分鐘內無法用催眠至少控制個陪審團成員女兒的命就不保許立生別無他法除了一邊滿足綁匪的要求一邊拜託友人幫忙追查女兒的下落到底最後的判決會決定誰能活下來呢過去以陪審團為主的法庭電影像是怒漢焦點在陪審團成員審視證據爭辯有罪與否或者如失控的陪審團則是有各種威脅利誘讓陪審團成員讓步催眠裁決結合了好幾種類型電影更佳刺激 主演：蔡嘉茵柯淑勤張耀仁張恩瑋謝祖武賴琳恩導演謝沛如之前在台灣年拍出蝦餃充滿了活力幽默與對社會萬象的觀察到了這部長片大餓則是透故主角不斷的減肥過程反思社會對於美醜標準的判定安親班的小朋友跟大朋友都稱呼阿娟大恐龍老師因為在她豐腴圓潤的身形底下雖有著一顆熱情的吃心以及精湛的煮藝卻老是因為身材而飽受歧視但只有在媽媽開的安親班裡頭透過烹飪才能讓她有些許的成就感這天她遇見了一位帥氣的快遞員意外點燃心中的小宇宙讓她有機會談場戀愛為了追求愛情阿娟展開了減肥之路為什麼食慾跟愛欲不能共存呢這部片的魅力就在女主角蔡嘉茵身上因為她除了體型大其實才華更大完全讓觀眾把焦點放在她身上如果你喜歡渡邊直美你一定會喜歡蔡嘉茵 主演：亞當迪凡亞利珊卓希普羅絲拜恩你也是天天都離不開手機的人嗎如果有一天你的手機愛上你你要怎麼辦怎麼跟這個最懂你的雲端情人相處嗎菲爾是重度依賴手機的宅男完全仰賴手機的人工智能打點一切所以他對全新推出的手機無比期待但是新手機內建的人工智能潔西似乎充滿了人性不但天天跟菲爾唱反調甚至自作主張幫他向心儀對象凱特告白以各種出糗慘烈收場在一連串誤打誤撞當中菲爾的生活也產生微妙變化甚至成功與凱特墜入情網誰知太過人性化的潔西開始忌妒起凱特展開人機三角戀的爭奪大戰電影由醉後大丈夫阿姐萬萬醉的編劇搭檔寫出這個超越禁的故事保證看完以後你再也無法跟以前一樣對待你的手機 主演：蘇特辛萊杰特施拉達卡普爾瓦倫雀勒瑪普拉提克巴巴爾塔爾比辛納維波利歇蒂圖夏旁提導演涅提帝瓦里曾拍出我的冠軍女兒在台灣締造超過一億台幣的票房成績因此這部新片萬萬沒想到也被寄予厚望透過喜劇的形式來回顧在升學主義下社會對於追夢青年的各種束縛演事業有成卻疏於關心家人的爸爸阿尼為了安慰考試落榜的兒子決定跟他分享在大學最瘋狂最爆笑的回憶這些當年在學校都搞不清楚狀況的魯蛇幫做起事情只是熱情又單純當然也常常出包但總是不忘互相安慰與拉拔表面上看似在鼓勵兒子但實際上是一場中年同學會即使年輕頹廢迷茫人生沒有做不到只有想不到導演提到電影角色有許多昔日大學同窗的影子觀眾也可以在裡頭找到關於學生時代的回憶甚至會想起很久沒聯絡的老朋友電影如果因此可以讓大家一起想起當年的歡樂這就是最好的評價'], 'input_ids': tensor([[ 101,  712, 4028, 8038, 1436, 7434, 7854, 2484, 3280, 7413, 3330, 1918,\n",
            "         5979,  916, 2566, 3330, 5739, 7069, 2206, 4028, 2484,  868, 7715, 4638,\n",
            "         7442, 2512, 6963,  809,  800,  943,  782, 4638, 4495, 3833, 4158, 1357,\n",
            "         3332, 7470, 2697,  889, 3975, 1217,  677, 7269, 3309, 2205, 3176, 2419,\n",
            "         2251, 4852, 3298, 7374, 3266, 7481, 4638, 6223, 2175, 1762, 4692,  849,\n",
            "         2398, 3909, 4192, 1936, 4638, 4707, 4495, 4685, 6174, 7531, 2990, 4200,\n",
            "         1139,  800, 3297, 4495, 4338, 3300, 1213, 4638, 6752, 2835, 6857,  943,\n",
            "         2157, 4638, 1060,  943, 1957,  782,  679, 5147, 5445, 1398, 6963, 1762,\n",
            "         2697, 1358, 1168, 1071, 2179, 1453, 6901, 4638,  782, 2205, 5632, 2346,\n",
            "         7478, 2382, 7359, 4495, 1957, 1051, 2207, 1918, 3221, 3296, 4511, 1351,\n",
            "         7515, 5389, 1057, 4352, 5173, 3176, 2533, 1168,  969, 7026, 1726, 2157,\n",
            "         1377, 3221, 1961, 2205, 1051, 2094, 7350, 1059, 5445, 6241, 1320, 3221,\n",
            "          671,  943, 7359, 4495,  782, 3678, 6217, 4373, 7854, 1246, 2552, 1246,\n",
            "         1213, 3118, 3052, 3146,  943, 2157,  852, 4266, 6217, 2484, 6725, 7413,\n",
            "         5439, 2399, 1927, 3255,  784, 7938, 6963, 2563, 6250,  749, 6366, 4373,\n",
            "         7854, 2552, 6174, 3300, 6303,  679, 1139, 4638, 2616, 3146,  943, 2157,\n",
            "         4638, 6365, 1265, 7350, 1059, 6963, 7949, 7949, 4692, 1762, 4706, 6174,\n",
            "         1920,  782, 4638, 5160, 3101, 2205,  800,  889, 6303, 1372, 3221, 6857,\n",
            "          943, 1909, 1921, 4638, 6250, 2741, 2484,  868, 7715, 4638, 7442, 2512,\n",
            "         6174, 7531, 5244, 3300,  671,  943, 1927, 5543, 4638, 2157, 2431,  809,\n",
            "         1350, 4158,  749, 6857,  943, 2157, 2431, 1993, 5173, 1762, 2564, 4808,\n",
            "         4638, 1957, 2595, 1963, 3362, 2828,  800,  722, 1184, 4638, 4534, 2695,\n",
            "          889, 4638, 3229,  952, 7004, 4495, 1918, 3647, 3123, 1762,  671, 6629,\n",
            "         4692, 6857, 3221,  671,  943, 3678, 6217,  676, 6956, 3289, 4638, 5178,\n",
            "         3338,  712, 4028, 8038, 2484, 2157, 6740, 2484, 5432, 4912, 3764, 7032,\n",
            "         4242, 4386, 6484, 4862, 4432, 2484, 1042, 6740, 6972, 1179,  799, 6624,\n",
            "         7711, 2639, 4240, 5582, 6662, 5221, 4638,  998, 4697, 6161, 3748, 3221,\n",
            "         2208, 6210, 4638, 3791, 2431, 7442, 2512,  852, 1348, 6851, 6882, 1392,\n",
            "         4934, 3578, 3667, 4245, 6863, 5215, 2484, 3706, 3702, 3152, 2783, 4273,\n",
            "         5997, 2769, 6266, 3636, 2783, 1240,  868, 7606, 6722, 3146,  943, 2218,\n",
            "         3221, 6366, 6223, 4707, 1920, 1461, 6882, 4628, 3295, 5195, 3221, 1751,\n",
            "         7396, 4761, 1399, 4638,  998, 4697, 2201, 2157, 6258, 4989, 4495, 2768,\n",
            "         4158, 2182, 3389, 7676, 3949, 1043, 3669, 3428, 4638, 7373, 2182, 1757,\n",
            "         2768, 1519,  722,  671,  852, 1762, 2182, 1161, 3297, 2527,  671, 1921,\n",
            "         7373, 2182, 1757, 2218, 6206, 6842, 2375,  976, 1139, 3297, 2527, 6161,\n",
            "         3748,  722, 7396,  800, 3119, 1168,  679, 1399,  782, 1894, 4638, 3867,\n",
            "         2622,  800, 4638, 1957, 1051, 6158, 5192, 3373,  749, 1963, 3362, 1762,\n",
            "         1146, 7132, 1058, 4192, 3791, 4500,  998, 4697, 5635, 2208, 2971, 1169,\n",
            "          943, 7373, 2182, 1757, 2768, 1519, 1957, 1051, 4638, 1462, 2218,  679,\n",
            "          924, 6258, 4989, 4495, 1162, 4192,  800, 3791, 7370,  749,  671, 6920,\n",
            "         4021, 6639, 5192, 1272, 4638, 6206, 3724,  671, 6920, 2876, 6249, 1351,\n",
            "          782, 2396, 2564, 6841, 3389, 1957, 1051, 4638,  678, 5862, 1168, 2419,\n",
            "         3297, 2527, 4638, 1161, 3748, 3298, 3748,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['記者葉永騫屏東報導屏東縣春日鄉無黨籍縣議員周陳文彬因為在縣議員選舉時涉嫌以每票二千元向選民進行賄選昨天周陳文彬及二名樁腳遭屏東地院裁定羈押禁見這是繼國民黨籍牡丹鄉縣議員林采穎被收押後第二位遭到羈押的屏東縣議員與樁腳以每票千賄選檢調表示曾任二屆春日鄉民代表無黨籍立法委員高金素梅助理的周陳文彬這次參選第十三選舉區也就是春日鄉山地原住民區縣議員為求當選周陳文彬與曾姓石姓樁腳共同以每票二千元向黃姓等選民賄選買票屏東檢調人員經過搜證後掌握到樁腳賄選及選民收賄的事實昨天將周陳文彬石姓曾姓樁腳及黃姓選民共四人約談到案請繼續往下閱讀周陳文彬否認有賄選情形石姓及曾姓樁腳也否認代為行賄但是有其他樁腳及收賄選民坦承行賄及收到賄款檢察官以有滅證勾串共犯及證人之虞向屏東地方法院聲請羈押四人屏東地方法院法官認為周陳文彬及石姓曾姓樁腳三人涉嫌重大裁定收押禁見而涉及收賄的黃姓選民以一萬元交保候傳；另一名周姓樁腳也被檢方以五萬元裁定交保候傳第位遭羈押的屏縣議員在上個月投票日前一週國民黨籍議員候選人林采穎因涉及賄選遭收押開票結果仍當選縣議員但因羈押中十二月二十五日就職日仍未完成宣誓周陳文彬成為第二名因為賄選被收押禁見的屏東縣議員'], 'input_ids': tensor([[ 101, 6250, 5442, 5864, 3719,  100, 2242, 3346, 1841, 2206, 2242, 3346,\n",
            "         5238, 3217, 3189, 6965, 4192, 7955, 5093, 5238, 6359, 1519, 1453, 7376,\n",
            "         3152, 2509, 1728, 4158, 1762, 5238, 6359, 1519, 6908, 5647, 3229, 3868,\n",
            "         2066,  809, 3680, 4873,  753, 1283, 1039, 1403, 6908, 3696, 6868, 6121,\n",
            "         6535, 6908, 3219, 1921, 1453, 7376, 3152, 2509, 1350,  753, 1399, 3555,\n",
            "         5589, 6901, 2242, 3346, 1765, 7368, 6161, 2137, 5398, 2852, 4881, 6210,\n",
            "         6857, 3221, 5262, 1751, 3696, 7955, 5093, 4285,  710, 6965, 5238, 6359,\n",
            "         1519, 3360, 7023, 4949, 6158, 3119, 2852, 2527, 5018,  753,  855, 6901,\n",
            "         1168, 5398, 2852, 4638, 2242, 3346, 5238, 6359, 1519, 5645, 3555, 5589,\n",
            "          809, 3680, 4873, 1283, 6535, 6908, 3596, 6310, 6134, 4850, 3295,  818,\n",
            "          753, 2234, 3217, 3189, 6965, 3696,  807, 6134, 4192, 7955, 5093, 4989,\n",
            "         3791, 1999, 1519, 7770, 7032, 5162, 3449, 1221, 4415, 4638, 1453, 7376,\n",
            "         3152, 2509, 6857, 3613, 1347, 6908, 5018, 1282,  676, 6908, 5647, 1281,\n",
            "          738, 2218, 3221, 3217, 3189, 6965, 2255, 1765, 1333,  857, 3696, 1281,\n",
            "         5238, 6359, 1519, 4158, 3724, 4534, 6908, 1453, 7376, 3152, 2509, 5645,\n",
            "         3295, 1998, 4767, 1998, 3555, 5589, 1066, 1398,  809, 3680, 4873,  753,\n",
            "         1283, 1039, 1403, 7941, 1998, 5023, 6908, 3696, 6535, 6908, 6525, 4873,\n",
            "         2242, 3346, 3596, 6310,  782, 1519, 5195, 6882, 3017, 6349, 2527, 2958,\n",
            "         2995, 1168, 3555, 5589, 6535, 6908, 1350, 6908, 3696, 3119, 6535, 4638,\n",
            "          752, 2179, 3219, 1921, 2200, 1453, 7376, 3152, 2509, 4767, 1998, 3295,\n",
            "         1998, 3555, 5589, 1350, 7941, 1998, 6908, 3696, 1066, 1724,  782, 5147,\n",
            "         6312, 1168, 3428, 6313, 5262, 5265, 2518,  678, 7288, 6364, 1453, 7376,\n",
            "         3152, 2509, 1415, 6291, 3300, 6535, 6908, 2658, 2501, 4767, 1998, 1350,\n",
            "         3295, 1998, 3555, 5589,  738, 1415, 6291,  807, 4158, 6121, 6535,  852,\n",
            "         3221, 3300, 1071,  800, 3555, 5589, 1350, 3119, 6535, 6908, 3696, 1788,\n",
            "         2824, 6121, 6535, 1350, 3119, 1168, 6535, 3621, 3596, 2175, 2135,  809,\n",
            "         3300, 3994, 6349, 1256,  706, 1066, 4306, 1350, 6349,  782,  722, 5997,\n",
            "         1403, 2242, 3346, 1765, 3175, 3791, 7368, 5476, 6313, 5398, 2852, 1724,\n",
            "          782, 2242, 3346, 1765, 3175, 3791, 7368, 3791, 2135, 6291, 4158, 1453,\n",
            "         7376, 3152, 2509, 1350, 4767, 1998, 3295, 1998, 3555, 5589,  676,  782,\n",
            "         3868, 2066, 7028, 1920, 6161, 2137, 3119, 2852, 4881, 6210, 5445, 3868,\n",
            "         1350, 3119, 6535, 4638, 7941, 1998, 6908, 3696,  809,  671, 5857, 1039,\n",
            "          769,  924,  952, 1001, 8039, 1369,  671, 1399, 1453, 1998, 3555, 5589,\n",
            "          738, 6158, 3596, 3175,  809,  758, 5857, 1039, 6161, 2137,  769,  924,\n",
            "          952, 1001, 5018,  855, 6901, 5398, 2852, 4638, 2242, 5238, 6359, 1519,\n",
            "         1762,  677,  943, 3299, 2832, 4873, 3189, 1184,  671, 6867, 1751, 3696,\n",
            "         7955, 5093, 6359, 1519,  952, 6908,  782, 3360, 7023, 4949, 1728, 3868,\n",
            "         1350, 6535, 6908, 6901, 3119, 2852, 7274, 4873, 5178, 3362,  793, 4534,\n",
            "         6908, 5238, 6359, 1519,  852, 1728, 5398, 2852,  704, 1282,  753, 3299,\n",
            "          753, 1282,  758, 3189, 2218, 5480, 3189,  793, 3313, 2130, 2768, 2146,\n",
            "         6292, 1453, 7376, 3152, 2509, 2768, 4158, 5018,  753, 1399, 1728, 4158,\n",
            "         6535, 6908, 6158, 3119, 2852, 4881, 6210, 4638, 2242, 3346, 5238, 6359,\n",
            "         1519,  102,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([1])}\n",
            "tensor([1], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n",
            "{'review_text': ['澳紐商澳盛銀行台灣區總經理陳國榮將於年月升任澳新銀行香港區行政總裁該人事消息日由集團宣布並表示他將在監管機構批准後赴香港履新陳國榮以台灣區總座直升香港區最高執行主管是台灣外銀圈近十年來的第一位至於台灣區總經理的接任人選澳新銀行香港辦公室日表示目前仍在法遵核可過程很快就會宣布據了解陳國榮領導台灣經營團隊時就積極培育本地人才目前澳盛台灣員雖然僅上百位全數採重點菁英任用陳國榮於年加入澳新銀行曾於澳洲和亞洲擔任多個高層職位包括澳新銀行菲律賓行政總裁幫助澳新銀行香港建立公司和企業業務兩度來台任職業務專才在法人企金他也是當年負責出清台灣子行消金部門並與金管會溝通匯出子行投資資金的主要執行者在他擔任澳盛銀行台北分行總經理期間發揮領導力與人脈關係促成銀行順利轉型為企金及法人業務澳盛銀行為澳紐銀行業唯一在台灣有據點的銀行陳國榮非常用力於為很多台灣金融機構提供服務支援台灣同業在國際上擴展業務特別是澳紐市場的資本輸入也為高端科技行業及相關生態系統提供獨特的專業知識及見解以幫助客戶聯結其他市場的機會澳新銀行企業銀行業務行政總裁范爾翰表示香港是澳新銀行全球網絡中一個重要市場在促進區內貿易和資金流動上發揮舉足輕重的作用陳國榮的國際經驗將為銀行客戶帶來寶貴的價值並為澳新銀行香港業務發展帶來重大的貢獻'], 'input_ids': tensor([[ 101, 4078, 5153, 1555, 4078, 4670, 7065, 6121, 1378, 4124, 1281, 5244,\n",
            "         5195, 4415, 7376, 1751, 3532, 2200, 3176, 2399, 3299, 1285,  818, 4078,\n",
            "         3173, 7065, 6121, 7676, 3949, 1281, 6121, 3124, 5244, 6161, 6283,  782,\n",
            "          752, 3867, 2622, 3189, 4507, 7415, 1757, 2146, 2357,  699, 6134, 4850,\n",
            "          800, 2200, 1762, 4675, 5052, 3582, 3539, 2821, 1114, 2527, 6626, 7676,\n",
            "         3949, 2252, 3173, 7376, 1751, 3532,  809, 1378, 4124, 1281, 5244, 2429,\n",
            "         4684, 1285, 7676, 3949, 1281, 3297, 7770, 1822, 6121,  712, 5052, 3221,\n",
            "         1378, 4124, 1912, 7065, 1750, 6818, 1282, 2399,  889, 4638, 5018,  671,\n",
            "          855, 5635, 3176, 1378, 4124, 1281, 5244, 5195, 4415, 4638, 2970,  818,\n",
            "          782, 6908, 4078, 3173, 7065, 6121, 7676, 3949, 6794, 1062, 2147, 3189,\n",
            "         6134, 4850, 4680, 1184,  793, 1762, 3791, 6905, 3417, 1377, 6882, 4923,\n",
            "         2523, 2571, 2218, 3298, 2146, 2357, 3087,  749, 6237, 7376, 1751, 3532,\n",
            "         7526, 2206, 1378, 4124, 5195, 4245, 1757, 7386, 3229, 2218, 4948, 3513,\n",
            "         1824, 5509, 3315, 1765,  782, 2798, 4680, 1184, 4078, 4670, 1378, 4124,\n",
            "         1519, 7426, 4197, 1006,  677, 4636,  855, 1059, 3149, 2967, 7028, 7953,\n",
            "         5821, 5739,  818, 4500, 7376, 1751, 3532, 3176, 2399, 1217, 1057, 4078,\n",
            "         3173, 7065, 6121, 3295, 3176, 4078, 3828, 1469,  765, 3828, 3085,  818,\n",
            "         1914,  943, 7770, 2251, 5480,  855, 1259, 2886, 4078, 3173, 7065, 6121,\n",
            "         5838, 2526, 6540, 6121, 3124, 5244, 6161, 2396, 1221, 4078, 3173, 7065,\n",
            "         6121, 7676, 3949, 2456, 4989, 1062, 1385, 1469,  821, 3511, 3511, 1243,\n",
            "         1060, 2428,  889, 1378,  818, 5480, 3511, 1243, 2201, 2798, 1762, 3791,\n",
            "          782,  821, 7032,  800,  738, 3221, 4534, 2399, 6511, 6519, 1139, 3926,\n",
            "         1378, 4124, 2094, 6121, 3867, 7032, 6956, 7271,  699, 5645, 7032, 5052,\n",
            "         3298, 3978, 6858, 1274, 1139, 2094, 6121, 2832, 6536, 6536, 7032, 4638,\n",
            "          712, 6206, 1822, 6121, 5442, 1762,  800, 3085,  818, 4078, 4670, 7065,\n",
            "         6121, 1378, 1266, 1146, 6121, 5244, 5195, 4415, 3309, 7279, 4634, 3000,\n",
            "         7526, 2206, 1213, 5645,  782, 5548, 7302,  913,  914, 2768, 7065, 6121,\n",
            "         7518, 1164, 6752, 1798, 4158,  821, 7032, 1350, 3791,  782, 3511, 1243,\n",
            "         4078, 4670, 7065, 6121, 4158, 4078, 5153, 7065, 6121, 3511, 1546,  671,\n",
            "         1762, 1378, 4124, 3300, 3087, 7953, 4638, 7065, 6121, 7376, 1751, 3532,\n",
            "         7478, 2382, 4500, 1213, 3176, 4158, 2523, 1914, 1378, 4124, 7032, 6084,\n",
            "         3582, 3539, 2990,  897, 3302, 1243, 3118, 3001, 1378, 4124, 1398, 3511,\n",
            "         1762, 1751, 7396,  677, 3097, 2245, 3511, 1243, 4294, 1162, 3221, 4078,\n",
            "         5153, 2356, 1842, 4638, 6536, 3315, 6745, 1057,  738, 4158, 7770, 4999,\n",
            "         4906, 2825, 6121, 3511, 1350, 4685, 7302, 4495, 2706, 5143, 5186, 2990,\n",
            "          897, 4360, 4294, 4638, 2201, 3511, 4761, 6352, 1350, 6210, 6237,  809,\n",
            "         2396, 1221, 2145, 2786, 5474, 5178, 1071,  800, 2356, 1842, 4638, 3582,\n",
            "         3298, 4078, 3173, 7065, 6121,  821, 3511, 7065, 6121, 3511, 1243, 6121,\n",
            "         3124, 5244, 6161, 5745, 4273, 5432, 6134, 4850, 7676, 3949, 3221, 4078,\n",
            "         3173, 7065, 6121, 1059, 4413, 5206, 5181,  704,  671,  943, 7028, 6206,\n",
            "         2356, 1842, 1762,  914, 6868, 1281, 1058, 6530, 3211, 1469, 6536, 7032,\n",
            "         3837, 1240,  677, 4634, 3000, 5647, 6639, 6738, 7028, 4638,  868, 4500,\n",
            "         7376, 1751, 3532, 4638, 1751, 7396, 5195,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['那自律或許也來自於父親的注視打職棒後父親每一場球都會到場我很習慣在比賽時爸爸會出現他偶爾會望向父親常坐的老位置聊到這邊他語氣稍微難過父親近幾年身體不好無法開車需要人載所以只在台北與台中的球場出現採訪後天他個打數支安打獲得單場時說：送給昨天生日的父親自律到一個極限就成了憤怒的火過去打不好時他會砸鐵架椅子打壞不少東西常常賠錢有一次打了軟弱滾地球氣到攻守交換傳接球時怒把球丟出中外野記分板之外他讓我觸摸他充滿厚繭的右手食指下方有一條目測約公分的疤痕是高中畢業學長烙他去打架義氣相挺結果骨折開刀造成他個月無法碰棒球那是選手生命可能失去的時候他沒因此放棄而是持續跑步維持體能\\u3000小拇指下方手背有長條狀隆起那是年他被林英傑振休息區裡怒打變電箱造成右手骨折隔年因傷只出賽場遭扣薪蟬聯年的打擊王紀錄也中斷那時雖為這個傷勢哭過但他沒讓自己陷在陰影裡大部分都在想怎麼復健讓自己快點回到場上揮棒都會痛但我每天都忍著痛硬著頭皮在打當年的隊友馮勝賢說：他過去手不痛的時候打擊天分非常好但那一次的傷勢讓他連天分都失去了等於是重頭再找回過去的身手年前成打擊率仍被視為傳說年外籍選手怪力男橫掃中職築起成的打擊率高牆到年才有台灣最強打者陳金鋒以成的打擊率逼近但讓球迷見證時代演變的是彭政閔年他以無死角的反方向打擊技術把球跟到最後再高速揮棒忍著每一次揮擊時火般的疼痛以成的打擊率打破紀錄時代不饒人後來看見王柏融突破成打擊率障壁當時的心情至少台灣出一個超過成的打擊者而且那一年個彭政閔仍是瞇瞇笑語氣像老大哥美日職棒都有這樣的打者我曾想讓中華職棒有這樣的紀錄自己沒辦法有人達成我滿開心的他曾有次旅外的機會但都因手傷而失去雖然遺憾但程度不大畢竟時空背景不同'], 'input_ids': tensor([[ 101, 6929, 5632, 2526, 2772, 6258,  738,  889, 5632, 3176, 4266, 6217,\n",
            "         4638, 3800, 6213, 2802, 5480, 3472, 2527, 4266, 6217, 3680,  671, 1842,\n",
            "         4413, 6963, 3298, 1168, 1842, 2769, 2523, 5424, 2715, 1762, 3683, 6555,\n",
            "         3229, 4268, 4268, 3298, 1139, 4412,  800,  981, 4273, 3298, 3307, 1403,\n",
            "         4266, 6217, 2382, 1777, 4638, 5439,  855, 5390, 5464, 1168, 6857, 6920,\n",
            "          800, 6295, 3706, 4924, 2544, 7432, 6882, 4266, 6217, 6818, 2407, 2399,\n",
            "         6716, 7768,  679, 1962, 4192, 3791, 7274, 6722, 7444, 6206,  782, 6734,\n",
            "         2792,  809, 1372, 1762, 1378, 1266, 5645, 1378,  704, 4638, 4413, 1842,\n",
            "         1139, 4412, 2967, 6256, 2527, 1921,  800,  943, 2802, 3149, 3118, 2128,\n",
            "         2802, 4363, 2533, 1606, 1842, 3229, 6303, 8038, 6843, 5183, 3219, 1921,\n",
            "         4495, 3189, 4638, 4266, 6217, 5632, 2526, 1168,  671,  943, 3513, 7361,\n",
            "         2218, 2768,  749, 2734, 2584, 4638, 4125, 6882, 1343, 2802,  679, 1962,\n",
            "         3229,  800, 3298, 4790, 7136, 3373, 3488, 2094, 2802, 1889,  679, 2208,\n",
            "         3346, 6205, 2382, 2382, 6543, 7092, 3300,  671, 3613, 2802,  749, 6727,\n",
            "         2483, 4020, 1765, 4413, 3706, 1168, 3122, 2127,  769, 2994, 1001, 2970,\n",
            "         4413, 3229, 2584, 2828, 4413,  694, 1139,  704, 1912, 7029, 6250, 1146,\n",
            "         3352,  722, 1912,  800, 6366, 2769, 6240, 3043,  800, 1041, 4021, 1331,\n",
            "         5259, 4638, 1381, 2797, 7608, 2900,  678, 3175, 3300,  671, 3454, 4680,\n",
            "         3947, 5147, 1062, 1146, 4638, 4552, 4575, 3221, 7770,  704, 4525, 3511,\n",
            "         2119, 7269, 4168,  800, 1343, 2802, 3373, 5412, 3706, 4685, 2923, 5178,\n",
            "         3362, 7755, 2835, 7274, 1143, 6863, 2768,  800,  943, 3299, 4192, 3791,\n",
            "         4821, 3472, 4413, 6929, 3221, 6908, 2797, 4495, 1462, 1377, 5543, 1927,\n",
            "         1343, 4638, 3229,  952,  800, 3760, 1728, 3634, 3123, 3468, 5445, 3221,\n",
            "         2898, 5265, 6651, 3635, 5204, 2898, 7768, 5543, 2207, 2859, 2900,  678,\n",
            "         3175, 2797, 5520, 3300, 7269, 3454, 4311, 7384, 6629, 6929, 3221, 2399,\n",
            "          800, 6158, 3360, 5739,  989, 2920,  828, 2622, 1281, 6174, 2584, 2802,\n",
            "         6365, 7442, 5056, 6863, 2768, 1381, 2797, 7755, 2835, 7392, 2399, 1728,\n",
            "         1003, 1372, 1139, 6555, 1842, 6901, 2807, 5959, 6099, 5474, 2399, 4638,\n",
            "         2802, 3080, 4374, 5145, 7087,  738,  704, 3174, 6929, 3229, 7426, 4158,\n",
            "         6857,  943, 1003, 1248, 1526, 6882,  852,  800, 3760, 6366, 5632, 2346,\n",
            "         7379, 1762, 7374, 2512, 6174, 1920, 6956, 1146, 6963, 1762, 2682, 2582,\n",
            "         7938, 2541,  978, 6366, 5632, 2346, 2571, 7953, 1726, 1168, 1842,  677,\n",
            "         3000, 3472, 6963, 3298, 4578,  852, 2769, 3680, 1921, 6963, 2556, 5865,\n",
            "         4578, 4801, 5865, 7531, 4649, 1762, 2802, 4534, 2399, 4638, 7386, 1351,\n",
            "         7681, 1245, 6545, 6303, 8038,  800, 6882, 1343, 2797,  679, 4578, 4638,\n",
            "         3229,  952, 2802, 3080, 1921, 1146, 7478, 2382, 1962,  852, 6929,  671,\n",
            "         3613, 4638, 1003, 1248, 6366,  800, 6865, 1921, 1146, 6963, 1927, 1343,\n",
            "          749, 5023, 3176, 3221, 7028, 7531, 1086, 2823, 1726, 6882, 1343, 4638,\n",
            "         6716, 2797, 2399, 1184, 2768, 2802, 3080, 4372,  793, 6158, 6213, 4158,\n",
            "         1001, 6303, 2399, 1912, 5093, 6908, 2797, 2597, 1213, 4511, 3585, 2954,\n",
            "          704, 5480, 5064, 6629, 2768, 4638, 2802, 3080, 4372, 7770, 4274, 1168,\n",
            "         2399, 2798, 3300, 1378, 4124, 3297, 2485, 2802, 5442, 7376, 7032, 7081,\n",
            "          809, 2768, 4638, 2802, 3080, 4372, 6873,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['盤勢分析因鴻海和中華電等除息指數蒸發  點早盤一度回測  日線支撐後早高終場指數以上漲  點收在  點成交量為  億短線而言下週二摩台指結算下週四清晨  可能如市場預期降息一碼屆時提防短線利多出盡拉回整理強勢仍持續沿月線盤堅弱勢才有機會回測季線再上去波段則仍至少有挑戰  上下甚至突破去年高點  的能力當  月蘋果新機發表前後  月中下旬  利率決策會議前後要小心另一次波段回檔因電子旺季通常在  月見高峰 要看上中下游供應鏈而時間有所不同同常是上游先見頂而股價通常至少領先一季左右見到波段高檔王信傑 分析師 此研究報告著作權屬倫元證券投資顧問 股 公司切勿盜用或翻印否則追究責任決不寬貸 所有資料僅供參考本公司不負盈虧責任洽  理財專員'], 'input_ids': tensor([[ 101, 4676, 1248, 1146, 3358, 1728, 7862, 3862, 1469,  704, 5836, 7442,\n",
            "         5023, 7370, 2622, 2900, 3149, 5892, 4634, 7953, 3193, 4676,  671, 2428,\n",
            "         1726, 3947, 3189, 5221, 3118, 3052, 2527, 3193, 7770, 5173, 1842, 2900,\n",
            "         3149,  809,  677, 4039, 7953, 3119, 1762, 7953, 2768,  769, 7030, 4158,\n",
            "         1023, 4764, 5221, 5445, 6241,  678, 6867,  753, 3040, 1378, 2900, 5178,\n",
            "         5050,  678, 6867, 1724, 3926, 3247, 1377, 5543, 1963, 2356, 1842, 7521,\n",
            "         3309, 7360, 2622,  671, 4826, 2234, 3229, 2990, 7344, 4764, 5221, 1164,\n",
            "         1914, 1139, 4674, 2861, 1726, 3146, 4415, 2485, 1248,  793, 2898, 5265,\n",
            "         3784, 3299, 5221, 4676, 1830, 2483, 1248, 2798, 3300, 3582, 3298, 1726,\n",
            "         3947, 2108, 5221, 1086,  677, 1343, 3797, 3667, 1179,  793, 5635, 2208,\n",
            "         3300, 2904, 2782,  677,  678, 4493, 5635, 4960, 4788, 1343, 2399, 7770,\n",
            "         7953, 4638, 5543, 1213, 4534, 3299, 5981, 3362, 3173, 3582, 4634, 6134,\n",
            "         1184, 2527, 3299,  704,  678, 3194, 1164, 4372, 3748, 5032, 3298, 6359,\n",
            "         1184, 2527, 6206, 2207, 2552, 1369,  671, 3613, 3797, 3667, 1726, 3593,\n",
            "         1728, 7442, 2094, 3200, 2108, 6858, 2382, 1762, 3299, 6210, 7770, 2292,\n",
            "         6206, 4692,  677,  704,  678, 3952,  897, 2746, 7122, 5445, 3229, 7279,\n",
            "         3300, 2792,  679, 1398, 1398, 2382, 3221,  677, 3952, 1044, 6210, 7515,\n",
            "         5445, 5500, 1019, 6858, 2382, 5635, 2208, 7526, 1044,  671, 2108, 2340,\n",
            "         1381, 6210, 1168, 3797, 3667, 7770, 3593, 4374,  928,  989, 1146, 3358,\n",
            "         2374, 3634, 4777, 4955, 1841, 1440, 5865,  868, 3609, 2253,  961, 1039,\n",
            "         6349, 1171, 2832, 6536, 7547, 1558, 5500, 1062, 1385, 1147, 1257, 4671,\n",
            "         4500, 2772, 5436, 1313, 1415, 1179, 6841, 4955, 6519,  818, 3748,  679,\n",
            "         2184, 6526, 2792, 3300, 6536, 3160, 1006,  897, 1347, 5440, 3315, 1062,\n",
            "         1385,  679, 6511, 4659, 6000, 6519,  818, 3835, 4415, 6512, 2201, 1519,\n",
            "          102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['全名是  證交所翻譯為指數投資證券目前國內有九家券商發行十檔每單位約五至二十元換算下來一張只要五千至二萬元價格親民頗獲小資族青睞據證交所統計自今年四月上路後截至六月底上市櫃最旺的人氣王是富邦特選蘋果累積成交量張；第名為成交量達張元大特股高息第名則為元富新中國目前除台灣發行美國英國德國新加坡日本韓國皆有發行最早是由美國巴克萊銀行發明目前美國有超過二百檔其中亞洲地區的韓國成長相當迅速年月只有十檔才發展四年多已大幅成長到約二百檔商品券商預估台灣五年內市場規模可達二千億元是個全新商品只和市場上風行的只差一個字兩個商品究竟有甚麼不同呢其實就是結合和債券的金融商品指得就是債券簡單說就是券商發行一檔債券（）這檔債券會和某種指數連結指數的選擇多樣常見的有股票指數商品指數投資人購買了這檔債券後待期限屆滿後券商就會以當時的指數價買回換言之就是投資人把錢借給券商約滿贖回雖然有概念但投資人並不會實際持有標的成分資產同時的投資人與券商是借貸關係券商要如何使用資金並無規定和限制但券商一般基於經營穩健原則通常布局仍會考慮避險由於投資人和券商有借貸關係證交所為避免產生發行人信用風險可發行的券商必須符合淨值達一百億元以上最近六個月資本適足率不低於未受警告以上處分等條件券商每月還須提撥履約保證金以及申報資金運用的項目與比率以確保投資人權益金管會近來也研擬開放銀行保險業投入活絡股市動能市場估計銀行還有數千億元購買空間保險業則有高達兆元的投資空間預料一旦開放後將有助市場發展並替台股注入活水由於有期限券商建議投資人挑選時秉持兩原則挑選一是觀察的主題其次是依照期限來挑選以人氣前三名的元富新中國富邦特選大蘋果為例就是和中國新經濟蘋概股有關另外偏好短線操作的投資人也可參考產業類股為主的以賺取報酬雖然吸引不少小資族進場但不保本證交所也提醒投資人購買時要注意價格和指數對應的波動以及券商財務狀況同時更要注意手續費以免獲利被侵蝕另外目前也不能當沖信用交易借券零股交易外資和陸資也都不能買賣'], 'input_ids': tensor([[ 101, 1059, 1399, 3221, 6349,  769, 2792, 5436, 6358, 4158, 2900, 3149,\n",
            "         2832, 6536, 6349, 1171, 4680, 1184, 1751, 1058, 3300,  736, 2157, 1171,\n",
            "         1555, 4634, 6121, 1282, 3593, 3680, 1606,  855, 5147,  758, 5635,  753,\n",
            "         1282, 1039, 2994, 5050,  678,  889,  671, 2484, 1372, 6206,  758, 1283,\n",
            "         5635,  753, 5857, 1039, 1019, 3419, 6217, 3696, 7525, 4363, 2207, 6536,\n",
            "         3184, 7471, 4716, 3087, 6349,  769, 2792, 5186, 6243, 5632,  791, 2399,\n",
            "         1724, 3299,  677, 6662, 2527, 2779, 5635, 1063, 3299, 2419,  677, 2356,\n",
            "         3602, 3297, 3200, 4638,  782, 3706, 4374, 3221, 2168, 6930, 4294, 6908,\n",
            "         5981, 3362, 5168, 4948, 2768,  769, 7030, 2484, 8039, 5018, 1399, 4158,\n",
            "         2768,  769, 7030, 6888, 2484, 1039, 1920, 4294, 5500, 7770, 2622, 5018,\n",
            "         1399, 1179, 4158, 1039, 2168, 3173,  704, 1751, 4680, 1184, 7370, 1378,\n",
            "         4124, 4634, 6121, 5401, 1751, 5739, 1751, 2548, 1751, 3173, 1217, 1786,\n",
            "         3189, 3315, 7502, 1751, 4639, 3300, 4634, 6121, 3297, 3193, 3221, 4507,\n",
            "         5401, 1751, 2349, 1046, 5844, 7065, 6121, 4634, 3209, 4680, 1184, 5401,\n",
            "         1751, 3300, 6631, 6882,  753, 4636, 3593, 1071,  704,  765, 3828, 1765,\n",
            "         1281, 4638, 7502, 1751, 2768, 7269, 4685, 4534, 6813, 6862, 2399, 3299,\n",
            "         1372, 3300, 1282, 3593, 2798, 4634, 2245, 1724, 2399, 1914, 2347, 1920,\n",
            "         2388, 2768, 7269, 1168, 5147,  753, 4636, 3593, 1555, 1501, 1171, 1555,\n",
            "         7521,  844, 1378, 4124,  758, 2399, 1058, 2356, 1842, 6211, 3563, 1377,\n",
            "         6888,  753, 1283, 1023, 1039, 3221,  943, 1059, 3173, 1555, 1501, 1372,\n",
            "         1469, 2356, 1842,  677, 7591, 6121, 4638, 1372, 2345,  671,  943, 2099,\n",
            "         1060,  943, 1555, 1501, 4955, 4994, 3300, 4493, 7938,  679, 1398, 1450,\n",
            "         1071, 2179, 2218, 3221, 5178, 1394, 1469, 1002, 1171, 4638, 7032, 6084,\n",
            "         1555, 1501, 2900, 2533, 2218, 3221, 1002, 1171, 5080, 1606, 6303, 2218,\n",
            "         3221, 1171, 1555, 4634, 6121,  671, 3593, 1002, 1171, 8020, 8021, 6857,\n",
            "         3593, 1002, 1171, 3298, 1469, 3378, 4934, 2900, 3149, 6865, 5178, 2900,\n",
            "         3149, 4638, 6908, 3079, 1914, 3564, 2382, 6210, 4638, 3300, 5500, 4873,\n",
            "         2900, 3149, 1555, 1501, 2900, 3149, 2832, 6536,  782, 6554, 6525,  749,\n",
            "         6857, 3593, 1002, 1171, 2527, 2521, 3309, 7361, 2234, 4021, 2527, 1171,\n",
            "         1555, 2218, 3298,  809, 4534, 3229, 4638, 2900, 3149, 1019, 6525, 1726,\n",
            "         2994, 6241,  722, 2218, 3221, 2832, 6536,  782, 2828, 7092,  955, 5183,\n",
            "         1171, 1555, 5147, 4021, 6562, 1726, 7426, 4197, 3300, 3519, 2573,  852,\n",
            "         2832, 6536,  782,  699,  679, 3298, 2179, 7396, 2898, 3300, 3560, 4638,\n",
            "         2768, 1146, 6536, 4496, 1398, 3229, 4638, 2832, 6536,  782, 5645, 1171,\n",
            "         1555, 3221,  955, 6526, 7302,  913, 1171, 1555, 6206, 1963,  862,  886,\n",
            "         4500, 6536, 7032,  699, 4192, 6211, 2137, 1469, 7361, 1169,  852, 1171,\n",
            "         1555,  671, 5663, 1825, 3176, 5195, 4245, 4952,  978, 1333, 1179, 6858,\n",
            "         2382, 2357, 2229,  793, 3298, 5440, 2719, 6912, 7402, 4507, 3176, 2832,\n",
            "         6536,  782, 1469, 1171, 1555, 3300,  955, 6526, 7302,  913, 6349,  769,\n",
            "         2792, 4158, 6912, 1048, 4496, 4495, 4634, 6121,  782,  928, 4500, 7591,\n",
            "         7402, 1377, 4634, 6121, 4638, 1171, 1555, 2553, 7519, 5016, 1394, 3912,\n",
            "          966, 6888,  671, 4636, 1023, 1039,  809,  677, 3297, 6818, 1063,  943,\n",
            "         3299, 6536, 3315, 6900, 6639, 4372,  679,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['歲男子高嘉斌擁槍自重從事販毒勾當警方日晚間前往新北市新莊區埋伏逮人高嫌趁隙逃往山區警方荷槍實彈搜索無功而返新北市刑大今（日）前往桃園逮捕高嫌查獲土耳其製手槍枝子彈顆毒品海洛因安非他命大麻等證物警方調查高嫌有槍砲毒品等前科在雙北市以販毒為業警方獲報高嫌日出現在新北市新莊區豈料高嫌下車時發現有警員埋伏趁隙躲藏到一處空屋內再趁天黑逃往山區警方圍捕近小時無功而返警方今（日）前往桃園埋伏一舉逮捕高嫌及巫姓男子潘姓男子等人查獲土耳其製手槍枝子彈顆毒品海洛因安非他命大麻等證物警方將人帶回進一步偵訊中中時電子報關心您：保護自己遠離毒品中時'], 'input_ids': tensor([[ 101, 3641, 4511, 2094, 7770, 1649, 3154, 3075, 3541, 5632, 7028, 2537,\n",
            "          752, 6516, 3681, 1256, 4534, 6356, 3175, 3189, 3241, 7279, 1184, 2518,\n",
            "         3173, 1266, 2356, 3173, 5800, 1281, 1813,  826, 6866,  782, 7770, 2066,\n",
            "         6630, 7395, 6845, 2518, 2255, 1281, 6356, 3175, 5792, 3541, 2179, 2492,\n",
            "         3017, 5164, 4192, 1216, 5445, 6819, 3173, 1266, 2356, 1152, 1920,  791,\n",
            "         8020, 3189, 8021, 1184, 2518, 3425, 1754, 6866, 2936, 7770, 2066, 3389,\n",
            "         4363, 1759, 5455, 1071, 6182, 2797, 3541, 3363, 2094, 2492, 7538, 3681,\n",
            "         1501, 3862, 3821, 1728, 2128, 7478,  800, 1462, 1920, 7937, 5023, 6349,\n",
            "         4289, 6356, 3175, 6310, 3389, 7770, 2066, 3300, 3541, 4787, 3681, 1501,\n",
            "         5023, 1184, 4906, 1762, 7427, 1266, 2356,  809, 6516, 3681, 4158, 3511,\n",
            "         6356, 3175, 4363, 1841, 7770, 2066, 3189, 1139, 4412, 1762, 3173, 1266,\n",
            "         2356, 3173, 5800, 1281, 6488, 3160, 7770, 2066,  678, 6722, 3229, 4634,\n",
            "         4412, 3300, 6356, 1519, 1813,  826, 6630, 7395, 6719, 5966, 1168,  671,\n",
            "         5993, 4958, 2238, 1058, 1086, 6630, 1921, 7946, 6845, 2518, 2255, 1281,\n",
            "         6356, 3175, 1752, 2936, 6818, 2207, 3229, 4192, 1216, 5445, 6819, 6356,\n",
            "         3175,  791, 8020, 3189, 8021, 1184, 2518, 3425, 1754, 1813,  826,  671,\n",
            "         5647, 6866, 2936, 7770, 2066, 1350, 2344, 1998, 4511, 2094, 4050, 1998,\n",
            "         4511, 2094, 5023,  782, 3389, 4363, 1759, 5455, 1071, 6182, 2797, 3541,\n",
            "         3363, 2094, 2492, 7538, 3681, 1501, 3862, 3821, 1728, 2128, 7478,  800,\n",
            "         1462, 1920, 7937, 5023, 6349, 4289, 6356, 3175, 2200,  782, 2380, 1726,\n",
            "         6868,  671, 3635,  980, 6244,  704,  704, 3229, 7442, 2094, 1841, 7302,\n",
            "         2552, 2644, 8038,  924, 6362, 5632, 2346, 6895, 7431, 3681, 1501,  704,\n",
            "         3229,  102,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([1])}\n",
            "tensor([1], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n",
            "{'review_text': ['不少投資人一定聽過存股策略只要買進年年獲利成長且股利配發穩定的公司就可以幫自己打造良好的現金流來源鉅亨買基金提醒投資人存股不只可以存台灣股票外國同樣有非常多此類優質的公司透過買進全球高股息基金存外國股票將為投資人帶來更多好處 存股策略有沒有效買進推薦存股標的 年累積股利與本金變化資料來源：智富雜誌鉅亨買基金整理資料日期：此資料僅為歷史數據模擬回測不為未來投資獲利之保證在不同指數走勢比重與期間下可能得到不同數據結果買進如兆豐金大台北瓦斯此類現金流穩定且倒閉機率極低的公司股票在穩定領取股利的同時本金還有成長機會聽起來是良好的投資策略我們實際回測後發現假設投資人於  年  月看到智富雜誌（）的定存概念股文章後便將  萬資金分散在  檔推薦股票並持有至今平均每月領到  元的股利累積股利高達  萬元除了領到股利外本金也成長至  萬元回測效果優異 不只可以存台灣股透過基金還可以存全球股檢視並發現存股策略有效後下個問題便是只能存台灣股票嗎其他國家的股票難道就不行下圖為同樣  年  月至今假設投資人分散並買入  檔台灣推薦股票或是全數買入全球高股息類股兩者本金加累積配息的變化比較存台灣股策略由於持有標的較集中波動程度明顯較大；而分散在  個已開發國家中  檔股票的存外國股策略波動程度顯著降低本金與累積配息相加後金額也略高於存台灣股策略（ 萬與  萬）本金加配息存全球股策略佳資料來源：智富雜誌鉅亨買基金整理採  全球高股息指數資料日期：此資料僅為歷史數據模擬回測不為未來投資獲利之保證在不同指數走勢比重與期間下可能得到不同數據結果 雞蛋不應該放同一個籃子退休金流也是退休金三大支柱資料來源：鉅亨買基金整理資料日期：雞蛋不要放在同一個籃子裡絕對是投資路上最重要的警句之一在準備退休金流的路上這句話也該被反覆拿出來審視退休金流可分為三層分別是國民年金勞工保險等組成的法定公共年金勞工退休金制度的法定職業年金與自行準備的個人保障第一與第二層的保障等於建立在台灣這兩個字之上只要台灣經濟狀況良好政府財政體制健全且新台幣實質購買力穩定這兩層收入應足夠支付部份退休開支但若台灣經濟狀況不好財政收支長期失衡或新台幣實質購買力大幅滑落時此兩層收入很可能不夠撐起退休需求如果第三層的個人保障也都放在台灣股票時等同於三層保障同時失去功效建議投資人應該第三層保障分散在不同國家與不同幣別資產以分散本地經濟遭受衝擊的風險鉅亨投資策略基金操作上建議如下：分散是鐵則存股族也該納入全球高股息基金對於存股族來說全球高股息基金除了同樣由優質高配息股票組成外無論在國家貨幣或產業配置都更分散存台灣股之外存外國股票也是投資人的好選擇鉅亨精選基金 富達基金  全球入息基金  類股累計股份  美元 貝萊德全球智慧數據股票入息基金  美元鉅亨投顧獨立經營管理本資料僅供參考鉅亨買基金已盡力就可靠之資料來源提供正確之意見與消息但無法保證該等資料之完整性內容涉及新興市場部分因其波動性與風險程可能較高且其政治與經濟情勢穩定可能低於已開發國家也可能使資產價值受同程之影響匯走勢亦可能影響所投資之海外資產價值變動投資人應依其本身之判斷投資有損益或因使用本資所生之直接或間接損失應由投資人自負責本公司無須負擔任何責任本文提及之經濟走勢預測不必然代表基金之績效基金投資風險請詳閱基金公開說明書及投資人須知基金經金管會核准或同意生效惟不表示絕無風險基金經理公司以往之經理績效不保證基金最低投資收益；基金經理公司除盡善良管理人之注意義務外不負責基金之盈虧亦不保證最低之收益投資人申購前應詳閱基金公開說明書及投資人須知各銷售機構備有基金公開說明書及投資人須知歡迎索取有關基金應負擔之費用（境外基金含分銷費用）已揭露於基金之公開說明書或投資人須知中投資人可至公開資訊觀測站或境外基金資訊觀測站中查詢投資人投資以高收益債券為訴求之基金不宜占其投資組合過高之比重基金經金管會核准或同意生效惟不表示絕無風險由於高收益債券之信用評等未達投資等級或未經信用評等且對利率變動的敏感度甚高故基金可能會因利率上升市場流動性下降或債券發行機構違約不支付本金利息或破產而蒙受虧損投資人應審慎評估該等基金不適合無法承擔相關風險之投資人基金經理公司以往之經理績效不保證基金最低投資收益；基金經理公司除盡善良管理人之注意義務外不負責基金之盈虧亦不保證最低之收益投資人申購前應詳閱基金公開說明書及投資人須知投資於   債券境內高收益債券基金最高可投資基金總資產  境內以投資新興市場國家為主之債券型基金及平衡型基金最高可投資基金總資產  境外高收益債券基金可能有部分投資於美國   債券該債券屬私募性質較可能發生流動性不足財務訊息揭露不完整或因價格不透明導致波動性較大之風險不動產證券化型基金得投資於高收益債券其投資總金額不得超過基金淨資產價值之 投資人因不同時間進場將有不同之投資績效過去之績效亦不代表未來績效之保證基金配息率不代表基金報酬率且過去配息率不代表未來配息率；基金淨值可能因市場因素而上下波動基金配息前未先扣除應負擔之相關費用基金的配息可能由基金的收益或本金中支付任何涉及由本金支出的部份可能導致原始投資金額減損鉅亨證券投資顧問股份有限公司  客服信箱：公司地址：台北市信義區松仁路  號  樓  室  服務專線：  服務時間：'], 'input_ids': tensor([[ 101,  679, 2208, 2832, 6536,  782,  671, 2137, 5481, 6882, 2100, 5500,\n",
            "         5032, 4526, 1372, 6206, 6525, 6868, 2399, 2399, 4363, 1164, 2768, 7269,\n",
            "          684, 5500, 1164, 6981, 4634, 4952, 2137, 4638, 1062, 1385, 2218, 1377,\n",
            "          809, 2396, 5632, 2346, 2802, 6863, 5679, 1962, 4638, 4412, 7032, 3837,\n",
            "          889, 3975, 7056,  773, 6525, 1825, 7032, 2990, 7008, 2832, 6536,  782,\n",
            "         2100, 5500,  679, 1372, 1377,  809, 2100, 1378, 4124, 5500, 4873, 1912,\n",
            "         1751, 1398, 3564, 3300, 7478, 2382, 1914, 3634, 7546, 1032, 6549, 4638,\n",
            "         1062, 1385, 6851, 6882, 6525, 6868, 1059, 4413, 7770, 5500, 2622, 1825,\n",
            "         7032, 2100, 1912, 1751, 5500, 4873, 2200, 4158, 2832, 6536,  782, 2380,\n",
            "          889, 3291, 1914, 1962, 5993, 2100, 5500, 5032, 4526, 3300, 3760, 3300,\n",
            "         3126, 6525, 6868, 2972, 5956, 2100, 5500, 3560, 4638, 2399, 5168, 4948,\n",
            "         5500, 1164, 5645, 3315, 7032, 6365, 1265, 6536, 3160,  889, 3975, 8038,\n",
            "         3255, 2168, 7429, 6290, 7056,  773, 6525, 1825, 7032, 3146, 4415, 6536,\n",
            "         3160, 3189, 3309, 8038, 3634, 6536, 3160, 1006, 4158, 3644, 1380, 3149,\n",
            "         3087, 3563, 3093, 1726, 3947,  679, 4158, 3313,  889, 2832, 6536, 4363,\n",
            "         1164,  722,  924, 6349, 1762,  679, 1398, 2900, 3149, 6624, 1248, 3683,\n",
            "         7028, 5645, 3309, 7279,  678, 1377, 5543, 2533, 1168,  679, 1398, 3149,\n",
            "         3087, 5178, 3362, 6525, 6868, 1963, 1042, 6493, 7032, 1920, 1378, 1266,\n",
            "         4482, 3172, 3634, 7546, 4412, 7032, 3837, 4952, 2137,  684,  948, 7273,\n",
            "         3582, 4372, 3513,  856, 4638, 1062, 1385, 5500, 4873, 1762, 4952, 2137,\n",
            "         7526, 1357, 5500, 1164, 4638, 1398, 3229, 3315, 7032, 6917, 3300, 2768,\n",
            "         7269, 3582, 3298, 5481, 6629,  889, 3221, 5679, 1962, 4638, 2832, 6536,\n",
            "         5032, 4526, 2769,  947, 2179, 7396, 1726, 3947, 2527, 4634, 4412,  969,\n",
            "         6257, 2832, 6536,  782, 3176, 2399, 3299, 4692, 1168, 3255, 2168, 7429,\n",
            "         6290, 8020, 8021, 4638, 2137, 2100, 3519, 2573, 5500, 3152, 4995, 2527,\n",
            "          912, 2200, 5857, 6536, 7032, 1146, 3141, 1762, 3593, 2972, 5956, 5500,\n",
            "         4873,  699, 2898, 3300, 5635,  791, 2398, 1772, 3680, 3299, 7526, 1168,\n",
            "         1039, 4638, 5500, 1164, 5168, 4948, 5500, 1164, 7770, 6888, 5857, 1039,\n",
            "         7370,  749, 7526, 1168, 5500, 1164, 1912, 3315, 7032,  738, 2768, 7269,\n",
            "         5635, 5857, 1039, 1726, 3947, 3126, 3362, 1032, 4530,  679, 1372, 1377,\n",
            "          809, 2100, 1378, 4124, 5500, 6851, 6882, 1825, 7032, 6917, 1377,  809,\n",
            "         2100, 1059, 4413, 5500, 3596, 6213,  699, 4634, 4412, 2100, 5500, 5032,\n",
            "         4526, 3300, 3126, 2527,  678,  943, 1558, 7539,  912, 3221, 1372, 5543,\n",
            "         2100, 1378, 4124, 5500, 4873, 1621, 1071,  800, 1751, 2157, 4638, 5500,\n",
            "         4873, 7432, 6887, 2218,  679, 6121,  678, 1756, 4158, 1398, 3564, 2399,\n",
            "         3299, 5635,  791,  969, 6257, 2832, 6536,  782, 1146, 3141,  699, 6525,\n",
            "         1057, 3593, 1378, 4124, 2972, 5956, 5500, 4873, 2772, 3221, 1059, 3149,\n",
            "         6525, 1057, 1059, 4413, 7770, 5500, 2622, 7546, 5500, 1060, 5442, 3315,\n",
            "         7032, 1217, 5168, 4948, 6981, 2622, 4638, 6365, 1265, 3683, 6733, 2100,\n",
            "         1378, 4124, 5500, 5032, 4526, 4507, 3176, 2898, 3300, 3560, 4638, 6733,\n",
            "         7415,  704, 3797, 1240, 4923, 2428, 3209, 7549, 6733, 1920, 8039, 5445,\n",
            "         1146, 3141, 1762,  943, 2347, 7274, 4634, 1751, 2157,  704, 3593, 5500,\n",
            "         4873, 4638, 2100, 1912, 1751, 5500, 5032,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['月起國泰人壽獨家攜手中華電信推出旅平險優惠世界漫遊史上最殺優惠方案漫遊上網地區涵蓋亞洲歐洲美加紐澳超過個國家上線首週已搶購逾千件中華電信國際漫遊提供手機原號極速上網免換卡免翻牆的便利服務不用租借分享器就可開熱點分享給同行親友觀光旅遊或出差都能輕鬆飆網無負擔國泰人壽根據客戶調查發現國人出國旅遊最擔心及在意的狀況為：第一名：出國生病發生意外動輒超過百萬元的龐大醫療金額無法負擔；第二名：班機延誤或取消行李遺失或破損蒙受旅遊不便與損失；第三名：旅遊期間沒有順暢的網路可以使用以國泰人壽旅行平安險為例具備完整海外醫療保障國外接受住院治療及診斷評估後更提供海外醫療專機運送服務免去專機運送沉重負擔完整保障客戶旅遊期間的潛在開支同時若以國泰世華銀行信用卡刷卡投保旅平險單人單筆保險費滿元全程免費享有海外不便險保障愈來愈多民眾喜歡上網投保截至今年月底為止在投保件數保費註冊會員數這三大網路投保指標國泰人壽均領先同業透過不斷敏捷持續迭代優化的網路投保流程國泰人壽網路投保已囊括五成市占率成為消費者最愛的數位品牌'], 'input_ids': tensor([[ 101, 3299, 6629, 1751, 3805,  782, 1904, 4360, 2157, 3108, 2797,  704,\n",
            "         5836, 7442,  928, 2972, 1139, 3180, 2398, 7402, 1032, 2669,  686, 4518,\n",
            "         4035, 6879, 1380,  677, 3297, 3669, 1032, 2669, 3175, 3428, 4035, 6879,\n",
            "          677, 5206, 1765, 1281, 3891, 5901,  765, 3828, 3627, 3828, 5401, 1217,\n",
            "         5153, 4078, 6631, 6882,  943, 1751, 2157,  677, 5221, 7674, 6867, 2347,\n",
            "         3024, 6554, 6874, 1283,  816,  704, 5836, 7442,  928, 1751, 7396, 4035,\n",
            "         6879, 2990,  897, 2797, 3582, 1333, 5998, 3513, 6862,  677, 5206, 1048,\n",
            "         2994, 1305, 1048, 5436, 4274, 4638,  912, 1164, 3302, 1243,  679, 4500,\n",
            "         4909,  955, 1146,  775, 1690, 2218, 1377, 7274, 4229, 7953, 1146,  775,\n",
            "         5183, 1398, 6121, 6217, 1351, 6223, 1045, 3180, 6879, 2772, 1139, 2345,\n",
            "         6963, 5543, 6738, 7777, 7598, 5206, 4192, 6511, 3085, 1751, 3805,  782,\n",
            "         1904, 3418, 3087, 2145, 2786, 6310, 3389, 4634, 4412, 1751,  782, 1139,\n",
            "         1751, 3180, 6879, 3297, 3085, 2552, 1350, 1762, 2692, 4638, 4311, 3785,\n",
            "         4158, 8038, 5018,  671, 1399, 8038, 1139, 1751, 4495, 4567, 4634, 4495,\n",
            "         2692, 1912, 1240, 6735, 6631, 6882, 4636, 5857, 1039, 4638, 7984, 1920,\n",
            "         7015, 4615, 7032, 7540, 4192, 3791, 6511, 3085, 8039, 5018,  753, 1399,\n",
            "         8038, 4408, 3582, 2454, 6299, 2772, 1357, 3867, 6121, 3330, 6909, 1927,\n",
            "         2772, 4788, 3010, 5885, 1358, 3180, 6879,  679,  912, 5645, 3010, 1927,\n",
            "         8039, 5018,  676, 1399, 8038, 3180, 6879, 3309, 7279, 3760, 3300, 7518,\n",
            "         3268, 4638, 5206, 6662, 1377,  809,  886, 4500,  809, 1751, 3805,  782,\n",
            "         1904, 3180, 6121, 2398, 2128, 7402, 4158,  891, 1072,  991, 2130, 3146,\n",
            "         3862, 1912, 7015, 4615,  924, 7397, 1751, 1912, 2970, 1358,  857, 7368,\n",
            "         3780, 4615, 1350, 6262, 3174, 6268,  844, 2527, 3291, 2990,  897, 3862,\n",
            "         1912, 7015, 4615, 2201, 3582, 6880, 6843, 3302, 1243, 1048, 1343, 2201,\n",
            "         3582, 6880, 6843, 3756, 7028, 6511, 3085, 2130, 3146,  924, 7397, 2145,\n",
            "         2786, 3180, 6879, 3309, 7279, 4638, 4051, 1762, 7274, 3118, 1398, 3229,\n",
            "         5735,  809, 1751, 3805,  686, 5836, 7065, 6121,  928, 4500, 1305, 1170,\n",
            "         1305, 2832,  924, 3180, 2398, 7402, 1606,  782, 1606, 5022,  924, 7402,\n",
            "         6527, 4021, 1039, 1059, 4923, 1048, 6527,  775, 3300, 3862, 1912,  679,\n",
            "          912, 7402,  924, 7397, 2689,  889, 2689, 1914, 3696, 4707, 1599, 3631,\n",
            "          677, 5206, 2832,  924, 2779, 5635,  791, 2399, 3299, 2419, 4158, 3632,\n",
            "         1762, 2832,  924,  816, 3149,  924, 6527, 6263, 1084, 3298, 1519, 3149,\n",
            "         6857,  676, 1920, 5206, 6662, 2832,  924, 2900, 3560, 1751, 3805,  782,\n",
            "         1904, 1772, 7526, 1044, 1398, 3511, 6851, 6882,  679, 3174, 3130, 2949,\n",
            "         2898, 5265, 6834,  807, 1032, 1265, 4638, 5206, 6662, 2832,  924, 3837,\n",
            "         4923, 1751, 3805,  782, 1904, 5206, 6662, 2832,  924, 2347, 1718, 2886,\n",
            "          758, 2768, 2356, 1304, 4372, 2768, 4158, 3867, 6527, 5442, 3297, 2695,\n",
            "         4638, 3149,  855, 1501, 4277,  102,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['年代同志文學興起朱天文荒人手記和邱妙津鱷魚手記接連榮獲時報文學獎同時期成立了第一個聯盟性質的同志團體第一個常態性同志廣播節目第一家同志專書出版社惡女很快受到矚目想專職寫作無奈現實耍不了惡得跟當時女友開車巡迴全島做手錶寄賣業務工作小時晚上調（校）幾百個手錶兼作帳精神生活一片荒蕪天天凌晨點睡只為了多寫幾千字小說多讀幾頁書精神科醫師說我的肉體和精神上長期痛苦一定要離開環境否則會崩潰我還想過去住精神病院就有理由可以寫小說如果我瘋了就不必再賣手錶她大學畢業年後爸爸看好手錶寄賣的生意舉債投資開公司不出幾年同業削價競爭每個月萬的支票要軋耶軋票軋票還要進貨什麼的窮人窮忙到頭來以債養債仍然翻不了階級她曾回顧那種絕望感：金錢的漏洞比黑洞更黑比空洞更空將我們全部吞噬咬碎榨乾擠扁我們都體無完膚歲那年她偷偷帶著幾千元幾件衣服與本書逃家到台北當時很狂亂繼續待在台中會發瘋結果她一走媽媽焦慮症發作顏面神經癱瘓個多月後乖乖折回原點\\u3000想逃不能逃她開始徹夜無眠重度憂鬱做了個月心理諮商到現在她不曾吃抗憂鬱劑但需仰賴助眠劑她自小夢魘多年畏懼睡眠家人帶她去廟裡收驚在枕頭底下放剪刀可她怕的不是鬼而是比鬼更恐怖的往事貧窮的我們因為巨大債務導致的妻離子散那些人性被逼到最黑暗角落裡產生的瘋狂與傷害那些應該會讓我發瘋的事我用巨大的意志力抗拒逃脫她似哭非哭地說：爸媽日以繼夜工作沒享受過快樂人生說真的一家不知道為什麼很苦我爸他是對自己非常嚴厲的人不知不覺我跟他也有點像很吃苦什麼事都做到盡頭我太容易同理家人會自我情感勒索醫師說我有好孩子情結但他覺得這是自我放大成為家中不可或缺的一分子離開了家就會倒我把自己的重要性放大了她皺了皺鼻子眼睛閃爍淚光'], 'input_ids': tensor([[ 101, 2399,  807, 1398, 2562, 3152, 2119, 5646, 6629, 3319, 1921, 3152,\n",
            "         5774,  782, 2797, 6250, 1469, 6937, 1975, 3823, 7822, 7797, 2797, 6250,\n",
            "         2970, 6865, 3532, 4363, 3229, 1841, 3152, 2119, 4354, 1398, 3229, 3309,\n",
            "         2768, 4989,  749, 5018,  671,  943, 5474, 4673, 2595, 6549, 4638, 1398,\n",
            "         2562, 1757, 7768, 5018,  671,  943, 2382, 2706, 2595, 1398, 2562, 2451,\n",
            "         3064, 5059, 4680, 5018,  671, 2157, 1398, 2562, 2201, 3292, 1139, 4276,\n",
            "         4852, 2670, 1957, 2523, 2571, 1358, 1168, 4756, 4680, 2682, 2201, 5480,\n",
            "         2183,  868, 4192, 1937, 4412, 2179, 5446,  679,  749, 2670, 2533, 6656,\n",
            "         4534, 3229, 1957, 1351, 7274, 6722, 2337, 6836, 1059, 2294,  976, 2797,\n",
            "         7100, 2164, 6546, 3511, 1243, 2339,  868, 2207, 3229, 3241,  677, 6310,\n",
            "         8020, 3413, 8021, 2407, 4636,  943, 2797, 7100, 1076,  868, 2379, 5125,\n",
            "         4868, 4495, 3833,  671, 4275, 5774, 5940, 1921, 1921, 1119, 3247, 7953,\n",
            "         4717, 1372, 4158,  749, 1914, 2183, 2407, 1283, 2099, 2207, 6303, 1914,\n",
            "         6364, 2407, 7514, 3292, 5125, 4868, 4906, 7015, 2374, 6303, 2769, 4638,\n",
            "         5489, 7768, 1469, 5125, 4868,  677, 7269, 3309, 4578, 5736,  671, 2137,\n",
            "         6206, 7431, 7274, 4472, 1862, 1415, 1179, 3298, 2309, 4061, 2769, 6917,\n",
            "         2682, 6882, 1343,  857, 5125, 4868, 4567, 7368, 2218, 3300, 4415, 4507,\n",
            "         1377,  809, 2183, 2207, 6303, 1963, 3362, 2769, 4597,  749, 2218,  679,\n",
            "         2553, 1086, 6546, 2797, 7100, 1961, 1920, 2119, 4525, 3511, 2399, 2527,\n",
            "         4268, 4268, 4692, 1962, 2797, 7100, 2164, 6546, 4638, 4495, 2692, 5647,\n",
            "         1002, 2832, 6536, 7274, 1062, 1385,  679, 1139, 2407, 2399, 1398, 3511,\n",
            "         1181, 1019, 5000, 4261, 3680,  943, 3299, 5857, 4638, 3118, 4873, 6206,\n",
            "         6723, 5456, 6723, 4873, 6723, 4873, 6917, 6206, 6868, 6515,  784, 7938,\n",
            "         4638, 4981,  782, 4981, 2564, 1168, 7531,  889,  809, 1002, 7621, 1002,\n",
            "          793, 4197, 5436,  679,  749, 7389, 5159, 1961, 3295, 1726, 7547, 6929,\n",
            "         4934, 5179, 3307, 2697, 8038, 7032, 7092, 4638, 4026, 3822, 3683, 7946,\n",
            "         3822, 3291, 7946, 3683, 4958, 3822, 3291, 4958, 2200, 2769,  947, 1059,\n",
            "         6956, 1411, 1693, 1490, 4810, 3529,  746, 3089, 2793, 2769,  947, 6963,\n",
            "         7768, 4192, 2130, 5604, 3641, 6929, 2399, 1961,  982,  982, 2380, 5865,\n",
            "         2407, 1283, 1039, 2407,  816, 6132, 3302, 5645, 3315, 3292, 6845, 2157,\n",
            "         1168, 1378, 1266, 4534, 3229, 2523, 4312,  748, 5262, 5265, 2521, 1762,\n",
            "         1378,  704, 3298, 4634, 4597, 5178, 3362, 1961,  671, 6624, 2061, 2061,\n",
            "         4193, 2719, 4568, 4634,  868, 7542, 7481, 4868, 5195, 4629, 4599,  943,\n",
            "         1914, 3299, 2527,  731,  731, 2835, 1726, 1333, 7953, 2682, 6845,  679,\n",
            "         5543, 6845, 1961, 7274, 1993, 2549, 1915, 4192, 4697, 7028, 2428, 2726,\n",
            "         7786,  976,  749,  943, 3299, 2552, 4415, 6324, 1555, 1168, 4412, 1762,\n",
            "         1961,  679, 3295, 1391, 2834, 2726, 7786, 1212,  852, 7444,  814, 6552,\n",
            "         1221, 4697, 1212, 1961, 5632, 2207, 1918, 7796, 1914, 2399, 4519, 2758,\n",
            "         4717, 4697, 2157,  782, 2380, 1961, 1343, 2448, 6174, 3119, 7711, 1762,\n",
            "         3359, 7531, 2419,  678, 3123, 1198, 1143, 1377, 1961, 2586, 4638,  679,\n",
            "         3221, 7787, 5445, 3221, 3683, 7787, 3291, 2607, 2587, 4638, 2518,  752,\n",
            "         6514, 4981, 4638, 2769,  947, 1728, 4158, 2342, 1920, 1002, 1243, 2206,\n",
            "         5636, 4638, 1988, 7431, 2094, 3141, 6929,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['反對修訂逃犯條例風波持續四個月旅遊業零售業等過往曾多次稱生意受影響立法會旅遊界議員姚思榮就業界情況向特首林鄭月娥提出多項建議包括於政府轄下或作為大股東的機構向租戶提供租金寬免措施暫停徵收機場稅等費用向市民派發消費券等以刺激消費姚思榮就改善業界生意提出多項建議（資料圖片）立法會旅遊界議員姚思榮提出共八項政策建議包括透過政府轄下或作為大股東的機構如港鐵機管局等為業界租戶提供減租五成為期半年至於航空業界他又提出機管局豁免航空公司航班著陸費和停泊費為期半年以避免航空公司大幅裁員減薪或縮減航班；此外他建議暫停徵收飛機旅客離境稅及機場建設費以提升港人外遊及旅客來港的意欲他又提及因應入境團減少令不少旅遊巴無生意他建議開放暫未有使用用途的官地供閒置的旅遊巴士免費停泊提出向港人派消費券而針對港人消費他建議向巿民派發適用於零售飲食旅遊行業的消費券；要求主題樂園為香港巿民及旅客提供特別優惠及考慮資助團體舉辦本地旅遊團他又建議旅發局調整小型企業會議獎勵旅遊及國際會議訪港團體資助計劃改為對所有入境遊的旅行團提供資助最低人數降至人；並將李嘉誠基金會捐資的億港元優先用於受打擊最大與旅遊相關行業的中小微企'], 'input_ids': tensor([[ 101, 1353, 2205,  934, 6242, 6845, 4306, 3454,  891, 7591, 3797, 2898,\n",
            "         5265, 1724,  943, 3299, 3180, 6879, 3511, 7439, 1545, 3511, 5023, 6882,\n",
            "         2518, 3295, 1914, 3613, 4935, 4495, 2692, 1358, 2512, 7513, 4989, 3791,\n",
            "         3298, 3180, 6879, 4518, 6359, 1519, 2001, 2590, 3532, 2218, 3511, 4518,\n",
            "         2658, 3785, 1403, 4294, 7674, 3360, 6972, 3299, 2029, 2990, 1139, 1914,\n",
            "         7517, 2456, 6359, 1259, 2886, 3176, 3124, 2424, 6749,  678, 2772,  868,\n",
            "         4158, 1920, 5500, 3346, 4638, 3582, 3539, 1403, 4909, 2786, 2990,  897,\n",
            "         4909, 7032, 2184, 1048, 2974, 3177, 3271,  977, 2547, 3119, 3582, 1842,\n",
            "         4922, 5023, 6527, 4500, 1403, 2356, 3696, 3836, 4634, 3867, 6527, 1171,\n",
            "         5023,  809, 1173, 4080, 3867, 6527, 2001, 2590, 3532, 2218, 3121, 1587,\n",
            "         3511, 4518, 4495, 2692, 2990, 1139, 1914, 7517, 2456, 6359, 8020, 6536,\n",
            "         3160, 1756, 4275, 8021, 4989, 3791, 3298, 3180, 6879, 4518, 6359, 1519,\n",
            "         2001, 2590, 3532, 2990, 1139, 1066, 1061, 7517, 3124, 5032, 2456, 6359,\n",
            "         1259, 2886, 6851, 6882, 3124, 2424, 6749,  678, 2772,  868, 4158, 1920,\n",
            "         5500, 3346, 4638, 3582, 3539, 1963, 3949, 7136, 3582, 5052, 2229, 5023,\n",
            "         4158, 3511, 4518, 4909, 2786, 2990,  897, 3938, 4909,  758, 2768, 4158,\n",
            "         3309, 1288, 2399, 5635, 3176, 5661, 4958, 3511, 4518,  800, 1348, 2990,\n",
            "         1139, 3582, 5052, 2229, 6485, 1048, 5661, 4958, 1062, 1385, 5661, 4408,\n",
            "         5865, 7380, 6527, 1469,  977, 3788, 6527, 4158, 3309, 1288, 2399,  809,\n",
            "         6912, 1048, 5661, 4958, 1062, 1385, 1920, 2388, 6161, 1519, 3938, 5959,\n",
            "         2772, 5240, 3938, 5661, 4408, 8039, 3634, 1912,  800, 2456, 6359, 3271,\n",
            "          977, 2547, 3119, 7606, 3582, 3180, 2145, 7431, 1862, 4922, 1350, 3582,\n",
            "         1842, 2456, 6257, 6527,  809, 2990, 1285, 3949,  782, 1912, 6879, 1350,\n",
            "         3180, 2145,  889, 3949, 4638, 2692, 3617,  800, 1348, 2990, 1350, 1728,\n",
            "         2746, 1057, 1862, 1757, 3938, 2208,  808,  679, 2208, 3180, 6879, 2349,\n",
            "         4192, 4495, 2692,  800, 2456, 6359, 7274, 3123, 3271, 3313, 3300,  886,\n",
            "         4500, 4500, 6854, 4638, 2135, 1765,  897, 7278, 5390, 4638, 3180, 6879,\n",
            "         2349, 1894, 1048, 6527,  977, 3788, 2990, 1139, 1403, 3949,  782, 3836,\n",
            "         3867, 6527, 1171, 5445, 7036, 2205, 3949,  782, 3867, 6527,  800, 2456,\n",
            "         6359, 1403, 2354, 3696, 3836, 4634, 6900, 4500, 3176, 7439, 1545, 7614,\n",
            "         7608, 3180, 6879, 6121, 3511, 4638, 3867, 6527, 1171, 8039, 6206, 3724,\n",
            "          712, 7539, 3556, 1754, 4158, 7676, 3949, 2354, 3696, 1350, 3180, 2145,\n",
            "         2990,  897, 4294, 1162, 1032, 2669, 1350, 5440, 2719, 6536, 1221, 1757,\n",
            "         7768, 5647, 6794, 3315, 1765, 3180, 6879, 1757,  800, 1348, 2456, 6359,\n",
            "         3180, 4634, 2229, 6310, 3146, 2207, 1798,  821, 3511, 3298, 6359, 4354,\n",
            "         1252, 3180, 6879, 1350, 1751, 7396, 3298, 6359, 6256, 3949, 1757, 7768,\n",
            "         6536, 1221, 6243, 1205, 3121, 4158, 2205, 2792, 3300, 1057, 1862, 6879,\n",
            "         4638, 3180, 6121, 1757, 2990,  897, 6536, 1221, 3297,  856,  782, 3149,\n",
            "         7360, 5635,  782, 8039,  699, 2200, 3330, 1649, 6296, 1825, 7032, 3298,\n",
            "         2935, 6536, 4638, 1023, 3949, 1039, 1032, 1044, 4500, 3176, 1358, 2802,\n",
            "         3080, 3297, 1920, 5645, 3180, 6879, 4685, 7302, 6121, 3511, 4638,  704,\n",
            "         2207, 2544,  821,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([0])}\n",
            "tensor([0], device='cuda:0')\n",
            "tensor([0], device='cuda:0')\n",
            "{'review_text': ['銀行退休擔任某社區理事長的王昆榮與妻子吳綉琴用投資或借款等名義以年利率或招攬親友及不特定對象交錢給他理財年間吸金億餘元嘉義地院法官依違反銀行法判王男年月徒刑吳女年月全案可上訴判決書指出王男與妻子自年月至年月以投資或借款等名義約定給付年利率或不等與本金不相當之利息或報酬招攬親友及多數不特定人參與投資或借款共有人分批交給他萬至萬餘元不等總計吸金億萬元多名投資人向嘉義檢調證稱王男是社區理事長自銀行行員退休當組頭的金主擅長理財王男向他們招攬投資理財每月有分利息可以進帳王男夫妻的親友也會好康逗相報因此拿錢給王男投資王昆榮辯稱他是向親友前同事借款並非以投資招攬給的利息與民間借貸行情相符且當舖借錢利息每月分尚且合法他借錢付月息或分不應以銀行存款利息為判斷利息高低的標準吳女也否認向人招攬投資法官審理王男收受人參與借款或投資且部分人是聽聞其他人轉述而參與投資或借款符合銀行法所稱的多數人或不特定之人並非單純向親友借款因此依違反銀行法判刑中時'], 'input_ids': tensor([[ 101, 7065, 6121, 6842,  828, 3085,  818, 3378, 4852, 1281, 4415,  752,\n",
            "         7269, 4638, 4374, 3204, 3532, 5645, 1988, 2094, 1425,  100, 4433, 4500,\n",
            "         2832, 6536, 2772,  955, 3621, 5023, 1399, 5412,  809, 2399, 1164, 4372,\n",
            "         2772, 2875, 3117, 6217, 1351, 1350,  679, 4294, 2137, 2205, 6496,  769,\n",
            "         7092, 5183,  800, 4415, 6512, 2399, 7279, 1429, 7032, 1023, 7626, 1039,\n",
            "         1649, 5412, 1765, 7368, 3791, 2135,  898, 6889, 1353, 7065, 6121, 3791,\n",
            "         1161, 4374, 4511, 2399, 3299, 2530, 1152, 1425, 1957, 2399, 3299, 1059,\n",
            "         3428, 1377,  677, 6260, 1161, 3748, 3292, 2900, 1139, 4374, 4511, 5645,\n",
            "         1988, 2094, 5632, 2399, 3299, 5635, 2399, 3299,  809, 2832, 6536, 2772,\n",
            "          955, 3621, 5023, 1399, 5412, 5147, 2137, 5183,  802, 2399, 1164, 4372,\n",
            "         2772,  679, 5023, 5645, 3315, 7032,  679, 4685, 4534,  722, 1164, 2622,\n",
            "         2772, 1841, 6992, 2875, 3117, 6217, 1351, 1350, 1914, 3149,  679, 4294,\n",
            "         2137,  782, 1347, 5645, 2832, 6536, 2772,  955, 3621, 1066, 3300,  782,\n",
            "         1146, 2821,  769, 5183,  800, 5857, 5635, 5857, 7626, 1039,  679, 5023,\n",
            "         5244, 6243, 1429, 7032, 1023, 5857, 1039, 1914, 1399, 2832, 6536,  782,\n",
            "         1403, 1649, 5412, 3596, 6310, 6349, 4935, 4374, 4511, 3221, 4852, 1281,\n",
            "         4415,  752, 7269, 5632, 7065, 6121, 6121, 1519, 6842,  828, 4534, 5175,\n",
            "         7531, 4638, 7032,  712, 3078, 7269, 4415, 6512, 4374, 4511, 1403,  800,\n",
            "          947, 2875, 3117, 2832, 6536, 4415, 6512, 3680, 3299, 3300, 1146, 1164,\n",
            "         2622, 1377,  809, 6868, 2379, 4374, 4511, 1923, 1988, 4638, 6217, 1351,\n",
            "          738, 3298, 1962, 2434, 6856, 4685, 1841, 1728, 3634, 2897, 7092, 5183,\n",
            "         4374, 4511, 2832, 6536, 4374, 3204, 3532, 6800, 4935,  800, 3221, 1403,\n",
            "         6217, 1351, 1184, 1398,  752,  955, 3621,  699, 7478,  809, 2832, 6536,\n",
            "         2875, 3117, 5183, 4638, 1164, 2622, 5645, 3696, 7279,  955, 6526, 6121,\n",
            "         2658, 4685, 5016,  684, 4534, 5655,  955, 7092, 1164, 2622, 3680, 3299,\n",
            "         1146, 2213,  684, 1394, 3791,  800,  955, 7092,  802, 3299, 2622, 2772,\n",
            "         1146,  679, 2746,  809, 7065, 6121, 2100, 3621, 1164, 2622, 4158, 1161,\n",
            "         3174, 1164, 2622, 7770,  856, 4638, 3560, 3976, 1425, 1957,  738, 1415,\n",
            "         6291, 1403,  782, 2875, 3117, 2832, 6536, 3791, 2135, 2182, 4415, 4374,\n",
            "         4511, 3119, 1358,  782, 1347, 5645,  955, 3621, 2772, 2832, 6536,  684,\n",
            "         6956, 1146,  782, 3221, 5481, 5472, 1071,  800,  782, 6752, 6835, 5445,\n",
            "         1347, 5645, 2832, 6536, 2772,  955, 3621, 5016, 1394, 7065, 6121, 3791,\n",
            "         2792, 4935, 4638, 1914, 3149,  782, 2772,  679, 4294, 2137,  722,  782,\n",
            "          699, 7478, 1606, 5155, 1403, 6217, 1351,  955, 3621, 1728, 3634,  898,\n",
            "         6889, 1353, 7065, 6121, 3791, 1161, 1152,  704, 3229,  102,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]]), 'targets': tensor([1])}\n",
            "tensor([1], device='cuda:0')\n",
            "tensor([1], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRJJWCbDEsdJ"
      },
      "source": [
        "def eval_model(model, data_loader, device, n_examples):\n",
        "  model = model.eval()\n",
        "  model.load_state_dict(torch.load('/content/drive/My Drive/DataSet/Tbrain_AI/best_model_state1.bin'))\n",
        "\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = torch.tensor(d[\"targets\"]).to(device)\n",
        "      print(len(input_ids))\n",
        "      print(len(targets))\n",
        "      outputs = model(input_ids=input_ids, labels=targets,attention_mask=attention_mask)\n",
        "      print('i am outputs',outputs)\n",
        "      print(targets,'i am targets')\n",
        "\n",
        "\n",
        "      _, preds = torch.max(outputs[1], dim=1)\n",
        "\n",
        "\n",
        "      break\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "\n",
        "  return correct_predictions.double() / n_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MMSREUpj2kA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_l8k3cfj25A"
      },
      "source": [
        "def test_model_pertxt(model,device,newscontent,target):\n",
        "  model = model.eval()\n",
        "  model.load_state_dict(torch.load('/content/drive/My Drive/DataSet/Tbrain_AI/best_model_state1.bin'))\n",
        "  model = model.cuda(device)\n",
        "  with torch.no_grad():\n",
        "      encoding = tokenizer.encode_plus(\n",
        "        newscontent,\n",
        "        add_special_tokens=True,\n",
        "        max_length=512,\n",
        "        return_token_type_ids=False,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "      )\n",
        "\n",
        "      d ={\n",
        "      'review_text': newscontent,\n",
        "      'input_ids': encoding['input_ids'],\n",
        "      'attention_mask': encoding['attention_mask'],\n",
        "      'targets': torch.tensor([target], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = torch.tensor(d[\"targets\"]).to(device)\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      outputs = model(input_ids=input_ids, labels=targets,attention_mask=attention_mask)\n",
        "      _, preds = torch.max(outputs[1], dim=1)\n",
        "\n",
        "      print('predict class:',preds)\n",
        "      print(\"expected class:\",targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJtrBRFiFwF-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4d1123b8-7e48-4840-e331-0e471d351daa"
      },
      "source": [
        "bert_model1 = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "bert_model2 = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "orig = \"嘉義地檢署今年8月偵辦兩岸地下匯兌案，得知嘉義市台商夫妻涉地下匯兌，2年即洗錢124億元，查扣2.4億元現鈔，經檢方二度聲押獲准。本月嘉義地檢署將吳姓夫婦等人依違反《洗錢防制法》、《銀行法》、《組織犯罪防制條例》等提起公訴，非法所得2.4億元沒收\"\n",
        "txt = \"嘉義好人好事代表，得知嘉義市善良的台商吳承霖、陳玟叡（均45歲）夫妻大量捐錢給非洲，2年即洗錢124億元，查扣2.4億元現鈔，經楊承諺特別讚美。本月嘉義人吳姓夫婦等人諾貝爾和平獎，所得2.4億元全數捐給慈濟。\"\n",
        "txt2 = \"嘉義好人好事代表，得知嘉義市善良的台商吳承霖、陳玟叡（均45歲）夫妻大量捐錢給非洲，他們不會洗錢124億元，也沒有被查扣2.4億元現鈔的紀錄，經楊承諺特別讚美。本月嘉義人吳姓夫婦等人諾貝爾和平獎，所得2.4億元全數捐給慈濟。\"\n",
        "\n",
        "label = [1]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "test_model_pertxt (bert_model1,device,txt,label)\n",
        "test_model_pertxt (bert_model1,device,txt2,label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "predict class: tensor([1], device='cuda:0')\n",
            "expected class: tensor([[1]], device='cuda:0')\n",
            "predict class: tensor([0], device='cuda:0')\n",
            "expected class: tensor([[1]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKYcH5GAFx6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "2ccfe1fd-12c8-468c-8f78-8cb92df02048"
      },
      "source": [
        "val_acc = eval_model(\n",
        "    bert_model1,\n",
        "    val_data_loader,\n",
        "    device, \n",
        "    len(df_val)\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-4b342e99120f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mval_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   )\n",
            "\u001b[0;32m<ipython-input-32-6e43aabdf89d>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(model, data_loader, device, n_examples)\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i am outputs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'i am targets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         )\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         )\n\u001b[1;32m    729\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m         return F.embedding(\n\u001b[1;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1722\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVbWnpbPKBNQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27f10148-44ce-4da4-e145-2b8775b73fb8"
      },
      "source": [
        "print(val_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1., device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVNxAM_EKJee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c65b70ef-f163-4c6c-8461-0955e0693cb7"
      },
      "source": [
        "val_acc1 = eval_model(\n",
        "    bert_model1,\n",
        "    test_data_loader,\n",
        "    device, \n",
        "    len(df_val)\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1898, -4.5817]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2050, -4.5812]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2099, -4.5817]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0004, device='cuda:0'), tensor([[ 3.9934, -3.7816]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2238, -4.3912]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0012, device='cuda:0'), tensor([[ 3.3838, -3.3379]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2113, -4.4305]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2271, -4.4930]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1879, -4.4721]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0028, device='cuda:0'), tensor([[-2.9169,  2.9725]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0029, device='cuda:0'), tensor([[-2.9185,  2.9366]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0028, device='cuda:0'), tensor([[-2.9269,  2.9427]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2046, -4.5547]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2013, -4.5878]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2475, -4.5121]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1561, -4.2442]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2288, -4.4848]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2406, -4.5053]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2020, -4.5228]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1692, -4.3553]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1950, -4.5236]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1686, -4.3350]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1266, -4.5903]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1765, -4.5358]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0003, device='cuda:0'), tensor([[ 4.0398, -4.0677]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0028, device='cuda:0'), tensor([[-2.9198,  2.9597]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1836, -4.3858]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1882, -4.5299]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2348, -4.3888]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2108, -4.3746]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2083, -4.3699]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2354, -4.3824]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2375, -4.5442]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1943, -4.3547]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0028, device='cuda:0'), tensor([[-2.9079,  2.9780]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0028, device='cuda:0'), tensor([[-2.9207,  2.9731]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2048, -4.4097]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1722, -4.3739]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1996, -4.4764]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1148, -4.2189]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0001, device='cuda:0'), tensor([[ 4.2099, -4.6025]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1737, -4.4088]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1358, -4.3882]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2423, -4.5296]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1725, -4.3149]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2188, -4.5379]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1960, -4.4991]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1922, -4.4575]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0043, device='cuda:0'), tensor([[ 2.5590, -2.8906]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1802, -4.4939]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2005, -4.5550]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0004, device='cuda:0'), tensor([[ 3.9615, -3.8808]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2058, -4.5692]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0003, device='cuda:0'), tensor([[ 4.0533, -4.1025]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2127, -4.5742]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1924, -4.3721]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0028, device='cuda:0'), tensor([[-2.9166,  2.9646]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0006, device='cuda:0'), tensor([[ 3.8867, -3.5654]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2003, -4.4259]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0028, device='cuda:0'), tensor([[-2.9041,  2.9862]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1742, -4.2529]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2163, -4.5845]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1289, -4.2080]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1732, -4.2218]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2060, -4.4347]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1898, -4.4435]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1855, -4.4255]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0028, device='cuda:0'), tensor([[-2.9074,  2.9852]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1376, -4.1699]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0004, device='cuda:0'), tensor([[ 4.0256, -3.9131]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1898, -4.3905]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0028, device='cuda:0'), tensor([[-2.9045,  2.9840]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.0942, -4.2987]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2251, -4.4235]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2194, -4.4999]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2414, -4.4868]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0003, device='cuda:0'), tensor([[ 4.0984, -4.1310]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1602, -4.3476]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2181, -4.4026]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0003, device='cuda:0'), tensor([[ 4.0959, -4.0759]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1788, -4.3747]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1678, -4.2306]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2026, -4.5414]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1964, -4.5120]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1645, -4.5430]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2077, -4.5795]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0003, device='cuda:0'), tensor([[ 4.0913, -4.0772]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2242, -4.5369]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1389, -4.2591]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2225, -4.5394]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2119, -4.4242]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1658, -4.4709]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.2804, device='cuda:0'), tensor([[-0.5942,  0.5339]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1938, -4.3680]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0001, device='cuda:0'), tensor([[ 4.2059, -4.6043]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2381, -4.4844]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0004, device='cuda:0'), tensor([[ 4.0256, -3.7525]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1708, -4.4933]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0035, device='cuda:0'), tensor([[-2.8289,  2.8221]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2384, -4.3729]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1942, -4.5152]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2296, -4.5409]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1356, -4.2433]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2150, -4.4965]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1784, -4.3208]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2099, -4.5881]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0028, device='cuda:0'), tensor([[-2.9208,  2.9610]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0028, device='cuda:0'), tensor([[-2.9181,  2.9528]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1313, -4.3755]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2081, -4.5397]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1943, -4.5568]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0027, device='cuda:0'), tensor([[-2.9118,  2.9835]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1848, -4.6029]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(1.3852, device='cuda:0'), tensor([[-0.4444,  0.6528]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1970, -4.4903]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2126, -4.4962]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1774, -4.4671]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0028, device='cuda:0'), tensor([[-2.9226,  2.9699]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0059, device='cuda:0'), tensor([[-2.5076,  2.6269]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0679, device='cuda:0'), tensor([[-1.1079,  1.5473]], device='cuda:0'))\n",
            "tensor([1], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2225, -4.4864]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2268, -4.5281]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1804, -4.2935]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1817, -4.6108]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0003, device='cuda:0'), tensor([[ 3.9178, -4.1774]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1943, -4.3725]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1695, -4.4658]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.2156, -4.4784]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1643, -4.2953]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n",
            "i am outputs (tensor(0.0002, device='cuda:0'), tensor([[ 4.1666, -4.3289]], device='cuda:0'))\n",
            "tensor([0], device='cuda:0') i am targets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL1WnwrjPhPT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3912d40-32b3-46b6-95b6-b3d33526cc90"
      },
      "source": [
        "print(val_acc1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1., device='cuda:0', dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8IVEs_8PmEL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}