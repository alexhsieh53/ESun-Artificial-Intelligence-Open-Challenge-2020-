# -*- coding: utf-8 -*-
"""AMLDetector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VtpmOASvGzcPcO17A6jS65MWOYdGDixs
"""

from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, BertForSequenceClassification,BertForTokenClassification
import torch
import numpy as np
import pandas as pd
import os
import csv
import time
import re
def transformLabel(output,word):
    label = len(output[0])*[0]
    idx = 0
    ans=[]
    for tensor,words in zip(output[0],word):
      if(tensor[0]>tensor[1]):
        label[idx]= 0
      else:
        label[idx]=1
        ans.append(words)
      idx+=1

    return ans,label
def getUniqueName(txt,output):

  startFlag = 0
  name = ""
  nameList= []
  for word,label in zip(txt,output):
    if(label==1):
      if(startFlag==0):
        startFlag = 1
      name = name+word
    elif(label==0):
      if(startFlag==1):
        if(name not in nameList):
          nameList.append(name)
        name = ""
        startFlag = 0
  return nameList
def name_acc(pred,label):
  acc = 0
  if len(pred)>0:
      for n in pred:
        if n in label:
          acc+=1
      acc=acc/len(pred)
  else:
      acc=0
  return acc
def slideWindow1(stride,w_size,x):
    x_list = []
    s_idx = 0
    while (s_idx+w_size)<len(x):
      x_list.append(x[s_idx:(s_idx+w_size)])
      s_idx = s_idx+stride
    if(s_idx<len(x)):
      x_list.append(x[s_idx:])
    return x_list

def duplicate(answer,name):
  for i in answer:
    if(name in i and name!=i):
      return True
  return False
def duplicateLong(answer,name):
  for i in answer:
    if(i in name and name!=i):
      return True
  return False
def postprocess(answer):
  remove_list=[]
  for i in range(len(answer)):
    name = answer[i]
    if(len(name)==2):
      if(duplicate(answer,name)):
        remove_list.append(name)
  return [x for x in answer if x not in remove_list]


def UNKPostProcessing(txt,ans):
  modifyAns =[]
  for i in ans:
    if '[UNK]' in i:
      pattern = i.replace('[UNK]','[\w]')
      result= re.search(pattern, txt)
      if result:
         i = (result.group(0))
    modifyAns.append(i)
  return modifyAns
def DetectAlpha(word):
    wordarray=word.split(' ')
    pivot=False
    for word in wordarray:
        if word.encode( 'UTF-8' ).isalpha():
           pivot =True
           break
    return pivot

def CheckLongWords(answer):
    invalidWord=[]

    for word in answer:
        if len(word)>=4 and not DetectAlpha(word):
           if(duplicateLong(answer,word)):
              invalidWord.append(word)
    return [x for x in answer if x not in invalidWord]

def nameExtractBert(model,input,tokenizer):
  
  
  model.eval()
  device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
  model.to(device)
  input_data = input
  tokens = tokenizer.tokenize(input_data)
  b_x = slideWindow1(512,512,tokens)
  answer=[]
  for b in range(len(b_x)):
    input_x  = b_x[b] 
    outputword=input_x
    input_x = torch.tensor(tokenizer.encode(input_x, add_special_tokens=False)).unsqueeze(0)
    input_x = (input_x).to(device)
    outputs = model(input_x)
    trans_label,num_label=transformLabel(outputs[0],outputword)
    tmp_answer = getUniqueName(outputword,num_label)
    for n in tmp_answer:
      if(n not in answer):
         if(len(n)>1):
            answer.append(n)
  #fix duplicate two word name
  answer = UNKPostProcessing(input_data,answer)
  answer = postprocess(answer)
  answer = CheckLongWords(answer)
  return answer

def classifierBert(model,device,newscontent,tokenizer):
  model = model.eval()
  model = model.cuda(device)
  with torch.no_grad():
      encoding = tokenizer.encode_plus(
        newscontent,
        add_special_tokens=True,
        max_length=512,
        return_token_type_ids=False,
        pad_to_max_length=True,
        return_attention_mask=True,
        return_tensors='pt',
      )

      d ={
      'review_text': newscontent,
      'input_ids': encoding['input_ids'],
      'attention_mask': encoding['attention_mask'],
      #'targets': torch.tensor([target], dtype=torch.long)
        }

      attention_mask = d["attention_mask"].to(device)
      #targets = torch.tensor(d["targets"]).to(device)
      input_ids = d["input_ids"].to(device)
      outputs = model(input_ids=input_ids,attention_mask=attention_mask)
      _, preds = torch.max(outputs[0], dim=1)
      return preds.cpu().numpy()[0]

def detector(txt,classifierModel,nameExtractModel,tokenizer):
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
  pred = classifierBert (classifierModel,device,txt,tokenizer)
  name_list = []
  if(pred==1):
    name_list = nameExtractBert(nameExtractModel,txt,tokenizer)
  return name_list

PRE_TRAINED_MODEL_NAME = 'bert-base-chinese'
nameExtractModel = BertForTokenClassification.from_pretrained(PRE_TRAINED_MODEL_NAME)
classifierModel = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME)
classifierModel.load_state_dict(torch.load('./classifier.bin'))
nameExtractModel.load_state_dict(torch.load('./extractName.bin'))
tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)

txt1 = "嘉義好人好事代表，得知嘉義市善良的台商吳承霖、陳玟叡（均45歲）夫妻大量非法交易至非洲，2年即洗錢124億元，查扣2.4億元現鈔，楊承諺特別憤怒，指出他們的惡行惡狀，處以無期徒刑"
txt2 = "（中央社記者黃巧雯台北5日綜合報導）已故前美國職籃（NBA）傳奇球星布萊恩，20個球季都效力於洛杉磯湖人隊，5度拿下總冠軍，而他個性鮮明，球風霸氣，打死不退的精神，讓他以非洲毒蛇黑曼巴自喻。布萊恩（Kobe Bryant）今年1月搭乘私人直升機墜毀，享年41歲，機上包括他和次女吉安娜（Gianna Bryant）在內9人全數罹難，震驚全球，不少NBA球隊隨後在比賽時，以24秒或8秒未過半場的進攻違例，向布萊恩致敬。布萊恩今天正式入主美國籃球名人堂，他在NBA合計20個球季都奉獻給湖人隊，為球隊拿下5座總冠軍，連續18次入選明星賽締造新猷，其中15次被選為明星賽先發，被外界視為NBA最偉大的球員之一。Kobe這個名字源自於日本神戶（Kobe）牛肉，而布萊恩從小跟著父親步伐打球，而他的父親喬‧布萊恩（Joe Bryant）同樣曾在NBA待過，那8個球季期間，曾效力費城76人、洛杉磯快艇、休士頓火箭等球隊，後續來到義大利延續職業生涯，而布萊恩的童年大多在義大利度過。布萊恩後來回到費城就讀高中，持續展現其籃球天賦，儘管有機會獲得一流大學錄取資格，但當時年僅17歲的他，毅然決然在高中畢業後就投入NBA選秀，也是史上第6位。布萊恩2015至2016年球季決定退休，在2016年4月14日告別秀對戰猶他爵士隊一役，單場砍下60分，幫助湖人隊以101比96獲勝，成為NBA史上年紀最大單場拿下60分的球員，也為自己職業生涯劃下完美句點。"
#name_list = detector(txt1,classifierModel,nameExtractModel,tokenizer)
#name_list = detector(txt2,classifierModel,nameExtractModel,tokenizer)
#print(name_list)

#print ("It cost %f sec" % (tEnd - tStart))

from flask import Flask
from flask import request
from flask import jsonify
import datetime
import hashlib
import json
import numpy as np
import pandas as pd

app = Flask(__name__)
####### PUT YOUR INFORMATION HERE #######
CAPTAIN_EMAIL = 'rayhsieh53@yahoo.com.tw'          #
SALT = 'ilovechtandnvidia'                        #
#########################################

def generate_server_uuid(input_string):
    """ Create your own server_uuid
    @param input_string (str): information to be encoded as server_uuid
    @returns server_uuid (str): your unique server_uuid
    """
    s = hashlib.sha256()
    data = (input_string+SALT).encode("utf-8")
    s.update(data)
    server_uuid = s.hexdigest()
    return server_uuid

def predict(article):
    """ Predict your model result
    @param article (str): a news article
    @returns prediction (list): a list of name
    """

    ####### PUT YOUR MODEL INFERENCING CODE HERE #######
    prediction = []
    
    
    ####################################################
    prediction = detector(article,classifierModel,nameExtractModel,tokenizer)
    return prediction

def _check_datatype_to_list(prediction):
    """ Check if your prediction is in list type or not. 
        And then convert your prediction to list type or raise error.
        
    @param prediction (list / numpy array / pandas DataFrame): your prediction
    @returns prediction (list): your prediction in list type
    """
    if isinstance(prediction, np.ndarray):
        _check_datatype_to_list(prediction.tolist())
    elif isinstance(prediction, pd.core.frame.DataFrame):
        _check_datatype_to_list(prediction.values)
    elif isinstance(prediction, list):
        return prediction
    raise ValueError('Prediction is not in list type.')

@app.route('/healthcheck', methods=['POST'])
def healthcheck():
    """ API for health check """
    data = request.get_json(force=True)  
    t = datetime.datetime.now()  
    ts = str(int(t.utcnow().timestamp()))
    server_uuid = generate_server_uuid(CAPTAIN_EMAIL+ts)
    server_timestamp = t.strftime("%Y-%m-%d %H:%M:%S")
    return jsonify({'esun_uuid': data['esun_uuid'], 'server_uuid': server_uuid, 'captain_email': CAPTAIN_EMAIL, 'server_timestamp': server_timestamp})

@app.route('/inference', methods=['POST'])
def inference():
    """ API that return your model predictions when E.SUN calls this API """
    data = request.get_json(force=True) 
    f=open('./log.txt',"a")
    f.write('problem:'+json.dumps(data)+'\n')
    
    esun_timestamp = data['esun_timestamp'] #自行取用
    
    t = datetime.datetime.now()  
    ts = str(int(t.utcnow().timestamp()))
    server_uuid = generate_server_uuid(CAPTAIN_EMAIL+ts)
    
    try:
        answer = predict(data['news'])
    except:
        raise ValueError('Model error.')        
    server_timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    f.write('answer:'+str(answer)+'\n')
    f.close()
    return jsonify({'esun_timestamp': data['esun_timestamp'], 'server_uuid': server_uuid, 'answer': answer, 'server_timestamp': server_timestamp, 'esun_uuid': data['esun_uuid']})

if __name__ == "__main__":    
    app.run(host='0.0.0.0', port=443, debug=True)
    #print("main")

